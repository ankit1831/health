{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d1b9eab907a44e3b9df346cb8046b60d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b1915abe3b24a9bb21827afe7a0d4b4",
              "IPY_MODEL_ad89a828b5bc40f290425269546a9ffe",
              "IPY_MODEL_258acb4c6ec04f75a6ce763c4b3a65d5"
            ],
            "layout": "IPY_MODEL_1c6c14742d9e4f109565e40e41beaadc"
          }
        },
        "2b1915abe3b24a9bb21827afe7a0d4b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4bf9da1bc584daca5a7a26405931ec0",
            "placeholder": "​",
            "style": "IPY_MODEL_1ead1cd41f6c4af699ab49efa716bf61",
            "value": "config.json: 100%"
          }
        },
        "ad89a828b5bc40f290425269546a9ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b83b5299d34d45e69c6fd3c3c1d1aabe",
            "max": 385,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d227de13ffb411780a21d809fd8d292",
            "value": 385
          }
        },
        "258acb4c6ec04f75a6ce763c4b3a65d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce663b4abb934d76ab2908b8993433e0",
            "placeholder": "​",
            "style": "IPY_MODEL_3f0065bd4e044f848a6d1c84bc3a5ffd",
            "value": " 385/385 [00:00&lt;00:00, 42.4kB/s]"
          }
        },
        "1c6c14742d9e4f109565e40e41beaadc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4bf9da1bc584daca5a7a26405931ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ead1cd41f6c4af699ab49efa716bf61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b83b5299d34d45e69c6fd3c3c1d1aabe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d227de13ffb411780a21d809fd8d292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce663b4abb934d76ab2908b8993433e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f0065bd4e044f848a6d1c84bc3a5ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea772c3144614428949245bc11ceaa2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3510aaf9aadf44dd8a181b44f8a070ec",
              "IPY_MODEL_128b189a87004b3c9a0b2ca79b940981",
              "IPY_MODEL_c4ea8254d5064fcd942c9d4f9c4dac67"
            ],
            "layout": "IPY_MODEL_c5f531f5f5314016ac8f52f1786c78f0"
          }
        },
        "3510aaf9aadf44dd8a181b44f8a070ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46973bf7f8b14e668c6a314fa4bf9e43",
            "placeholder": "​",
            "style": "IPY_MODEL_2cdc34c881a947c3bb9fcaaa16ca03d3",
            "value": "vocab.txt: "
          }
        },
        "128b189a87004b3c9a0b2ca79b940981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_174e7a7d3fa24063a5566196f07ab61a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a640367825614b98bfc2353b2c3a21c5",
            "value": 1
          }
        },
        "c4ea8254d5064fcd942c9d4f9c4dac67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edeed30a6dd24eb691b7e8347cae57ac",
            "placeholder": "​",
            "style": "IPY_MODEL_fbeadce71da848f4824a5e290a035d67",
            "value": " 213k/? [00:00&lt;00:00, 15.0MB/s]"
          }
        },
        "c5f531f5f5314016ac8f52f1786c78f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46973bf7f8b14e668c6a314fa4bf9e43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cdc34c881a947c3bb9fcaaa16ca03d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "174e7a7d3fa24063a5566196f07ab61a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a640367825614b98bfc2353b2c3a21c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edeed30a6dd24eb691b7e8347cae57ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbeadce71da848f4824a5e290a035d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c55a1944e374630b1fe58fa45c02690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18226ad2eea74a97a13538d93d51c9eb",
              "IPY_MODEL_c7892fce676b48c6b56e0dec1d86bb9e",
              "IPY_MODEL_d33b53f975be49f1b8e385bedf600259"
            ],
            "layout": "IPY_MODEL_3715574f01b04e5bb3bdf43f11590dbf"
          }
        },
        "18226ad2eea74a97a13538d93d51c9eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bd5f75ee4954da7a8b6a67b122e6b3f",
            "placeholder": "​",
            "style": "IPY_MODEL_99592e6a9e8543529993f4799c0f70b7",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "c7892fce676b48c6b56e0dec1d86bb9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007b4b127a524ea484cc3a472b133460",
            "max": 435778770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e911e3083fe4c17836d3421bfeba94e",
            "value": 435778770
          }
        },
        "d33b53f975be49f1b8e385bedf600259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cbb4af8e38b4a3d8811096c7abc14a5",
            "placeholder": "​",
            "style": "IPY_MODEL_1b8871ffcec14e16b92cfecfd0520b20",
            "value": " 436M/436M [00:04&lt;00:00, 205MB/s]"
          }
        },
        "3715574f01b04e5bb3bdf43f11590dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bd5f75ee4954da7a8b6a67b122e6b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99592e6a9e8543529993f4799c0f70b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "007b4b127a524ea484cc3a472b133460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e911e3083fe4c17836d3421bfeba94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cbb4af8e38b4a3d8811096c7abc14a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b8871ffcec14e16b92cfecfd0520b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07b74df533464789a2497da9f4983dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93c30fb7032042a89bb00bfb76227d51",
              "IPY_MODEL_a93a0e87137e46aa90ba2bddfd39e793",
              "IPY_MODEL_7934042b97d64519bbfd2c652f37a7d4"
            ],
            "layout": "IPY_MODEL_0572f9db64904fe382c9d2cc5fd64cbd"
          }
        },
        "93c30fb7032042a89bb00bfb76227d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b39c5556b1f24899b5cefa480efe807a",
            "placeholder": "​",
            "style": "IPY_MODEL_41e80850ca504f56bcd573bf6aa7074e",
            "value": "Loading weights: 100%"
          }
        },
        "a93a0e87137e46aa90ba2bddfd39e793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67a8f36fadea42d6bd9a865f2c814563",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0be1f5e7a039423ab8f62e45e65ac0f1",
            "value": 199
          }
        },
        "7934042b97d64519bbfd2c652f37a7d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ec0b7d27cde4749984942e8bb70755c",
            "placeholder": "​",
            "style": "IPY_MODEL_71a6dbeec83548fcb39b7c0139d059e8",
            "value": " 199/199 [00:00&lt;00:00, 434.89it/s, Materializing param=bert.pooler.dense.weight]"
          }
        },
        "0572f9db64904fe382c9d2cc5fd64cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b39c5556b1f24899b5cefa480efe807a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41e80850ca504f56bcd573bf6aa7074e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67a8f36fadea42d6bd9a865f2c814563": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0be1f5e7a039423ab8f62e45e65ac0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ec0b7d27cde4749984942e8bb70755c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71a6dbeec83548fcb39b7c0139d059e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4a2e79af4a3449fb9005a00c42571b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82e437128f144a979d2540413af8033a",
              "IPY_MODEL_57ef6e43debf477d8c9ef4a9bd865c89",
              "IPY_MODEL_3f353029f9864a42ba227f56050942d4"
            ],
            "layout": "IPY_MODEL_6ef8e6c9e55740a6969313adfad6a5e1"
          }
        },
        "82e437128f144a979d2540413af8033a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e991329319f46cf9a5448694e06e235",
            "placeholder": "​",
            "style": "IPY_MODEL_9752741cab724acebb45d09dbcb53b1c",
            "value": "model.safetensors: 100%"
          }
        },
        "57ef6e43debf477d8c9ef4a9bd865c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5c9a06d444d467c9b37921f0292743f",
            "max": 435755888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_965b45be8da54415acb900691a7e8357",
            "value": 435755888
          }
        },
        "3f353029f9864a42ba227f56050942d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaaf52370e124c22bfb83b126c344be0",
            "placeholder": "​",
            "style": "IPY_MODEL_e6869bfc6222458199365dc81377cefd",
            "value": " 436M/436M [00:04&lt;00:00, 171MB/s]"
          }
        },
        "6ef8e6c9e55740a6969313adfad6a5e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e991329319f46cf9a5448694e06e235": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9752741cab724acebb45d09dbcb53b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5c9a06d444d467c9b37921f0292743f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "965b45be8da54415acb900691a7e8357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aaaf52370e124c22bfb83b126c344be0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6869bfc6222458199365dc81377cefd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qZLmQh2x4g3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e8284c-bddd-42a3-9e84-3d2f75da30fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique pathologies found: 49\n",
            "Alphabetical Classes: ['Acute COPD exacerbation / infection' 'Acute dystonic reactions'\n",
            " 'Acute laryngitis' 'Acute otitis media' 'Acute pulmonary edema']... (showing first 5)\n",
            "--------------------------------------------------\n",
            "Original Label (Row 0): PSVT\n",
            "Machine-Readable Vector (Row 0):\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Shape of the binary vector: (49,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# 1. Load the tiny sample in Colab\n",
        "df = pd.read_csv('tiny_train_sample.csv')\n",
        "\n",
        "# 2. Prepare the labels\n",
        "# The Binarizer expects a list of labels for each patient, even if it's just one disease.\n",
        "# We turn \"URTI\" into [\"URTI\"]\n",
        "df['TARGET_LIST'] = df['PATHOLOGY'].apply(lambda x: [x])\n",
        "\n",
        "# 3. Initialize and fit the Binarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "binary_labels = mlb.fit_transform(df['TARGET_LIST'])\n",
        "\n",
        "# 4. Let's analyze what the machine just did to Row 0\n",
        "print(f\"Total unique pathologies found: {len(mlb.classes_)}\")\n",
        "print(f\"Alphabetical Classes: {mlb.classes_[:5]}... (showing first 5)\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Original Label (Row 0): {df['PATHOLOGY'].iloc[0]}\")\n",
        "print(f\"Machine-Readable Vector (Row 0):\\n{binary_labels[0]}\")\n",
        "print(f\"Shape of the binary vector: {binary_labels[0].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab usually has transformers pre-installed, but let's be safe\n",
        "!pip install -q transformers\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 1. Download the pre-trained ClinicalBERT Tokenizer\n",
        "print(\"Downloading ClinicalBERT Tokenizer...\")\n",
        "model_checkpoint = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "# 2. Grab the text from Row 0\n",
        "sample_text = df['NARRATIVE'].iloc[0]\n",
        "print(\"\\n--- ORIGINAL TEXT ---\")\n",
        "print(sample_text)\n",
        "\n",
        "# 3. Pass the text through the Tokenizer\n",
        "# We use truncation=True and max_length=128 to keep things standard\n",
        "tokens = tokenizer(\n",
        "    sample_text,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    max_length=128,\n",
        "    return_tensors='pt' # This tells it to return PyTorch Tensors instead of standard Python lists\n",
        ")\n",
        "\n",
        "# 4. Let's analyze the mathematical output\n",
        "print(\"\\n--- THE MATHEMATICAL TRANSLATION ---\")\n",
        "print(f\"Shape of Input IDs: {tokens['input_ids'].shape}\")\n",
        "print(f\"First 15 Input IDs:\\n{tokens['input_ids'][0][:15]}\")\n",
        "print(f\"First 15 Attention Mask values:\\n{tokens['attention_mask'][0][:15]}\")\n",
        "\n",
        "# 5. Reverse-engineer it to see what the model actually sees!\n",
        "print(\"\\n--- REVERSE TRANSLATION (What the model reads) ---\")\n",
        "print(tokenizer.decode(tokens['input_ids'][0][:20]))"
      ],
      "metadata": {
        "id": "2h0jjh1U4kiA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448,
          "referenced_widgets": [
            "d1b9eab907a44e3b9df346cb8046b60d",
            "2b1915abe3b24a9bb21827afe7a0d4b4",
            "ad89a828b5bc40f290425269546a9ffe",
            "258acb4c6ec04f75a6ce763c4b3a65d5",
            "1c6c14742d9e4f109565e40e41beaadc",
            "f4bf9da1bc584daca5a7a26405931ec0",
            "1ead1cd41f6c4af699ab49efa716bf61",
            "b83b5299d34d45e69c6fd3c3c1d1aabe",
            "4d227de13ffb411780a21d809fd8d292",
            "ce663b4abb934d76ab2908b8993433e0",
            "3f0065bd4e044f848a6d1c84bc3a5ffd",
            "ea772c3144614428949245bc11ceaa2e",
            "3510aaf9aadf44dd8a181b44f8a070ec",
            "128b189a87004b3c9a0b2ca79b940981",
            "c4ea8254d5064fcd942c9d4f9c4dac67",
            "c5f531f5f5314016ac8f52f1786c78f0",
            "46973bf7f8b14e668c6a314fa4bf9e43",
            "2cdc34c881a947c3bb9fcaaa16ca03d3",
            "174e7a7d3fa24063a5566196f07ab61a",
            "a640367825614b98bfc2353b2c3a21c5",
            "edeed30a6dd24eb691b7e8347cae57ac",
            "fbeadce71da848f4824a5e290a035d67"
          ]
        },
        "outputId": "4abb9cc0-cbf9-44c6-e83d-463ad9dc8934"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ClinicalBERT Tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1b9eab907a44e3b9df346cb8046b60d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea772c3144614428949245bc11ceaa2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ORIGINAL TEXT ---\n",
            "I am an 27-year-old female. I came into the clinic today because I feel your heart is beating fast (racing), irregularly (missing a beat) or do you feel palpitations. I would describe the pain as haunting, tedious, a knife stroke, tugging, and heavy. The pain is specifically located in my. forehead. On a scale of 1 to 10, the intensity is 3. On a scale of 1 to 10, the precision of the pain location is a 4. Regarding how fast the pain appeared, on a scale of 1 to 10, it was a 5. No, I am not traveling out of the country recently. To give you more context: I have pain somewhere, related to your reason for consulting. I regularly take stimulant drugs. I am experiencing shortness of breath or difficulty breathing in a significant way. I feel lightheaded and dizzy or do you feel like you are about to faint. Regarding the question 'Have you recently taken decongestants or other substances that may have stimulant effects', my answer is\n",
            "\n",
            "--- THE MATHEMATICAL TRANSLATION ---\n",
            "Shape of Input IDs: torch.Size([1, 128])\n",
            "First 15 Input IDs:\n",
            "tensor([ 101,  146, 1821, 1126, 1765,  118, 1214,  118, 1385, 2130,  119,  146,\n",
            "        1338, 1154, 1103])\n",
            "First 15 Attention Mask values:\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "\n",
            "--- REVERSE TRANSLATION (What the model reads) ---\n",
            "[CLS] I am an 27 - year - old female. I came into the clinic today because I feel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DDXPlusDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, multilabel_binarizer, max_len=128):\n",
        "        # FIX 1: Reset the pandas index so row numbers are cleanly 0 to 9999\n",
        "        self.data = dataframe.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.mlb = multilabel_binarizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "        self.labels = self.mlb.transform(self.data['TARGET_LIST'])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        narrative = str(self.data.iloc[index]['NARRATIVE'])\n",
        "        label_vector = self.labels[index]\n",
        "\n",
        "        # FIX 2: Call the tokenizer directly (The modern Hugging Face way)\n",
        "        encoding = self.tokenizer(\n",
        "            narrative,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'targets': torch.tensor(label_vector, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "# --- TEST THE DATASET CLASS AGAIN ---\n",
        "print(\"Initializing the PyTorch Dataset...\")\n",
        "train_dataset = DDXPlusDataset(df, tokenizer, mlb, max_len=128)\n",
        "\n",
        "print(f\"Total items in dataset: {len(train_dataset)}\")\n",
        "\n",
        "# Let's ask PyTorch to grab Patient #500\n",
        "sample_item = train_dataset[500]\n",
        "\n",
        "print(\"\\n--- WHAT THE GPU RECEIVES FOR PATIENT #500 ---\")\n",
        "print(f\"Input IDs Shape: {sample_item['input_ids'].shape}\")\n",
        "print(f\"Attention Mask Shape: {sample_item['attention_mask'].shape}\")\n",
        "print(f\"Targets Shape: {sample_item['targets'].shape}\")\n",
        "print(f\"Target Vector snippet: {sample_item['targets'][:10]}\")"
      ],
      "metadata": {
        "id": "VArd-oBr4kfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b90d247a-eb51-4200-88da-518346da8291"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing the PyTorch Dataset...\n",
            "Total items in dataset: 10000\n",
            "\n",
            "--- WHAT THE GPU RECEIVES FOR PATIENT #500 ---\n",
            "Input IDs Shape: torch.Size([128])\n",
            "Attention Mask Shape: torch.Size([128])\n",
            "Targets Shape: torch.Size([49])\n",
            "Target Vector snippet: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# 1. Define our exact number of diseases\n",
        "num_classes = len(mlb.classes_) # This is 49\n",
        "\n",
        "print(\"Downloading ClinicalBERT Model Weights...\")\n",
        "# 2. Initialize the model with our custom configuration\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"emilyalsentzer/Bio_ClinicalBERT\",\n",
        "    num_labels=num_classes,\n",
        "    problem_type=\"multi_label_classification\" # This tells HF to prep for BCE Loss, not Softmax!\n",
        ")\n",
        "\n",
        "# 3. Detect the T4 GPU and move the model onto it\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"\\n--- MODEL ARCHITECTURE STATUS ---\")\n",
        "print(f\"Device connected: {device}\")\n",
        "print(f\"Number of output neurons in the final layer: {model.num_labels}\")"
      ],
      "metadata": {
        "id": "hhPXp-ji4kc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529,
          "referenced_widgets": [
            "8c55a1944e374630b1fe58fa45c02690",
            "18226ad2eea74a97a13538d93d51c9eb",
            "c7892fce676b48c6b56e0dec1d86bb9e",
            "d33b53f975be49f1b8e385bedf600259",
            "3715574f01b04e5bb3bdf43f11590dbf",
            "4bd5f75ee4954da7a8b6a67b122e6b3f",
            "99592e6a9e8543529993f4799c0f70b7",
            "007b4b127a524ea484cc3a472b133460",
            "0e911e3083fe4c17836d3421bfeba94e",
            "4cbb4af8e38b4a3d8811096c7abc14a5",
            "1b8871ffcec14e16b92cfecfd0520b20",
            "07b74df533464789a2497da9f4983dfb",
            "93c30fb7032042a89bb00bfb76227d51",
            "a93a0e87137e46aa90ba2bddfd39e793",
            "7934042b97d64519bbfd2c652f37a7d4",
            "0572f9db64904fe382c9d2cc5fd64cbd",
            "b39c5556b1f24899b5cefa480efe807a",
            "41e80850ca504f56bcd573bf6aa7074e",
            "67a8f36fadea42d6bd9a865f2c814563",
            "0be1f5e7a039423ab8f62e45e65ac0f1",
            "0ec0b7d27cde4749984942e8bb70755c",
            "71a6dbeec83548fcb39b7c0139d059e8",
            "f4a2e79af4a3449fb9005a00c42571b6",
            "82e437128f144a979d2540413af8033a",
            "57ef6e43debf477d8c9ef4a9bd865c89",
            "3f353029f9864a42ba227f56050942d4",
            "6ef8e6c9e55740a6969313adfad6a5e1",
            "5e991329319f46cf9a5448694e06e235",
            "9752741cab724acebb45d09dbcb53b1c",
            "e5c9a06d444d467c9b37921f0292743f",
            "965b45be8da54415acb900691a7e8357",
            "aaaf52370e124c22bfb83b126c344be0",
            "e6869bfc6222458199365dc81377cefd"
          ]
        },
        "outputId": "84c3679d-4098-43d4-9ba6-328ff54b6729"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ClinicalBERT Model Weights...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c55a1944e374630b1fe58fa45c02690"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07b74df533464789a2497da9f4983dfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForSequenceClassification LOAD REPORT from: emilyalsentzer/Bio_ClinicalBERT\n",
            "Key                                        | Status     | \n",
            "-------------------------------------------+------------+-\n",
            "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
            "cls.seq_relationship.bias                  | UNEXPECTED | \n",
            "cls.seq_relationship.weight                | UNEXPECTED | \n",
            "cls.predictions.decoder.weight             | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
            "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
            "cls.predictions.bias                       | UNEXPECTED | \n",
            "classifier.weight                          | MISSING    | \n",
            "classifier.bias                            | MISSING    | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4a2e79af4a3449fb9005a00c42571b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- MODEL ARCHITECTURE STATUS ---\n",
            "Device connected: cuda\n",
            "Number of output neurons in the final layer: 49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Split our 10,000 row sample into Train (80%) and Validation (20%)\n",
        "print(\"Splitting data into Training and Validation sets...\")\n",
        "df_train, df_val = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    stratify=df['PATHOLOGY'], # Ensures the 20% validation set has the same disease ratios\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2. Initialize our Custom PyTorch Datasets\n",
        "print(\"Initializing Datasets...\")\n",
        "train_dataset = DDXPlusDataset(df_train, tokenizer, mlb, max_len=128)\n",
        "val_dataset = DDXPlusDataset(df_val, tokenizer, mlb, max_len=128)\n",
        "\n",
        "print(f\"Training patients: {len(train_dataset)}\")\n",
        "print(f\"Validation patients: {len(val_dataset)}\")\n",
        "\n",
        "# 3. Create the DataLoaders (The \"Waiters\" for the GPU)\n",
        "# A batch size of 16 is perfectly safe for a T4 GPU with 128 max_len tokens\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# We shuffle the train loader so the model doesn't learn the order of the patients\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# 4. Let's peek at exactly one \"Tray\" of data going to the GPU\n",
        "first_batch = next(iter(train_loader))\n",
        "print(\"\\n--- FIRST BATCH TENSORS (TRAY OF 16 PATIENTS) ---\")\n",
        "print(f\"Input IDs shape: {first_batch['input_ids'].shape}\")\n",
        "print(f\"Attention Mask shape: {first_batch['attention_mask'].shape}\")\n",
        "print(f\"Targets shape: {first_batch['targets'].shape}\")"
      ],
      "metadata": {
        "id": "CJfNLzgL4kaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "657f7973-23a0-4eae-d2f3-9adce3e377dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting data into Training and Validation sets...\n",
            "Initializing Datasets...\n",
            "Training patients: 8000\n",
            "Validation patients: 2000\n",
            "\n",
            "--- FIRST BATCH TENSORS (TRAY OF 16 PATIENTS) ---\n",
            "Input IDs shape: torch.Size([16, 128])\n",
            "Attention Mask shape: torch.Size([16, 128])\n",
            "Targets shape: torch.Size([16, 49])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# 1. Define the Learning Engine\n",
        "# 2e-5 is the standard \"safe\" learning rate for fine-tuning BERT\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# 2. The Sanity Check (Forward Pass on 1 Batch)\n",
        "print(\"Passing the first batch of 16 patients into the untrained model...\")\n",
        "\n",
        "# Move the batch tensors to the GPU\n",
        "input_ids = first_batch['input_ids'].to(device)\n",
        "attention_mask = first_batch['attention_mask'].to(device)\n",
        "targets = first_batch['targets'].to(device)\n",
        "\n",
        "# Tell PyTorch we don't want to calculate gradients yet, just predict\n",
        "with torch.no_grad():\n",
        "    # Pass the text and masks into ClinicalBERT\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Extract the 49 output neurons (Logits)\n",
        "    logits = outputs.logits\n",
        "\n",
        "# 3. Calculate the initial Loss\n",
        "initial_loss = criterion(logits, targets)\n",
        "\n",
        "# 4. Let's look at the math!\n",
        "print(\"\\n--- SANITY CHECK RESULTS ---\")\n",
        "print(f\"Logits Shape (Should be 16, 49): {logits.shape}\")\n",
        "print(f\"Initial Untrained Loss: {initial_loss.item():.4f}\")\n",
        "\n",
        "# Look at the raw output numbers for the very first patient\n",
        "print(f\"\\nRaw Outputs (Logits) for Patient 0 (First 5 diseases):\\n{logits[0][:5]}\")\n",
        "\n",
        "# Apply Sigmoid to turn them into readable percentages (0% to 100%)\n",
        "probabilities = torch.sigmoid(logits)\n",
        "print(f\"\\nActual Probabilities for Patient 0 (First 5 diseases):\\n{probabilities[0][:5]}\")"
      ],
      "metadata": {
        "id": "fqWxwvuX4kXo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "ee955af2-e7bc-438f-ba04-d86da4d4e6ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passing the first batch of 16 patients into the untrained model...\n",
            "\n",
            "--- SANITY CHECK RESULTS ---\n",
            "Logits Shape (Should be 16, 49): torch.Size([16, 49])\n",
            "Initial Untrained Loss: 0.6967\n",
            "\n",
            "Raw Outputs (Logits) for Patient 0 (First 5 diseases):\n",
            "tensor([-0.1223,  0.1772, -0.7391, -0.1911, -0.2373], device='cuda:0')\n",
            "\n",
            "Actual Probabilities for Patient 0 (First 5 diseases):\n",
            "tensor([0.4695, 0.5442, 0.3232, 0.4524, 0.4410], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# We will train for 2 loops over the dataset to see if the loss goes down\n",
        "EPOCHS = 2\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\n======== Epoch {epoch+1} / {EPOCHS} ========\")\n",
        "\n",
        "    # ==========================================\n",
        "    #               TRAINING PHASE\n",
        "    # ==========================================\n",
        "    model.train() # Put model in training mode\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Create a progress bar for the training batches\n",
        "    train_loop = tqdm(train_loader, leave=True, desc=\"Training Batches\")\n",
        "\n",
        "    for batch in train_loop:\n",
        "        # 1. Clear old gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 2. Push the tray of data to the GPU\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        targets = batch['targets'].to(device)\n",
        "\n",
        "        # 3. Forward Pass (Make a guess)\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # 4. Calculate Loss (How wrong is it?)\n",
        "        loss = criterion(logits, targets)\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # 5. Backward Pass (Calculate the fixes)\n",
        "        loss.backward()\n",
        "\n",
        "        # 6. Optimizer Step (Apply the fixes to the weights)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the progress bar text with the current loss\n",
        "        train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    print(f\"\\n>>> Average Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # ==========================================\n",
        "    #              VALIDATION PHASE\n",
        "    # ==========================================\n",
        "    model.eval() # Put model in test mode (turns off dropout layers, prevents learning)\n",
        "    total_val_loss = 0\n",
        "\n",
        "    val_loop = tqdm(val_loader, leave=True, desc=\"Validation Batches\")\n",
        "\n",
        "    with torch.no_grad(): # Tell PyTorch to stop tracking gradients (saves massive memory)\n",
        "        for batch in val_loop:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            targets = batch['targets'].to(device)\n",
        "\n",
        "            # Make a guess\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, targets)\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "            val_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    print(f\"\\n>>> Average Validation Loss: {avg_val_loss:.4f}\")"
      ],
      "metadata": {
        "id": "fGUW9wUM4kVF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fb50337d-a6b5-454e-a11f-77f2782d861c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training Batches:   0%|          | 0/500 [00:00<?, ?it/s]\u001b[A\n",
            "Training Batches:   0%|          | 0/500 [00:01<?, ?it/s, loss=0.697]\u001b[A\n",
            "Training Batches:   0%|          | 1/500 [00:01<10:52,  1.31s/it, loss=0.697]\u001b[A\n",
            "Training Batches:   0%|          | 1/500 [00:01<10:52,  1.31s/it, loss=0.685]\u001b[A\n",
            "Training Batches:   0%|          | 2/500 [00:01<06:57,  1.19it/s, loss=0.685]\u001b[A\n",
            "Training Batches:   0%|          | 2/500 [00:02<06:57,  1.19it/s, loss=0.673]\u001b[A\n",
            "Training Batches:   1%|          | 3/500 [00:02<05:57,  1.39it/s, loss=0.673]\u001b[A\n",
            "Training Batches:   1%|          | 3/500 [00:02<05:57,  1.39it/s, loss=0.659]\u001b[A\n",
            "Training Batches:   1%|          | 4/500 [00:02<05:23,  1.53it/s, loss=0.659]\u001b[A\n",
            "Training Batches:   1%|          | 4/500 [00:03<05:23,  1.53it/s, loss=0.649]\u001b[A\n",
            "Training Batches:   1%|          | 5/500 [00:03<04:44,  1.74it/s, loss=0.649]\u001b[A\n",
            "Training Batches:   1%|          | 5/500 [00:03<04:44,  1.74it/s, loss=0.629]\u001b[A\n",
            "Training Batches:   1%|          | 6/500 [00:03<04:23,  1.87it/s, loss=0.629]\u001b[A\n",
            "Training Batches:   1%|          | 6/500 [00:04<04:23,  1.87it/s, loss=0.618]\u001b[A\n",
            "Training Batches:   1%|▏         | 7/500 [00:04<04:02,  2.03it/s, loss=0.618]\u001b[A\n",
            "Training Batches:   1%|▏         | 7/500 [00:04<04:02,  2.03it/s, loss=0.603]\u001b[A\n",
            "Training Batches:   2%|▏         | 8/500 [00:04<03:45,  2.19it/s, loss=0.603]\u001b[A\n",
            "Training Batches:   2%|▏         | 8/500 [00:05<03:45,  2.19it/s, loss=0.594]\u001b[A\n",
            "Training Batches:   2%|▏         | 9/500 [00:05<03:36,  2.27it/s, loss=0.594]\u001b[A\n",
            "Training Batches:   2%|▏         | 9/500 [00:05<03:36,  2.27it/s, loss=0.582]\u001b[A\n",
            "Training Batches:   2%|▏         | 10/500 [00:05<03:25,  2.38it/s, loss=0.582]\u001b[A\n",
            "Training Batches:   2%|▏         | 10/500 [00:05<03:25,  2.38it/s, loss=0.571]\u001b[A\n",
            "Training Batches:   2%|▏         | 11/500 [00:05<03:19,  2.46it/s, loss=0.571]\u001b[A\n",
            "Training Batches:   2%|▏         | 11/500 [00:06<03:19,  2.46it/s, loss=0.556]\u001b[A\n",
            "Training Batches:   2%|▏         | 12/500 [00:06<03:14,  2.52it/s, loss=0.556]\u001b[A\n",
            "Training Batches:   2%|▏         | 12/500 [00:06<03:14,  2.52it/s, loss=0.547]\u001b[A\n",
            "Training Batches:   3%|▎         | 13/500 [00:06<03:09,  2.57it/s, loss=0.547]\u001b[A\n",
            "Training Batches:   3%|▎         | 13/500 [00:06<03:09,  2.57it/s, loss=0.531]\u001b[A\n",
            "Training Batches:   3%|▎         | 14/500 [00:06<03:10,  2.55it/s, loss=0.531]\u001b[A\n",
            "Training Batches:   3%|▎         | 14/500 [00:07<03:10,  2.55it/s, loss=0.525]\u001b[A\n",
            "Training Batches:   3%|▎         | 15/500 [00:07<03:13,  2.51it/s, loss=0.525]\u001b[A\n",
            "Training Batches:   3%|▎         | 15/500 [00:07<03:13,  2.51it/s, loss=0.519]\u001b[A\n",
            "Training Batches:   3%|▎         | 16/500 [00:07<03:17,  2.46it/s, loss=0.519]\u001b[A\n",
            "Training Batches:   3%|▎         | 16/500 [00:08<03:17,  2.46it/s, loss=0.509]\u001b[A\n",
            "Training Batches:   3%|▎         | 17/500 [00:08<03:19,  2.42it/s, loss=0.509]\u001b[A\n",
            "Training Batches:   3%|▎         | 17/500 [00:08<03:19,  2.42it/s, loss=0.497]\u001b[A\n",
            "Training Batches:   4%|▎         | 18/500 [00:08<03:12,  2.50it/s, loss=0.497]\u001b[A\n",
            "Training Batches:   4%|▎         | 18/500 [00:08<03:12,  2.50it/s, loss=0.495]\u001b[A\n",
            "Training Batches:   4%|▍         | 19/500 [00:08<03:08,  2.55it/s, loss=0.495]\u001b[A\n",
            "Training Batches:   4%|▍         | 19/500 [00:09<03:08,  2.55it/s, loss=0.476]\u001b[A\n",
            "Training Batches:   4%|▍         | 20/500 [00:09<03:04,  2.60it/s, loss=0.476]\u001b[A\n",
            "Training Batches:   4%|▍         | 20/500 [00:09<03:04,  2.60it/s, loss=0.475]\u001b[A\n",
            "Training Batches:   4%|▍         | 21/500 [00:09<03:03,  2.61it/s, loss=0.475]\u001b[A\n",
            "Training Batches:   4%|▍         | 21/500 [00:10<03:03,  2.61it/s, loss=0.463]\u001b[A\n",
            "Training Batches:   4%|▍         | 22/500 [00:10<03:02,  2.62it/s, loss=0.463]\u001b[A\n",
            "Training Batches:   4%|▍         | 22/500 [00:10<03:02,  2.62it/s, loss=0.458]\u001b[A\n",
            "Training Batches:   5%|▍         | 23/500 [00:10<03:01,  2.62it/s, loss=0.458]\u001b[A\n",
            "Training Batches:   5%|▍         | 23/500 [00:10<03:01,  2.62it/s, loss=0.446]\u001b[A\n",
            "Training Batches:   5%|▍         | 24/500 [00:10<03:03,  2.59it/s, loss=0.446]\u001b[A\n",
            "Training Batches:   5%|▍         | 24/500 [00:11<03:03,  2.59it/s, loss=0.448]\u001b[A\n",
            "Training Batches:   5%|▌         | 25/500 [00:11<03:00,  2.63it/s, loss=0.448]\u001b[A\n",
            "Training Batches:   5%|▌         | 25/500 [00:11<03:00,  2.63it/s, loss=0.434]\u001b[A\n",
            "Training Batches:   5%|▌         | 26/500 [00:11<02:58,  2.66it/s, loss=0.434]\u001b[A\n",
            "Training Batches:   5%|▌         | 26/500 [00:11<02:58,  2.66it/s, loss=0.435]\u001b[A\n",
            "Training Batches:   5%|▌         | 27/500 [00:11<02:57,  2.66it/s, loss=0.435]\u001b[A\n",
            "Training Batches:   5%|▌         | 27/500 [00:12<02:57,  2.66it/s, loss=0.429]\u001b[A\n",
            "Training Batches:   6%|▌         | 28/500 [00:12<02:57,  2.66it/s, loss=0.429]\u001b[A\n",
            "Training Batches:   6%|▌         | 28/500 [00:12<02:57,  2.66it/s, loss=0.416]\u001b[A\n",
            "Training Batches:   6%|▌         | 29/500 [00:12<02:57,  2.65it/s, loss=0.416]\u001b[A\n",
            "Training Batches:   6%|▌         | 29/500 [00:13<02:57,  2.65it/s, loss=0.416]\u001b[A\n",
            "Training Batches:   6%|▌         | 30/500 [00:13<02:59,  2.62it/s, loss=0.416]\u001b[A\n",
            "Training Batches:   6%|▌         | 30/500 [00:13<02:59,  2.62it/s, loss=0.41] \u001b[A\n",
            "Training Batches:   6%|▌         | 31/500 [00:13<02:57,  2.64it/s, loss=0.41]\u001b[A\n",
            "Training Batches:   6%|▌         | 31/500 [00:13<02:57,  2.64it/s, loss=0.402]\u001b[A\n",
            "Training Batches:   6%|▋         | 32/500 [00:13<02:56,  2.64it/s, loss=0.402]\u001b[A\n",
            "Training Batches:   6%|▋         | 32/500 [00:14<02:56,  2.64it/s, loss=0.394]\u001b[A\n",
            "Training Batches:   7%|▋         | 33/500 [00:14<03:01,  2.57it/s, loss=0.394]\u001b[A\n",
            "Training Batches:   7%|▋         | 33/500 [00:14<03:01,  2.57it/s, loss=0.391]\u001b[A\n",
            "Training Batches:   7%|▋         | 34/500 [00:14<03:02,  2.55it/s, loss=0.391]\u001b[A\n",
            "Training Batches:   7%|▋         | 34/500 [00:15<03:02,  2.55it/s, loss=0.384]\u001b[A\n",
            "Training Batches:   7%|▋         | 35/500 [00:15<03:06,  2.50it/s, loss=0.384]\u001b[A\n",
            "Training Batches:   7%|▋         | 35/500 [00:15<03:06,  2.50it/s, loss=0.377]\u001b[A\n",
            "Training Batches:   7%|▋         | 36/500 [00:15<03:24,  2.27it/s, loss=0.377]\u001b[A\n",
            "Training Batches:   7%|▋         | 36/500 [00:16<03:24,  2.27it/s, loss=0.373]\u001b[A\n",
            "Training Batches:   7%|▋         | 37/500 [00:16<03:39,  2.11it/s, loss=0.373]\u001b[A\n",
            "Training Batches:   7%|▋         | 37/500 [00:16<03:39,  2.11it/s, loss=0.367]\u001b[A\n",
            "Training Batches:   8%|▊         | 38/500 [00:16<03:47,  2.03it/s, loss=0.367]\u001b[A\n",
            "Training Batches:   8%|▊         | 38/500 [00:17<03:47,  2.03it/s, loss=0.366]\u001b[A\n",
            "Training Batches:   8%|▊         | 39/500 [00:17<03:51,  1.99it/s, loss=0.366]\u001b[A\n",
            "Training Batches:   8%|▊         | 39/500 [00:17<03:51,  1.99it/s, loss=0.365]\u001b[A\n",
            "Training Batches:   8%|▊         | 40/500 [00:17<03:32,  2.16it/s, loss=0.365]\u001b[A\n",
            "Training Batches:   8%|▊         | 40/500 [00:17<03:32,  2.16it/s, loss=0.359]\u001b[A\n",
            "Training Batches:   8%|▊         | 41/500 [00:17<03:20,  2.29it/s, loss=0.359]\u001b[A\n",
            "Training Batches:   8%|▊         | 41/500 [00:18<03:20,  2.29it/s, loss=0.351]\u001b[A\n",
            "Training Batches:   8%|▊         | 42/500 [00:18<03:13,  2.37it/s, loss=0.351]\u001b[A\n",
            "Training Batches:   8%|▊         | 42/500 [00:18<03:13,  2.37it/s, loss=0.345]\u001b[A\n",
            "Training Batches:   9%|▊         | 43/500 [00:18<03:07,  2.44it/s, loss=0.345]\u001b[A\n",
            "Training Batches:   9%|▊         | 43/500 [00:19<03:07,  2.44it/s, loss=0.346]\u001b[A\n",
            "Training Batches:   9%|▉         | 44/500 [00:19<03:02,  2.50it/s, loss=0.346]\u001b[A\n",
            "Training Batches:   9%|▉         | 44/500 [00:19<03:02,  2.50it/s, loss=0.34] \u001b[A\n",
            "Training Batches:   9%|▉         | 45/500 [00:19<03:00,  2.52it/s, loss=0.34]\u001b[A\n",
            "Training Batches:   9%|▉         | 45/500 [00:19<03:00,  2.52it/s, loss=0.337]\u001b[A\n",
            "Training Batches:   9%|▉         | 46/500 [00:19<03:05,  2.45it/s, loss=0.337]\u001b[A\n",
            "Training Batches:   9%|▉         | 46/500 [00:20<03:05,  2.45it/s, loss=0.329]\u001b[A\n",
            "Training Batches:   9%|▉         | 47/500 [00:20<03:06,  2.43it/s, loss=0.329]\u001b[A\n",
            "Training Batches:   9%|▉         | 47/500 [00:20<03:06,  2.43it/s, loss=0.322]\u001b[A\n",
            "Training Batches:  10%|▉         | 48/500 [00:20<03:04,  2.46it/s, loss=0.322]\u001b[A\n",
            "Training Batches:  10%|▉         | 48/500 [00:21<03:04,  2.46it/s, loss=0.321]\u001b[A\n",
            "Training Batches:  10%|▉         | 49/500 [00:21<03:00,  2.50it/s, loss=0.321]\u001b[A\n",
            "Training Batches:  10%|▉         | 49/500 [00:21<03:00,  2.50it/s, loss=0.321]\u001b[A\n",
            "Training Batches:  10%|█         | 50/500 [00:21<03:01,  2.49it/s, loss=0.321]\u001b[A\n",
            "Training Batches:  10%|█         | 50/500 [00:21<03:01,  2.49it/s, loss=0.316]\u001b[A\n",
            "Training Batches:  10%|█         | 51/500 [00:21<02:59,  2.51it/s, loss=0.316]\u001b[A\n",
            "Training Batches:  10%|█         | 51/500 [00:22<02:59,  2.51it/s, loss=0.31] \u001b[A\n",
            "Training Batches:  10%|█         | 52/500 [00:22<02:59,  2.49it/s, loss=0.31]\u001b[A\n",
            "Training Batches:  10%|█         | 52/500 [00:22<02:59,  2.49it/s, loss=0.31]\u001b[A\n",
            "Training Batches:  11%|█         | 53/500 [00:22<02:57,  2.51it/s, loss=0.31]\u001b[A\n",
            "Training Batches:  11%|█         | 53/500 [00:23<02:57,  2.51it/s, loss=0.305]\u001b[A\n",
            "Training Batches:  11%|█         | 54/500 [00:23<02:56,  2.53it/s, loss=0.305]\u001b[A\n",
            "Training Batches:  11%|█         | 54/500 [00:23<02:56,  2.53it/s, loss=0.3]  \u001b[A\n",
            "Training Batches:  11%|█         | 55/500 [00:23<02:54,  2.56it/s, loss=0.3]\u001b[A\n",
            "Training Batches:  11%|█         | 55/500 [00:23<02:54,  2.56it/s, loss=0.298]\u001b[A\n",
            "Training Batches:  11%|█         | 56/500 [00:23<02:54,  2.55it/s, loss=0.298]\u001b[A\n",
            "Training Batches:  11%|█         | 56/500 [00:24<02:54,  2.55it/s, loss=0.291]\u001b[A\n",
            "Training Batches:  11%|█▏        | 57/500 [00:24<02:50,  2.59it/s, loss=0.291]\u001b[A\n",
            "Training Batches:  11%|█▏        | 57/500 [00:24<02:50,  2.59it/s, loss=0.291]\u001b[A\n",
            "Training Batches:  12%|█▏        | 58/500 [00:24<02:54,  2.53it/s, loss=0.291]\u001b[A\n",
            "Training Batches:  12%|█▏        | 58/500 [00:25<02:54,  2.53it/s, loss=0.286]\u001b[A\n",
            "Training Batches:  12%|█▏        | 59/500 [00:25<02:53,  2.55it/s, loss=0.286]\u001b[A\n",
            "Training Batches:  12%|█▏        | 59/500 [00:25<02:53,  2.55it/s, loss=0.279]\u001b[A\n",
            "Training Batches:  12%|█▏        | 60/500 [00:25<02:50,  2.58it/s, loss=0.279]\u001b[A\n",
            "Training Batches:  12%|█▏        | 60/500 [00:25<02:50,  2.58it/s, loss=0.274]\u001b[A\n",
            "Training Batches:  12%|█▏        | 61/500 [00:25<02:49,  2.59it/s, loss=0.274]\u001b[A\n",
            "Training Batches:  12%|█▏        | 61/500 [00:26<02:49,  2.59it/s, loss=0.277]\u001b[A\n",
            "Training Batches:  12%|█▏        | 62/500 [00:26<02:48,  2.60it/s, loss=0.277]\u001b[A\n",
            "Training Batches:  12%|█▏        | 62/500 [00:26<02:48,  2.60it/s, loss=0.279]\u001b[A\n",
            "Training Batches:  13%|█▎        | 63/500 [00:26<02:48,  2.59it/s, loss=0.279]\u001b[A\n",
            "Training Batches:  13%|█▎        | 63/500 [00:26<02:48,  2.59it/s, loss=0.268]\u001b[A\n",
            "Training Batches:  13%|█▎        | 64/500 [00:26<02:47,  2.60it/s, loss=0.268]\u001b[A\n",
            "Training Batches:  13%|█▎        | 64/500 [00:27<02:47,  2.60it/s, loss=0.268]\u001b[A\n",
            "Training Batches:  13%|█▎        | 65/500 [00:27<02:46,  2.61it/s, loss=0.268]\u001b[A\n",
            "Training Batches:  13%|█▎        | 65/500 [00:27<02:46,  2.61it/s, loss=0.263]\u001b[A\n",
            "Training Batches:  13%|█▎        | 66/500 [00:27<02:52,  2.52it/s, loss=0.263]\u001b[A\n",
            "Training Batches:  13%|█▎        | 66/500 [00:28<02:52,  2.52it/s, loss=0.265]\u001b[A\n",
            "Training Batches:  13%|█▎        | 67/500 [00:28<03:10,  2.27it/s, loss=0.265]\u001b[A\n",
            "Training Batches:  13%|█▎        | 67/500 [00:28<03:10,  2.27it/s, loss=0.256]\u001b[A\n",
            "Training Batches:  14%|█▎        | 68/500 [00:28<03:05,  2.33it/s, loss=0.256]\u001b[A\n",
            "Training Batches:  14%|█▎        | 68/500 [00:29<03:05,  2.33it/s, loss=0.258]\u001b[A\n",
            "Training Batches:  14%|█▍        | 69/500 [00:29<03:02,  2.36it/s, loss=0.258]\u001b[A\n",
            "Training Batches:  14%|█▍        | 69/500 [00:29<03:02,  2.36it/s, loss=0.251]\u001b[A\n",
            "Training Batches:  14%|█▍        | 70/500 [00:29<03:07,  2.29it/s, loss=0.251]\u001b[A\n",
            "Training Batches:  14%|█▍        | 70/500 [00:30<03:07,  2.29it/s, loss=0.249]\u001b[A\n",
            "Training Batches:  14%|█▍        | 71/500 [00:30<03:08,  2.28it/s, loss=0.249]\u001b[A\n",
            "Training Batches:  14%|█▍        | 71/500 [00:30<03:08,  2.28it/s, loss=0.245]\u001b[A\n",
            "Training Batches:  14%|█▍        | 72/500 [00:30<03:09,  2.26it/s, loss=0.245]\u001b[A\n",
            "Training Batches:  14%|█▍        | 72/500 [00:30<03:09,  2.26it/s, loss=0.243]\u001b[A\n",
            "Training Batches:  15%|█▍        | 73/500 [00:30<03:09,  2.26it/s, loss=0.243]\u001b[A\n",
            "Training Batches:  15%|█▍        | 73/500 [00:31<03:09,  2.26it/s, loss=0.239]\u001b[A\n",
            "Training Batches:  15%|█▍        | 74/500 [00:31<03:00,  2.36it/s, loss=0.239]\u001b[A\n",
            "Training Batches:  15%|█▍        | 74/500 [00:31<03:00,  2.36it/s, loss=0.238]\u001b[A\n",
            "Training Batches:  15%|█▌        | 75/500 [00:31<02:58,  2.39it/s, loss=0.238]\u001b[A\n",
            "Training Batches:  15%|█▌        | 75/500 [00:32<02:58,  2.39it/s, loss=0.236]\u001b[A\n",
            "Training Batches:  15%|█▌        | 76/500 [00:32<03:04,  2.30it/s, loss=0.236]\u001b[A\n",
            "Training Batches:  15%|█▌        | 76/500 [00:32<03:04,  2.30it/s, loss=0.233]\u001b[A\n",
            "Training Batches:  15%|█▌        | 77/500 [00:32<03:01,  2.33it/s, loss=0.233]\u001b[A\n",
            "Training Batches:  15%|█▌        | 77/500 [00:33<03:01,  2.33it/s, loss=0.227]\u001b[A\n",
            "Training Batches:  16%|█▌        | 78/500 [00:33<02:58,  2.37it/s, loss=0.227]\u001b[A\n",
            "Training Batches:  16%|█▌        | 78/500 [00:33<02:58,  2.37it/s, loss=0.227]\u001b[A\n",
            "Training Batches:  16%|█▌        | 79/500 [00:33<03:03,  2.29it/s, loss=0.227]\u001b[A\n",
            "Training Batches:  16%|█▌        | 79/500 [00:33<03:03,  2.29it/s, loss=0.226]\u001b[A\n",
            "Training Batches:  16%|█▌        | 80/500 [00:33<02:59,  2.34it/s, loss=0.226]\u001b[A\n",
            "Training Batches:  16%|█▌        | 80/500 [00:34<02:59,  2.34it/s, loss=0.221]\u001b[A\n",
            "Training Batches:  16%|█▌        | 81/500 [00:34<03:00,  2.33it/s, loss=0.221]\u001b[A\n",
            "Training Batches:  16%|█▌        | 81/500 [00:34<03:00,  2.33it/s, loss=0.218]\u001b[A\n",
            "Training Batches:  16%|█▋        | 82/500 [00:34<03:04,  2.27it/s, loss=0.218]\u001b[A\n",
            "Training Batches:  16%|█▋        | 82/500 [00:35<03:04,  2.27it/s, loss=0.215]\u001b[A\n",
            "Training Batches:  17%|█▋        | 83/500 [00:35<02:58,  2.34it/s, loss=0.215]\u001b[A\n",
            "Training Batches:  17%|█▋        | 83/500 [00:35<02:58,  2.34it/s, loss=0.213]\u001b[A\n",
            "Training Batches:  17%|█▋        | 84/500 [00:35<02:55,  2.37it/s, loss=0.213]\u001b[A\n",
            "Training Batches:  17%|█▋        | 84/500 [00:36<02:55,  2.37it/s, loss=0.215]\u001b[A\n",
            "Training Batches:  17%|█▋        | 85/500 [00:36<02:53,  2.39it/s, loss=0.215]\u001b[A\n",
            "Training Batches:  17%|█▋        | 85/500 [00:36<02:53,  2.39it/s, loss=0.209]\u001b[A\n",
            "Training Batches:  17%|█▋        | 86/500 [00:36<02:55,  2.36it/s, loss=0.209]\u001b[A\n",
            "Training Batches:  17%|█▋        | 86/500 [00:36<02:55,  2.36it/s, loss=0.208]\u001b[A\n",
            "Training Batches:  17%|█▋        | 87/500 [00:36<02:52,  2.39it/s, loss=0.208]\u001b[A\n",
            "Training Batches:  17%|█▋        | 87/500 [00:37<02:52,  2.39it/s, loss=0.209]\u001b[A\n",
            "Training Batches:  18%|█▊        | 88/500 [00:37<02:49,  2.43it/s, loss=0.209]\u001b[A\n",
            "Training Batches:  18%|█▊        | 88/500 [00:37<02:49,  2.43it/s, loss=0.203]\u001b[A\n",
            "Training Batches:  18%|█▊        | 89/500 [00:37<02:50,  2.40it/s, loss=0.203]\u001b[A\n",
            "Training Batches:  18%|█▊        | 89/500 [00:38<02:50,  2.40it/s, loss=0.205]\u001b[A\n",
            "Training Batches:  18%|█▊        | 90/500 [00:38<02:51,  2.40it/s, loss=0.205]\u001b[A\n",
            "Training Batches:  18%|█▊        | 90/500 [00:38<02:51,  2.40it/s, loss=0.198]\u001b[A\n",
            "Training Batches:  18%|█▊        | 91/500 [00:38<02:47,  2.44it/s, loss=0.198]\u001b[A\n",
            "Training Batches:  18%|█▊        | 91/500 [00:38<02:47,  2.44it/s, loss=0.202]\u001b[A\n",
            "Training Batches:  18%|█▊        | 92/500 [00:38<02:44,  2.47it/s, loss=0.202]\u001b[A\n",
            "Training Batches:  18%|█▊        | 92/500 [00:39<02:44,  2.47it/s, loss=0.198]\u001b[A\n",
            "Training Batches:  19%|█▊        | 93/500 [00:39<02:45,  2.46it/s, loss=0.198]\u001b[A\n",
            "Training Batches:  19%|█▊        | 93/500 [00:39<02:45,  2.46it/s, loss=0.196]\u001b[A\n",
            "Training Batches:  19%|█▉        | 94/500 [00:39<02:44,  2.46it/s, loss=0.196]\u001b[A\n",
            "Training Batches:  19%|█▉        | 94/500 [00:40<02:44,  2.46it/s, loss=0.196]\u001b[A\n",
            "Training Batches:  19%|█▉        | 95/500 [00:40<02:47,  2.42it/s, loss=0.196]\u001b[A\n",
            "Training Batches:  19%|█▉        | 95/500 [00:40<02:47,  2.42it/s, loss=0.193]\u001b[A\n",
            "Training Batches:  19%|█▉        | 96/500 [00:40<02:41,  2.51it/s, loss=0.193]\u001b[A\n",
            "Training Batches:  19%|█▉        | 96/500 [00:40<02:41,  2.51it/s, loss=0.185]\u001b[A\n",
            "Training Batches:  19%|█▉        | 97/500 [00:40<02:39,  2.53it/s, loss=0.185]\u001b[A\n",
            "Training Batches:  19%|█▉        | 97/500 [00:41<02:39,  2.53it/s, loss=0.188]\u001b[A\n",
            "Training Batches:  20%|█▉        | 98/500 [00:41<02:33,  2.62it/s, loss=0.188]\u001b[A\n",
            "Training Batches:  20%|█▉        | 98/500 [00:41<02:33,  2.62it/s, loss=0.187]\u001b[A\n",
            "Training Batches:  20%|█▉        | 99/500 [00:41<02:35,  2.58it/s, loss=0.187]\u001b[A\n",
            "Training Batches:  20%|█▉        | 99/500 [00:42<02:35,  2.58it/s, loss=0.183]\u001b[A\n",
            "Training Batches:  20%|██        | 100/500 [00:42<02:33,  2.60it/s, loss=0.183]\u001b[A\n",
            "Training Batches:  20%|██        | 100/500 [00:42<02:33,  2.60it/s, loss=0.182]\u001b[A\n",
            "Training Batches:  20%|██        | 101/500 [00:42<02:32,  2.61it/s, loss=0.182]\u001b[A\n",
            "Training Batches:  20%|██        | 101/500 [00:42<02:32,  2.61it/s, loss=0.182]\u001b[A\n",
            "Training Batches:  20%|██        | 102/500 [00:42<02:31,  2.62it/s, loss=0.182]\u001b[A\n",
            "Training Batches:  20%|██        | 102/500 [00:43<02:31,  2.62it/s, loss=0.179]\u001b[A\n",
            "Training Batches:  21%|██        | 103/500 [00:43<02:30,  2.64it/s, loss=0.179]\u001b[A\n",
            "Training Batches:  21%|██        | 103/500 [00:43<02:30,  2.64it/s, loss=0.181]\u001b[A\n",
            "Training Batches:  21%|██        | 104/500 [00:43<02:29,  2.65it/s, loss=0.181]\u001b[A\n",
            "Training Batches:  21%|██        | 104/500 [00:43<02:29,  2.65it/s, loss=0.18] \u001b[A\n",
            "Training Batches:  21%|██        | 105/500 [00:43<02:28,  2.66it/s, loss=0.18]\u001b[A\n",
            "Training Batches:  21%|██        | 105/500 [00:44<02:28,  2.66it/s, loss=0.176]\u001b[A\n",
            "Training Batches:  21%|██        | 106/500 [00:44<02:27,  2.66it/s, loss=0.176]\u001b[A\n",
            "Training Batches:  21%|██        | 106/500 [00:44<02:27,  2.66it/s, loss=0.175]\u001b[A\n",
            "Training Batches:  21%|██▏       | 107/500 [00:44<02:27,  2.66it/s, loss=0.175]\u001b[A\n",
            "Training Batches:  21%|██▏       | 107/500 [00:45<02:27,  2.66it/s, loss=0.172]\u001b[A\n",
            "Training Batches:  22%|██▏       | 108/500 [00:45<02:26,  2.67it/s, loss=0.172]\u001b[A\n",
            "Training Batches:  22%|██▏       | 108/500 [00:45<02:26,  2.67it/s, loss=0.172]\u001b[A\n",
            "Training Batches:  22%|██▏       | 109/500 [00:45<02:26,  2.66it/s, loss=0.172]\u001b[A\n",
            "Training Batches:  22%|██▏       | 109/500 [00:45<02:26,  2.66it/s, loss=0.171]\u001b[A\n",
            "Training Batches:  22%|██▏       | 110/500 [00:45<02:26,  2.67it/s, loss=0.171]\u001b[A\n",
            "Training Batches:  22%|██▏       | 110/500 [00:46<02:26,  2.67it/s, loss=0.171]\u001b[A\n",
            "Training Batches:  22%|██▏       | 111/500 [00:46<02:25,  2.66it/s, loss=0.171]\u001b[A\n",
            "Training Batches:  22%|██▏       | 111/500 [00:46<02:25,  2.66it/s, loss=0.167]\u001b[A\n",
            "Training Batches:  22%|██▏       | 112/500 [00:46<02:25,  2.67it/s, loss=0.167]\u001b[A\n",
            "Training Batches:  22%|██▏       | 112/500 [00:46<02:25,  2.67it/s, loss=0.17] \u001b[A\n",
            "Training Batches:  23%|██▎       | 113/500 [00:46<02:25,  2.66it/s, loss=0.17]\u001b[A\n",
            "Training Batches:  23%|██▎       | 113/500 [00:47<02:25,  2.66it/s, loss=0.166]\u001b[A\n",
            "Training Batches:  23%|██▎       | 114/500 [00:47<02:24,  2.66it/s, loss=0.166]\u001b[A\n",
            "Training Batches:  23%|██▎       | 114/500 [00:47<02:24,  2.66it/s, loss=0.166]\u001b[A\n",
            "Training Batches:  23%|██▎       | 115/500 [00:47<02:24,  2.66it/s, loss=0.166]\u001b[A\n",
            "Training Batches:  23%|██▎       | 115/500 [00:48<02:24,  2.66it/s, loss=0.165]\u001b[A\n",
            "Training Batches:  23%|██▎       | 116/500 [00:48<02:24,  2.65it/s, loss=0.165]\u001b[A\n",
            "Training Batches:  23%|██▎       | 116/500 [00:48<02:24,  2.65it/s, loss=0.162]\u001b[A\n",
            "Training Batches:  23%|██▎       | 117/500 [00:48<02:23,  2.66it/s, loss=0.162]\u001b[A\n",
            "Training Batches:  23%|██▎       | 117/500 [00:48<02:23,  2.66it/s, loss=0.161]\u001b[A\n",
            "Training Batches:  24%|██▎       | 118/500 [00:48<02:23,  2.66it/s, loss=0.161]\u001b[A\n",
            "Training Batches:  24%|██▎       | 118/500 [00:49<02:23,  2.66it/s, loss=0.162]\u001b[A\n",
            "Training Batches:  24%|██▍       | 119/500 [00:49<02:22,  2.67it/s, loss=0.162]\u001b[A\n",
            "Training Batches:  24%|██▍       | 119/500 [00:49<02:22,  2.67it/s, loss=0.161]\u001b[A\n",
            "Training Batches:  24%|██▍       | 120/500 [00:49<02:22,  2.67it/s, loss=0.161]\u001b[A\n",
            "Training Batches:  24%|██▍       | 120/500 [00:49<02:22,  2.67it/s, loss=0.16] \u001b[A\n",
            "Training Batches:  24%|██▍       | 121/500 [00:49<02:22,  2.67it/s, loss=0.16]\u001b[A\n",
            "Training Batches:  24%|██▍       | 121/500 [00:50<02:22,  2.67it/s, loss=0.158]\u001b[A\n",
            "Training Batches:  24%|██▍       | 122/500 [00:50<02:21,  2.66it/s, loss=0.158]\u001b[A\n",
            "Training Batches:  24%|██▍       | 122/500 [00:50<02:21,  2.66it/s, loss=0.159]\u001b[A\n",
            "Training Batches:  25%|██▍       | 123/500 [00:50<02:22,  2.64it/s, loss=0.159]\u001b[A\n",
            "Training Batches:  25%|██▍       | 123/500 [00:51<02:22,  2.64it/s, loss=0.157]\u001b[A\n",
            "Training Batches:  25%|██▍       | 124/500 [00:51<02:22,  2.63it/s, loss=0.157]\u001b[A\n",
            "Training Batches:  25%|██▍       | 124/500 [00:51<02:22,  2.63it/s, loss=0.158]\u001b[A\n",
            "Training Batches:  25%|██▌       | 125/500 [00:51<02:22,  2.64it/s, loss=0.158]\u001b[A\n",
            "Training Batches:  25%|██▌       | 125/500 [00:51<02:22,  2.64it/s, loss=0.154]\u001b[A\n",
            "Training Batches:  25%|██▌       | 126/500 [00:51<02:21,  2.64it/s, loss=0.154]\u001b[A\n",
            "Training Batches:  25%|██▌       | 126/500 [00:52<02:21,  2.64it/s, loss=0.152]\u001b[A\n",
            "Training Batches:  25%|██▌       | 127/500 [00:52<02:20,  2.65it/s, loss=0.152]\u001b[A\n",
            "Training Batches:  25%|██▌       | 127/500 [00:52<02:20,  2.65it/s, loss=0.152]\u001b[A\n",
            "Training Batches:  26%|██▌       | 128/500 [00:52<02:20,  2.65it/s, loss=0.152]\u001b[A\n",
            "Training Batches:  26%|██▌       | 128/500 [00:52<02:20,  2.65it/s, loss=0.151]\u001b[A\n",
            "Training Batches:  26%|██▌       | 129/500 [00:52<02:21,  2.62it/s, loss=0.151]\u001b[A\n",
            "Training Batches:  26%|██▌       | 129/500 [00:53<02:21,  2.62it/s, loss=0.15] \u001b[A\n",
            "Training Batches:  26%|██▌       | 130/500 [00:53<02:22,  2.60it/s, loss=0.15]\u001b[A\n",
            "Training Batches:  26%|██▌       | 130/500 [00:53<02:22,  2.60it/s, loss=0.149]\u001b[A\n",
            "Training Batches:  26%|██▌       | 131/500 [00:53<02:22,  2.59it/s, loss=0.149]\u001b[A\n",
            "Training Batches:  26%|██▌       | 131/500 [00:54<02:22,  2.59it/s, loss=0.149]\u001b[A\n",
            "Training Batches:  26%|██▋       | 132/500 [00:54<02:23,  2.56it/s, loss=0.149]\u001b[A\n",
            "Training Batches:  26%|██▋       | 132/500 [00:54<02:23,  2.56it/s, loss=0.151]\u001b[A\n",
            "Training Batches:  27%|██▋       | 133/500 [00:54<02:22,  2.57it/s, loss=0.151]\u001b[A\n",
            "Training Batches:  27%|██▋       | 133/500 [00:54<02:22,  2.57it/s, loss=0.15] \u001b[A\n",
            "Training Batches:  27%|██▋       | 134/500 [00:54<02:22,  2.56it/s, loss=0.15]\u001b[A\n",
            "Training Batches:  27%|██▋       | 134/500 [00:55<02:22,  2.56it/s, loss=0.146]\u001b[A\n",
            "Training Batches:  27%|██▋       | 135/500 [00:55<02:20,  2.59it/s, loss=0.146]\u001b[A\n",
            "Training Batches:  27%|██▋       | 135/500 [00:55<02:20,  2.59it/s, loss=0.147]\u001b[A\n",
            "Training Batches:  27%|██▋       | 136/500 [00:55<02:20,  2.59it/s, loss=0.147]\u001b[A\n",
            "Training Batches:  27%|██▋       | 136/500 [00:56<02:20,  2.59it/s, loss=0.151]\u001b[A\n",
            "Training Batches:  27%|██▋       | 137/500 [00:56<02:18,  2.62it/s, loss=0.151]\u001b[A\n",
            "Training Batches:  27%|██▋       | 137/500 [00:56<02:18,  2.62it/s, loss=0.145]\u001b[A\n",
            "Training Batches:  28%|██▊       | 138/500 [00:56<02:18,  2.62it/s, loss=0.145]\u001b[A\n",
            "Training Batches:  28%|██▊       | 138/500 [00:56<02:18,  2.62it/s, loss=0.145]\u001b[A\n",
            "Training Batches:  28%|██▊       | 139/500 [00:56<02:17,  2.62it/s, loss=0.145]\u001b[A\n",
            "Training Batches:  28%|██▊       | 139/500 [00:57<02:17,  2.62it/s, loss=0.147]\u001b[A\n",
            "Training Batches:  28%|██▊       | 140/500 [00:57<02:17,  2.62it/s, loss=0.147]\u001b[A\n",
            "Training Batches:  28%|██▊       | 140/500 [00:57<02:17,  2.62it/s, loss=0.144]\u001b[A\n",
            "Training Batches:  28%|██▊       | 141/500 [00:57<02:16,  2.64it/s, loss=0.144]\u001b[A\n",
            "Training Batches:  28%|██▊       | 141/500 [00:57<02:16,  2.64it/s, loss=0.143]\u001b[A\n",
            "Training Batches:  28%|██▊       | 142/500 [00:57<02:17,  2.61it/s, loss=0.143]\u001b[A\n",
            "Training Batches:  28%|██▊       | 142/500 [00:58<02:17,  2.61it/s, loss=0.143]\u001b[A\n",
            "Training Batches:  29%|██▊       | 143/500 [00:58<02:17,  2.59it/s, loss=0.143]\u001b[A\n",
            "Training Batches:  29%|██▊       | 143/500 [00:58<02:17,  2.59it/s, loss=0.142]\u001b[A\n",
            "Training Batches:  29%|██▉       | 144/500 [00:58<02:17,  2.60it/s, loss=0.142]\u001b[A\n",
            "Training Batches:  29%|██▉       | 144/500 [00:59<02:17,  2.60it/s, loss=0.143]\u001b[A\n",
            "Training Batches:  29%|██▉       | 145/500 [00:59<02:16,  2.60it/s, loss=0.143]\u001b[A\n",
            "Training Batches:  29%|██▉       | 145/500 [00:59<02:16,  2.60it/s, loss=0.141]\u001b[A\n",
            "Training Batches:  29%|██▉       | 146/500 [00:59<02:15,  2.62it/s, loss=0.141]\u001b[A\n",
            "Training Batches:  29%|██▉       | 146/500 [00:59<02:15,  2.62it/s, loss=0.138]\u001b[A\n",
            "Training Batches:  29%|██▉       | 147/500 [00:59<02:14,  2.62it/s, loss=0.138]\u001b[A\n",
            "Training Batches:  29%|██▉       | 147/500 [01:00<02:14,  2.62it/s, loss=0.137]\u001b[A\n",
            "Training Batches:  30%|██▉       | 148/500 [01:00<02:13,  2.63it/s, loss=0.137]\u001b[A\n",
            "Training Batches:  30%|██▉       | 148/500 [01:00<02:13,  2.63it/s, loss=0.137]\u001b[A\n",
            "Training Batches:  30%|██▉       | 149/500 [01:00<02:14,  2.62it/s, loss=0.137]\u001b[A\n",
            "Training Batches:  30%|██▉       | 149/500 [01:01<02:14,  2.62it/s, loss=0.139]\u001b[A\n",
            "Training Batches:  30%|███       | 150/500 [01:01<02:13,  2.62it/s, loss=0.139]\u001b[A\n",
            "Training Batches:  30%|███       | 150/500 [01:01<02:13,  2.62it/s, loss=0.141]\u001b[A\n",
            "Training Batches:  30%|███       | 151/500 [01:01<02:12,  2.63it/s, loss=0.141]\u001b[A\n",
            "Training Batches:  30%|███       | 151/500 [01:01<02:12,  2.63it/s, loss=0.139]\u001b[A\n",
            "Training Batches:  30%|███       | 152/500 [01:01<02:12,  2.63it/s, loss=0.139]\u001b[A\n",
            "Training Batches:  30%|███       | 152/500 [01:02<02:12,  2.63it/s, loss=0.137]\u001b[A\n",
            "Training Batches:  31%|███       | 153/500 [01:02<02:12,  2.62it/s, loss=0.137]\u001b[A\n",
            "Training Batches:  31%|███       | 153/500 [01:02<02:12,  2.62it/s, loss=0.136]\u001b[A\n",
            "Training Batches:  31%|███       | 154/500 [01:02<02:12,  2.62it/s, loss=0.136]\u001b[A\n",
            "Training Batches:  31%|███       | 154/500 [01:02<02:12,  2.62it/s, loss=0.137]\u001b[A\n",
            "Training Batches:  31%|███       | 155/500 [01:02<02:12,  2.61it/s, loss=0.137]\u001b[A\n",
            "Training Batches:  31%|███       | 155/500 [01:03<02:12,  2.61it/s, loss=0.135]\u001b[A\n",
            "Training Batches:  31%|███       | 156/500 [01:03<02:12,  2.60it/s, loss=0.135]\u001b[A\n",
            "Training Batches:  31%|███       | 156/500 [01:03<02:12,  2.60it/s, loss=0.136]\u001b[A\n",
            "Training Batches:  31%|███▏      | 157/500 [01:03<02:12,  2.60it/s, loss=0.136]\u001b[A\n",
            "Training Batches:  31%|███▏      | 157/500 [01:04<02:12,  2.60it/s, loss=0.134]\u001b[A\n",
            "Training Batches:  32%|███▏      | 158/500 [01:04<02:11,  2.60it/s, loss=0.134]\u001b[A\n",
            "Training Batches:  32%|███▏      | 158/500 [01:04<02:11,  2.60it/s, loss=0.134]\u001b[A\n",
            "Training Batches:  32%|███▏      | 159/500 [01:04<02:11,  2.60it/s, loss=0.134]\u001b[A\n",
            "Training Batches:  32%|███▏      | 159/500 [01:04<02:11,  2.60it/s, loss=0.132]\u001b[A\n",
            "Training Batches:  32%|███▏      | 160/500 [01:04<02:10,  2.60it/s, loss=0.132]\u001b[A\n",
            "Training Batches:  32%|███▏      | 160/500 [01:05<02:10,  2.60it/s, loss=0.132]\u001b[A\n",
            "Training Batches:  32%|███▏      | 161/500 [01:05<02:12,  2.56it/s, loss=0.132]\u001b[A\n",
            "Training Batches:  32%|███▏      | 161/500 [01:05<02:12,  2.56it/s, loss=0.134]\u001b[A\n",
            "Training Batches:  32%|███▏      | 162/500 [01:05<02:12,  2.54it/s, loss=0.134]\u001b[A\n",
            "Training Batches:  32%|███▏      | 162/500 [01:06<02:12,  2.54it/s, loss=0.13] \u001b[A\n",
            "Training Batches:  33%|███▎      | 163/500 [01:06<02:13,  2.52it/s, loss=0.13]\u001b[A\n",
            "Training Batches:  33%|███▎      | 163/500 [01:06<02:13,  2.52it/s, loss=0.133]\u001b[A\n",
            "Training Batches:  33%|███▎      | 164/500 [01:06<02:12,  2.53it/s, loss=0.133]\u001b[A\n",
            "Training Batches:  33%|███▎      | 164/500 [01:06<02:12,  2.53it/s, loss=0.132]\u001b[A\n",
            "Training Batches:  33%|███▎      | 165/500 [01:06<02:13,  2.51it/s, loss=0.132]\u001b[A\n",
            "Training Batches:  33%|███▎      | 165/500 [01:07<02:13,  2.51it/s, loss=0.13] \u001b[A\n",
            "Training Batches:  33%|███▎      | 166/500 [01:07<02:13,  2.50it/s, loss=0.13]\u001b[A\n",
            "Training Batches:  33%|███▎      | 166/500 [01:07<02:13,  2.50it/s, loss=0.131]\u001b[A\n",
            "Training Batches:  33%|███▎      | 167/500 [01:07<02:12,  2.52it/s, loss=0.131]\u001b[A\n",
            "Training Batches:  33%|███▎      | 167/500 [01:08<02:12,  2.52it/s, loss=0.128]\u001b[A\n",
            "Training Batches:  34%|███▎      | 168/500 [01:08<02:11,  2.53it/s, loss=0.128]\u001b[A\n",
            "Training Batches:  34%|███▎      | 168/500 [01:08<02:11,  2.53it/s, loss=0.13] \u001b[A\n",
            "Training Batches:  34%|███▍      | 169/500 [01:08<02:07,  2.60it/s, loss=0.13]\u001b[A\n",
            "Training Batches:  34%|███▍      | 169/500 [01:08<02:07,  2.60it/s, loss=0.129]\u001b[A\n",
            "Training Batches:  34%|███▍      | 170/500 [01:08<02:07,  2.59it/s, loss=0.129]\u001b[A\n",
            "Training Batches:  34%|███▍      | 170/500 [01:09<02:07,  2.59it/s, loss=0.126]\u001b[A\n",
            "Training Batches:  34%|███▍      | 171/500 [01:09<02:07,  2.58it/s, loss=0.126]\u001b[A\n",
            "Training Batches:  34%|███▍      | 171/500 [01:09<02:07,  2.58it/s, loss=0.126]\u001b[A\n",
            "Training Batches:  34%|███▍      | 172/500 [01:09<02:06,  2.59it/s, loss=0.126]\u001b[A\n",
            "Training Batches:  34%|███▍      | 172/500 [01:09<02:06,  2.59it/s, loss=0.125]\u001b[A\n",
            "Training Batches:  35%|███▍      | 173/500 [01:09<02:06,  2.58it/s, loss=0.125]\u001b[A\n",
            "Training Batches:  35%|███▍      | 173/500 [01:10<02:06,  2.58it/s, loss=0.13] \u001b[A\n",
            "Training Batches:  35%|███▍      | 174/500 [01:10<02:06,  2.59it/s, loss=0.13]\u001b[A\n",
            "Training Batches:  35%|███▍      | 174/500 [01:10<02:06,  2.59it/s, loss=0.126]\u001b[A\n",
            "Training Batches:  35%|███▌      | 175/500 [01:10<02:06,  2.57it/s, loss=0.126]\u001b[A\n",
            "Training Batches:  35%|███▌      | 175/500 [01:11<02:06,  2.57it/s, loss=0.127]\u001b[A\n",
            "Training Batches:  35%|███▌      | 176/500 [01:11<02:06,  2.57it/s, loss=0.127]\u001b[A\n",
            "Training Batches:  35%|███▌      | 176/500 [01:11<02:06,  2.57it/s, loss=0.126]\u001b[A\n",
            "Training Batches:  35%|███▌      | 177/500 [01:11<02:05,  2.58it/s, loss=0.126]\u001b[A\n",
            "Training Batches:  35%|███▌      | 177/500 [01:11<02:05,  2.58it/s, loss=0.126]\u001b[A\n",
            "Training Batches:  36%|███▌      | 178/500 [01:11<02:05,  2.56it/s, loss=0.126]\u001b[A\n",
            "Training Batches:  36%|███▌      | 178/500 [01:12<02:05,  2.56it/s, loss=0.128]\u001b[A\n",
            "Training Batches:  36%|███▌      | 179/500 [01:12<02:05,  2.56it/s, loss=0.128]\u001b[A\n",
            "Training Batches:  36%|███▌      | 179/500 [01:12<02:05,  2.56it/s, loss=0.124]\u001b[A\n",
            "Training Batches:  36%|███▌      | 180/500 [01:12<02:05,  2.55it/s, loss=0.124]\u001b[A\n",
            "Training Batches:  36%|███▌      | 180/500 [01:13<02:05,  2.55it/s, loss=0.125]\u001b[A\n",
            "Training Batches:  36%|███▌      | 181/500 [01:13<02:05,  2.55it/s, loss=0.125]\u001b[A\n",
            "Training Batches:  36%|███▌      | 181/500 [01:13<02:05,  2.55it/s, loss=0.123]\u001b[A\n",
            "Training Batches:  36%|███▋      | 182/500 [01:13<02:04,  2.55it/s, loss=0.123]\u001b[A\n",
            "Training Batches:  36%|███▋      | 182/500 [01:13<02:04,  2.55it/s, loss=0.125]\u001b[A\n",
            "Training Batches:  37%|███▋      | 183/500 [01:13<02:04,  2.56it/s, loss=0.125]\u001b[A\n",
            "Training Batches:  37%|███▋      | 183/500 [01:14<02:04,  2.56it/s, loss=0.125]\u001b[A\n",
            "Training Batches:  37%|███▋      | 184/500 [01:14<02:03,  2.55it/s, loss=0.125]\u001b[A\n",
            "Training Batches:  37%|███▋      | 184/500 [01:14<02:03,  2.55it/s, loss=0.123]\u001b[A\n",
            "Training Batches:  37%|███▋      | 185/500 [01:14<02:03,  2.55it/s, loss=0.123]\u001b[A\n",
            "Training Batches:  37%|███▋      | 185/500 [01:15<02:03,  2.55it/s, loss=0.124]\u001b[A\n",
            "Training Batches:  37%|███▋      | 186/500 [01:15<02:02,  2.56it/s, loss=0.124]\u001b[A\n",
            "Training Batches:  37%|███▋      | 186/500 [01:15<02:02,  2.56it/s, loss=0.122]\u001b[A\n",
            "Training Batches:  37%|███▋      | 187/500 [01:15<02:02,  2.55it/s, loss=0.122]\u001b[A\n",
            "Training Batches:  37%|███▋      | 187/500 [01:15<02:02,  2.55it/s, loss=0.12] \u001b[A\n",
            "Training Batches:  38%|███▊      | 188/500 [01:15<02:02,  2.55it/s, loss=0.12]\u001b[A\n",
            "Training Batches:  38%|███▊      | 188/500 [01:16<02:02,  2.55it/s, loss=0.123]\u001b[A\n",
            "Training Batches:  38%|███▊      | 189/500 [01:16<02:02,  2.53it/s, loss=0.123]\u001b[A\n",
            "Training Batches:  38%|███▊      | 189/500 [01:16<02:02,  2.53it/s, loss=0.125]\u001b[A\n",
            "Training Batches:  38%|███▊      | 190/500 [01:16<02:01,  2.54it/s, loss=0.125]\u001b[A\n",
            "Training Batches:  38%|███▊      | 190/500 [01:17<02:01,  2.54it/s, loss=0.122]\u001b[A\n",
            "Training Batches:  38%|███▊      | 191/500 [01:17<02:02,  2.52it/s, loss=0.122]\u001b[A\n",
            "Training Batches:  38%|███▊      | 191/500 [01:17<02:02,  2.52it/s, loss=0.125]\u001b[A\n",
            "Training Batches:  38%|███▊      | 192/500 [01:17<02:02,  2.51it/s, loss=0.125]\u001b[A\n",
            "Training Batches:  38%|███▊      | 192/500 [01:17<02:02,  2.51it/s, loss=0.121]\u001b[A\n",
            "Training Batches:  39%|███▊      | 193/500 [01:17<02:02,  2.50it/s, loss=0.121]\u001b[A\n",
            "Training Batches:  39%|███▊      | 193/500 [01:18<02:02,  2.50it/s, loss=0.121]\u001b[A\n",
            "Training Batches:  39%|███▉      | 194/500 [01:18<02:02,  2.49it/s, loss=0.121]\u001b[A\n",
            "Training Batches:  39%|███▉      | 194/500 [01:18<02:02,  2.49it/s, loss=0.121]\u001b[A\n",
            "Training Batches:  39%|███▉      | 195/500 [01:18<02:02,  2.49it/s, loss=0.121]\u001b[A\n",
            "Training Batches:  39%|███▉      | 195/500 [01:19<02:02,  2.49it/s, loss=0.122]\u001b[A\n",
            "Training Batches:  39%|███▉      | 196/500 [01:19<02:02,  2.47it/s, loss=0.122]\u001b[A\n",
            "Training Batches:  39%|███▉      | 196/500 [01:19<02:02,  2.47it/s, loss=0.121]\u001b[A\n",
            "Training Batches:  39%|███▉      | 197/500 [01:19<02:02,  2.48it/s, loss=0.121]\u001b[A\n",
            "Training Batches:  39%|███▉      | 197/500 [01:19<02:02,  2.48it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  40%|███▉      | 198/500 [01:19<02:00,  2.50it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  40%|███▉      | 198/500 [01:20<02:00,  2.50it/s, loss=0.123]\u001b[A\n",
            "Training Batches:  40%|███▉      | 199/500 [01:20<02:00,  2.50it/s, loss=0.123]\u001b[A\n",
            "Training Batches:  40%|███▉      | 199/500 [01:20<02:00,  2.50it/s, loss=0.12] \u001b[A\n",
            "Training Batches:  40%|████      | 200/500 [01:20<02:00,  2.49it/s, loss=0.12]\u001b[A\n",
            "Training Batches:  40%|████      | 200/500 [01:21<02:00,  2.49it/s, loss=0.119]\u001b[A\n",
            "Training Batches:  40%|████      | 201/500 [01:21<02:00,  2.49it/s, loss=0.119]\u001b[A\n",
            "Training Batches:  40%|████      | 201/500 [01:21<02:00,  2.49it/s, loss=0.119]\u001b[A\n",
            "Training Batches:  40%|████      | 202/500 [01:21<01:59,  2.49it/s, loss=0.119]\u001b[A\n",
            "Training Batches:  40%|████      | 202/500 [01:21<01:59,  2.49it/s, loss=0.119]\u001b[A\n",
            "Training Batches:  41%|████      | 203/500 [01:21<01:59,  2.49it/s, loss=0.119]\u001b[A\n",
            "Training Batches:  41%|████      | 203/500 [01:22<01:59,  2.49it/s, loss=0.119]\u001b[A\n",
            "Training Batches:  41%|████      | 204/500 [01:22<01:59,  2.47it/s, loss=0.119]\u001b[A\n",
            "Training Batches:  41%|████      | 204/500 [01:22<01:59,  2.47it/s, loss=0.119]\u001b[A\n",
            "Training Batches:  41%|████      | 205/500 [01:22<01:59,  2.48it/s, loss=0.119]\u001b[A\n",
            "Training Batches:  41%|████      | 205/500 [01:23<01:59,  2.48it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  41%|████      | 206/500 [01:23<01:58,  2.48it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  41%|████      | 206/500 [01:23<01:58,  2.48it/s, loss=0.119]\u001b[A\n",
            "Training Batches:  41%|████▏     | 207/500 [01:23<01:57,  2.49it/s, loss=0.119]\u001b[A\n",
            "Training Batches:  41%|████▏     | 207/500 [01:23<01:57,  2.49it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  42%|████▏     | 208/500 [01:23<01:57,  2.48it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  42%|████▏     | 208/500 [01:24<01:57,  2.48it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  42%|████▏     | 209/500 [01:24<01:57,  2.47it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  42%|████▏     | 209/500 [01:24<01:57,  2.47it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  42%|████▏     | 210/500 [01:24<01:57,  2.46it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  42%|████▏     | 210/500 [01:25<01:57,  2.46it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  42%|████▏     | 211/500 [01:25<01:57,  2.47it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  42%|████▏     | 211/500 [01:25<01:57,  2.47it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  42%|████▏     | 212/500 [01:25<01:56,  2.47it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  42%|████▏     | 212/500 [01:25<01:56,  2.47it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  43%|████▎     | 213/500 [01:25<01:56,  2.47it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  43%|████▎     | 213/500 [01:26<01:56,  2.47it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  43%|████▎     | 214/500 [01:26<01:55,  2.48it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  43%|████▎     | 214/500 [01:26<01:55,  2.48it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  43%|████▎     | 215/500 [01:26<01:54,  2.49it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  43%|████▎     | 215/500 [01:27<01:54,  2.49it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  43%|████▎     | 216/500 [01:27<01:54,  2.49it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  43%|████▎     | 216/500 [01:27<01:54,  2.49it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  43%|████▎     | 217/500 [01:27<01:54,  2.48it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  43%|████▎     | 217/500 [01:27<01:54,  2.48it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  44%|████▎     | 218/500 [01:27<01:54,  2.47it/s, loss=0.117]\u001b[A\n",
            "Training Batches:  44%|████▎     | 218/500 [01:28<01:54,  2.47it/s, loss=0.115]\u001b[A\n",
            "Training Batches:  44%|████▍     | 219/500 [01:28<01:54,  2.45it/s, loss=0.115]\u001b[A\n",
            "Training Batches:  44%|████▍     | 219/500 [01:28<01:54,  2.45it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  44%|████▍     | 220/500 [01:28<01:54,  2.45it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  44%|████▍     | 220/500 [01:29<01:54,  2.45it/s, loss=0.114]\u001b[A\n",
            "Training Batches:  44%|████▍     | 221/500 [01:29<01:54,  2.44it/s, loss=0.114]\u001b[A\n",
            "Training Batches:  44%|████▍     | 221/500 [01:29<01:54,  2.44it/s, loss=0.113]\u001b[A\n",
            "Training Batches:  44%|████▍     | 222/500 [01:29<01:53,  2.45it/s, loss=0.113]\u001b[A\n",
            "Training Batches:  44%|████▍     | 222/500 [01:29<01:53,  2.45it/s, loss=0.118]\u001b[A\n",
            "Training Batches:  45%|████▍     | 223/500 [01:29<01:53,  2.44it/s, loss=0.118]\u001b[A\n",
            "Training Batches:  45%|████▍     | 223/500 [01:30<01:53,  2.44it/s, loss=0.115]\u001b[A\n",
            "Training Batches:  45%|████▍     | 224/500 [01:30<01:53,  2.43it/s, loss=0.115]\u001b[A\n",
            "Training Batches:  45%|████▍     | 224/500 [01:30<01:53,  2.43it/s, loss=0.114]\u001b[A\n",
            "Training Batches:  45%|████▌     | 225/500 [01:30<01:52,  2.45it/s, loss=0.114]\u001b[A\n",
            "Training Batches:  45%|████▌     | 225/500 [01:31<01:52,  2.45it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  45%|████▌     | 226/500 [01:31<01:52,  2.43it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  45%|████▌     | 226/500 [01:31<01:52,  2.43it/s, loss=0.114]\u001b[A\n",
            "Training Batches:  45%|████▌     | 227/500 [01:31<01:53,  2.41it/s, loss=0.114]\u001b[A\n",
            "Training Batches:  45%|████▌     | 227/500 [01:32<01:53,  2.41it/s, loss=0.113]\u001b[A\n",
            "Training Batches:  46%|████▌     | 228/500 [01:32<01:52,  2.42it/s, loss=0.113]\u001b[A\n",
            "Training Batches:  46%|████▌     | 228/500 [01:32<01:52,  2.42it/s, loss=0.112]\u001b[A\n",
            "Training Batches:  46%|████▌     | 229/500 [01:32<01:51,  2.43it/s, loss=0.112]\u001b[A\n",
            "Training Batches:  46%|████▌     | 229/500 [01:32<01:51,  2.43it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  46%|████▌     | 230/500 [01:32<01:51,  2.43it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  46%|████▌     | 230/500 [01:33<01:51,  2.43it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  46%|████▌     | 231/500 [01:33<01:50,  2.44it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  46%|████▌     | 231/500 [01:33<01:50,  2.44it/s, loss=0.11] \u001b[A\n",
            "Training Batches:  46%|████▋     | 232/500 [01:33<01:50,  2.42it/s, loss=0.11]\u001b[A\n",
            "Training Batches:  46%|████▋     | 232/500 [01:34<01:50,  2.42it/s, loss=0.112]\u001b[A\n",
            "Training Batches:  47%|████▋     | 233/500 [01:34<01:50,  2.42it/s, loss=0.112]\u001b[A\n",
            "Training Batches:  47%|████▋     | 233/500 [01:34<01:50,  2.42it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  47%|████▋     | 234/500 [01:34<01:49,  2.43it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  47%|████▋     | 234/500 [01:34<01:49,  2.43it/s, loss=0.113]\u001b[A\n",
            "Training Batches:  47%|████▋     | 235/500 [01:34<01:49,  2.43it/s, loss=0.113]\u001b[A\n",
            "Training Batches:  47%|████▋     | 235/500 [01:35<01:49,  2.43it/s, loss=0.113]\u001b[A\n",
            "Training Batches:  47%|████▋     | 236/500 [01:35<01:47,  2.47it/s, loss=0.113]\u001b[A\n",
            "Training Batches:  47%|████▋     | 236/500 [01:35<01:47,  2.47it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  47%|████▋     | 237/500 [01:35<01:46,  2.46it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  47%|████▋     | 237/500 [01:36<01:46,  2.46it/s, loss=0.112]\u001b[A\n",
            "Training Batches:  48%|████▊     | 238/500 [01:36<01:46,  2.45it/s, loss=0.112]\u001b[A\n",
            "Training Batches:  48%|████▊     | 238/500 [01:36<01:46,  2.45it/s, loss=0.11] \u001b[A\n",
            "Training Batches:  48%|████▊     | 239/500 [01:36<01:46,  2.44it/s, loss=0.11]\u001b[A\n",
            "Training Batches:  48%|████▊     | 239/500 [01:36<01:46,  2.44it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  48%|████▊     | 240/500 [01:36<01:44,  2.49it/s, loss=0.116]\u001b[A\n",
            "Training Batches:  48%|████▊     | 240/500 [01:37<01:44,  2.49it/s, loss=0.11] \u001b[A\n",
            "Training Batches:  48%|████▊     | 241/500 [01:37<01:44,  2.48it/s, loss=0.11]\u001b[A\n",
            "Training Batches:  48%|████▊     | 241/500 [01:37<01:44,  2.48it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  48%|████▊     | 242/500 [01:37<01:44,  2.47it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  48%|████▊     | 242/500 [01:38<01:44,  2.47it/s, loss=0.114]\u001b[A\n",
            "Training Batches:  49%|████▊     | 243/500 [01:38<01:44,  2.47it/s, loss=0.114]\u001b[A\n",
            "Training Batches:  49%|████▊     | 243/500 [01:38<01:44,  2.47it/s, loss=0.112]\u001b[A\n",
            "Training Batches:  49%|████▉     | 244/500 [01:38<01:43,  2.47it/s, loss=0.112]\u001b[A\n",
            "Training Batches:  49%|████▉     | 244/500 [01:38<01:43,  2.47it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  49%|████▉     | 245/500 [01:38<01:43,  2.46it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  49%|████▉     | 245/500 [01:39<01:43,  2.46it/s, loss=0.112]\u001b[A\n",
            "Training Batches:  49%|████▉     | 246/500 [01:39<01:43,  2.44it/s, loss=0.112]\u001b[A\n",
            "Training Batches:  49%|████▉     | 246/500 [01:39<01:43,  2.44it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  49%|████▉     | 247/500 [01:39<01:43,  2.45it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  49%|████▉     | 247/500 [01:40<01:43,  2.45it/s, loss=0.11] \u001b[A\n",
            "Training Batches:  50%|████▉     | 248/500 [01:40<01:43,  2.44it/s, loss=0.11]\u001b[A\n",
            "Training Batches:  50%|████▉     | 248/500 [01:40<01:43,  2.44it/s, loss=0.112]\u001b[A\n",
            "Training Batches:  50%|████▉     | 249/500 [01:40<01:42,  2.45it/s, loss=0.112]\u001b[A\n",
            "Training Batches:  50%|████▉     | 249/500 [01:41<01:42,  2.45it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  50%|█████     | 250/500 [01:41<01:41,  2.46it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  50%|█████     | 250/500 [01:41<01:41,  2.46it/s, loss=0.11] \u001b[A\n",
            "Training Batches:  50%|█████     | 251/500 [01:41<01:41,  2.45it/s, loss=0.11]\u001b[A\n",
            "Training Batches:  50%|█████     | 251/500 [01:41<01:41,  2.45it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  50%|█████     | 252/500 [01:41<01:41,  2.45it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  50%|█████     | 252/500 [01:42<01:41,  2.45it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  51%|█████     | 253/500 [01:42<01:41,  2.43it/s, loss=0.111]\u001b[A\n",
            "Training Batches:  51%|█████     | 253/500 [01:42<01:41,  2.43it/s, loss=0.11] \u001b[A\n",
            "Training Batches:  51%|█████     | 254/500 [01:42<01:42,  2.40it/s, loss=0.11]\u001b[A\n",
            "Training Batches:  51%|█████     | 254/500 [01:43<01:42,  2.40it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  51%|█████     | 255/500 [01:43<01:41,  2.40it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  51%|█████     | 255/500 [01:43<01:41,  2.40it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  51%|█████     | 256/500 [01:43<01:41,  2.42it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  51%|█████     | 256/500 [01:43<01:41,  2.42it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  51%|█████▏    | 257/500 [01:43<01:40,  2.42it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  51%|█████▏    | 257/500 [01:44<01:40,  2.42it/s, loss=0.11] \u001b[A\n",
            "Training Batches:  52%|█████▏    | 258/500 [01:44<01:39,  2.42it/s, loss=0.11]\u001b[A\n",
            "Training Batches:  52%|█████▏    | 258/500 [01:44<01:39,  2.42it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  52%|█████▏    | 259/500 [01:44<01:39,  2.42it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  52%|█████▏    | 259/500 [01:45<01:39,  2.42it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  52%|█████▏    | 260/500 [01:45<01:38,  2.45it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  52%|█████▏    | 260/500 [01:45<01:38,  2.45it/s, loss=0.108]\u001b[A\n",
            "Training Batches:  52%|█████▏    | 261/500 [01:45<01:37,  2.44it/s, loss=0.108]\u001b[A\n",
            "Training Batches:  52%|█████▏    | 261/500 [01:45<01:37,  2.44it/s, loss=0.108]\u001b[A\n",
            "Training Batches:  52%|█████▏    | 262/500 [01:45<01:37,  2.43it/s, loss=0.108]\u001b[A\n",
            "Training Batches:  52%|█████▏    | 262/500 [01:46<01:37,  2.43it/s, loss=0.11] \u001b[A\n",
            "Training Batches:  53%|█████▎    | 263/500 [01:46<01:37,  2.44it/s, loss=0.11]\u001b[A\n",
            "Training Batches:  53%|█████▎    | 263/500 [01:46<01:37,  2.44it/s, loss=0.11]\u001b[A\n",
            "Training Batches:  53%|█████▎    | 264/500 [01:46<01:36,  2.45it/s, loss=0.11]\u001b[A\n",
            "Training Batches:  53%|█████▎    | 264/500 [01:47<01:36,  2.45it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  53%|█████▎    | 265/500 [01:47<01:36,  2.45it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  53%|█████▎    | 265/500 [01:47<01:36,  2.45it/s, loss=0.11] \u001b[A\n",
            "Training Batches:  53%|█████▎    | 266/500 [01:47<01:35,  2.45it/s, loss=0.11]\u001b[A\n",
            "Training Batches:  53%|█████▎    | 266/500 [01:47<01:35,  2.45it/s, loss=0.11]\u001b[A\n",
            "Training Batches:  53%|█████▎    | 267/500 [01:48<01:35,  2.45it/s, loss=0.11]\u001b[A\n",
            "Training Batches:  53%|█████▎    | 267/500 [01:48<01:35,  2.45it/s, loss=0.108]\u001b[A\n",
            "Training Batches:  54%|█████▎    | 268/500 [01:48<01:34,  2.45it/s, loss=0.108]\u001b[A\n",
            "Training Batches:  54%|█████▎    | 268/500 [01:48<01:34,  2.45it/s, loss=0.108]\u001b[A\n",
            "Training Batches:  54%|█████▍    | 269/500 [01:48<01:34,  2.44it/s, loss=0.108]\u001b[A\n",
            "Training Batches:  54%|█████▍    | 269/500 [01:49<01:34,  2.44it/s, loss=0.108]\u001b[A\n",
            "Training Batches:  54%|█████▍    | 270/500 [01:49<01:35,  2.41it/s, loss=0.108]\u001b[A\n",
            "Training Batches:  54%|█████▍    | 270/500 [01:49<01:35,  2.41it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  54%|█████▍    | 271/500 [01:49<01:34,  2.42it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  54%|█████▍    | 271/500 [01:50<01:34,  2.42it/s, loss=0.11] \u001b[A\n",
            "Training Batches:  54%|█████▍    | 272/500 [01:50<01:34,  2.42it/s, loss=0.11]\u001b[A\n",
            "Training Batches:  54%|█████▍    | 272/500 [01:50<01:34,  2.42it/s, loss=0.108]\u001b[A\n",
            "Training Batches:  55%|█████▍    | 273/500 [01:50<01:33,  2.42it/s, loss=0.108]\u001b[A\n",
            "Training Batches:  55%|█████▍    | 273/500 [01:50<01:33,  2.42it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  55%|█████▍    | 274/500 [01:50<01:32,  2.43it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  55%|█████▍    | 274/500 [01:51<01:32,  2.43it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  55%|█████▌    | 275/500 [01:51<01:33,  2.41it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  55%|█████▌    | 275/500 [01:51<01:33,  2.41it/s, loss=0.108]\u001b[A\n",
            "Training Batches:  55%|█████▌    | 276/500 [01:51<01:32,  2.41it/s, loss=0.108]\u001b[A\n",
            "Training Batches:  55%|█████▌    | 276/500 [01:52<01:32,  2.41it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  55%|█████▌    | 277/500 [01:52<01:32,  2.41it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  55%|█████▌    | 277/500 [01:52<01:32,  2.41it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  56%|█████▌    | 278/500 [01:52<01:31,  2.43it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  56%|█████▌    | 278/500 [01:52<01:31,  2.43it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  56%|█████▌    | 279/500 [01:52<01:31,  2.41it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  56%|█████▌    | 279/500 [01:53<01:31,  2.41it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  56%|█████▌    | 280/500 [01:53<01:31,  2.42it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  56%|█████▌    | 280/500 [01:53<01:31,  2.42it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  56%|█████▌    | 281/500 [01:53<01:30,  2.42it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  56%|█████▌    | 281/500 [01:54<01:30,  2.42it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  56%|█████▋    | 282/500 [01:54<01:30,  2.42it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  56%|█████▋    | 282/500 [01:54<01:30,  2.42it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  57%|█████▋    | 283/500 [01:54<01:30,  2.41it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  57%|█████▋    | 283/500 [01:55<01:30,  2.41it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  57%|█████▋    | 284/500 [01:55<01:29,  2.42it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  57%|█████▋    | 284/500 [01:55<01:29,  2.42it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  57%|█████▋    | 285/500 [01:55<01:28,  2.42it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  57%|█████▋    | 285/500 [01:55<01:28,  2.42it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  57%|█████▋    | 286/500 [01:55<01:29,  2.40it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  57%|█████▋    | 286/500 [01:56<01:29,  2.40it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  57%|█████▋    | 287/500 [01:56<01:29,  2.38it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  57%|█████▋    | 287/500 [01:56<01:29,  2.38it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  58%|█████▊    | 288/500 [01:56<01:28,  2.39it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  58%|█████▊    | 288/500 [01:57<01:28,  2.39it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  58%|█████▊    | 289/500 [01:57<01:28,  2.38it/s, loss=0.109]\u001b[A\n",
            "Training Batches:  58%|█████▊    | 289/500 [01:57<01:28,  2.38it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  58%|█████▊    | 290/500 [01:57<01:27,  2.40it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  58%|█████▊    | 290/500 [01:57<01:27,  2.40it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  58%|█████▊    | 291/500 [01:57<01:27,  2.40it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  58%|█████▊    | 291/500 [01:58<01:27,  2.40it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  58%|█████▊    | 292/500 [01:58<01:26,  2.41it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  58%|█████▊    | 292/500 [01:58<01:26,  2.41it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  59%|█████▊    | 293/500 [01:58<01:26,  2.40it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  59%|█████▊    | 293/500 [01:59<01:26,  2.40it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  59%|█████▉    | 294/500 [01:59<01:25,  2.40it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  59%|█████▉    | 294/500 [01:59<01:25,  2.40it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  59%|█████▉    | 295/500 [01:59<01:25,  2.40it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  59%|█████▉    | 295/500 [02:00<01:25,  2.40it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  59%|█████▉    | 296/500 [02:00<01:24,  2.40it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  59%|█████▉    | 296/500 [02:00<01:24,  2.40it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  59%|█████▉    | 297/500 [02:00<01:24,  2.40it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  59%|█████▉    | 297/500 [02:00<01:24,  2.40it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  60%|█████▉    | 298/500 [02:00<01:24,  2.39it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  60%|█████▉    | 298/500 [02:01<01:24,  2.39it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  60%|█████▉    | 299/500 [02:01<01:24,  2.39it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  60%|█████▉    | 299/500 [02:01<01:24,  2.39it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  60%|██████    | 300/500 [02:01<01:23,  2.39it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  60%|██████    | 300/500 [02:02<01:23,  2.39it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  60%|██████    | 301/500 [02:02<01:23,  2.39it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  60%|██████    | 301/500 [02:02<01:23,  2.39it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  60%|██████    | 302/500 [02:02<01:23,  2.37it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  60%|██████    | 302/500 [02:02<01:23,  2.37it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  61%|██████    | 303/500 [02:02<01:23,  2.37it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  61%|██████    | 303/500 [02:03<01:23,  2.37it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  61%|██████    | 304/500 [02:03<01:23,  2.36it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  61%|██████    | 304/500 [02:03<01:23,  2.36it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  61%|██████    | 305/500 [02:03<01:22,  2.36it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  61%|██████    | 305/500 [02:04<01:22,  2.36it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  61%|██████    | 306/500 [02:04<01:22,  2.36it/s, loss=0.107]\u001b[A\n",
            "Training Batches:  61%|██████    | 306/500 [02:04<01:22,  2.36it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  61%|██████▏   | 307/500 [02:04<01:21,  2.36it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  61%|██████▏   | 307/500 [02:05<01:21,  2.36it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  62%|██████▏   | 308/500 [02:05<01:21,  2.35it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  62%|██████▏   | 308/500 [02:05<01:21,  2.35it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  62%|██████▏   | 309/500 [02:05<01:21,  2.35it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  62%|██████▏   | 309/500 [02:05<01:21,  2.35it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  62%|██████▏   | 310/500 [02:05<01:20,  2.35it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  62%|██████▏   | 310/500 [02:06<01:20,  2.35it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  62%|██████▏   | 311/500 [02:06<01:20,  2.36it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  62%|██████▏   | 311/500 [02:06<01:20,  2.36it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  62%|██████▏   | 312/500 [02:06<01:19,  2.35it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  62%|██████▏   | 312/500 [02:07<01:19,  2.35it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  63%|██████▎   | 313/500 [02:07<01:19,  2.35it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  63%|██████▎   | 313/500 [02:07<01:19,  2.35it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  63%|██████▎   | 314/500 [02:07<01:19,  2.35it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  63%|██████▎   | 314/500 [02:08<01:19,  2.35it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  63%|██████▎   | 315/500 [02:08<01:18,  2.34it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  63%|██████▎   | 315/500 [02:08<01:18,  2.34it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  63%|██████▎   | 316/500 [02:08<01:18,  2.34it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  63%|██████▎   | 316/500 [02:08<01:18,  2.34it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  63%|██████▎   | 317/500 [02:08<01:18,  2.33it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  63%|██████▎   | 317/500 [02:09<01:18,  2.33it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  64%|██████▎   | 318/500 [02:09<01:18,  2.33it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  64%|██████▎   | 318/500 [02:09<01:18,  2.33it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  64%|██████▍   | 319/500 [02:09<01:17,  2.34it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  64%|██████▍   | 319/500 [02:10<01:17,  2.34it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  64%|██████▍   | 320/500 [02:10<01:17,  2.33it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  64%|██████▍   | 320/500 [02:10<01:17,  2.33it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  64%|██████▍   | 321/500 [02:10<01:17,  2.31it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  64%|██████▍   | 321/500 [02:11<01:17,  2.31it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  64%|██████▍   | 322/500 [02:11<01:16,  2.32it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  64%|██████▍   | 322/500 [02:11<01:16,  2.32it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  65%|██████▍   | 323/500 [02:11<01:15,  2.33it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  65%|██████▍   | 323/500 [02:11<01:15,  2.33it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  65%|██████▍   | 324/500 [02:11<01:13,  2.40it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  65%|██████▍   | 324/500 [02:12<01:13,  2.40it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  65%|██████▌   | 325/500 [02:12<01:13,  2.38it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  65%|██████▌   | 325/500 [02:12<01:13,  2.38it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  65%|██████▌   | 326/500 [02:12<01:13,  2.37it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  65%|██████▌   | 326/500 [02:13<01:13,  2.37it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  65%|██████▌   | 327/500 [02:13<01:13,  2.34it/s, loss=0.106]\u001b[A\n",
            "Training Batches:  65%|██████▌   | 327/500 [02:13<01:13,  2.34it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  66%|██████▌   | 328/500 [02:13<01:13,  2.34it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  66%|██████▌   | 328/500 [02:14<01:13,  2.34it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  66%|██████▌   | 329/500 [02:14<01:13,  2.34it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  66%|██████▌   | 329/500 [02:14<01:13,  2.34it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  66%|██████▌   | 330/500 [02:14<01:13,  2.32it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  66%|██████▌   | 330/500 [02:14<01:13,  2.32it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  66%|██████▌   | 331/500 [02:14<01:12,  2.33it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  66%|██████▌   | 331/500 [02:15<01:12,  2.33it/s, loss=0.1]  \u001b[A\n",
            "Training Batches:  66%|██████▋   | 332/500 [02:15<01:12,  2.33it/s, loss=0.1]\u001b[A\n",
            "Training Batches:  66%|██████▋   | 332/500 [02:15<01:12,  2.33it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  67%|██████▋   | 333/500 [02:15<01:12,  2.31it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  67%|██████▋   | 333/500 [02:16<01:12,  2.31it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  67%|██████▋   | 334/500 [02:16<01:11,  2.32it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  67%|██████▋   | 334/500 [02:16<01:11,  2.32it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  67%|██████▋   | 335/500 [02:16<01:11,  2.30it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  67%|██████▋   | 335/500 [02:17<01:11,  2.30it/s, loss=0.1]  \u001b[A\n",
            "Training Batches:  67%|██████▋   | 336/500 [02:17<01:12,  2.27it/s, loss=0.1]\u001b[A\n",
            "Training Batches:  67%|██████▋   | 336/500 [02:17<01:12,  2.27it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  67%|██████▋   | 337/500 [02:17<01:19,  2.06it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  67%|██████▋   | 337/500 [02:18<01:19,  2.06it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  68%|██████▊   | 338/500 [02:18<01:20,  2.00it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  68%|██████▊   | 338/500 [02:18<01:20,  2.00it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  68%|██████▊   | 339/500 [02:18<01:24,  1.91it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  68%|██████▊   | 339/500 [02:19<01:24,  1.91it/s, loss=0.1]  \u001b[A\n",
            "Training Batches:  68%|██████▊   | 340/500 [02:19<01:24,  1.89it/s, loss=0.1]\u001b[A\n",
            "Training Batches:  68%|██████▊   | 340/500 [02:19<01:24,  1.89it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  68%|██████▊   | 341/500 [02:19<01:26,  1.85it/s, loss=0.105]\u001b[A\n",
            "Training Batches:  68%|██████▊   | 341/500 [02:20<01:26,  1.85it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  68%|██████▊   | 342/500 [02:20<01:27,  1.81it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  68%|██████▊   | 342/500 [02:21<01:27,  1.81it/s, loss=0.0997]\u001b[A\n",
            "Training Batches:  69%|██████▊   | 343/500 [02:21<01:26,  1.82it/s, loss=0.0997]\u001b[A\n",
            "Training Batches:  69%|██████▊   | 343/500 [02:21<01:26,  1.82it/s, loss=0.0992]\u001b[A\n",
            "Training Batches:  69%|██████▉   | 344/500 [02:21<01:20,  1.93it/s, loss=0.0992]\u001b[A\n",
            "Training Batches:  69%|██████▉   | 344/500 [02:21<01:20,  1.93it/s, loss=0.101] \u001b[A\n",
            "Training Batches:  69%|██████▉   | 345/500 [02:21<01:16,  2.01it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  69%|██████▉   | 345/500 [02:22<01:16,  2.01it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  69%|██████▉   | 346/500 [02:22<01:14,  2.08it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  69%|██████▉   | 346/500 [02:22<01:14,  2.08it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  69%|██████▉   | 347/500 [02:22<01:11,  2.13it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  69%|██████▉   | 347/500 [02:23<01:11,  2.13it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  70%|██████▉   | 348/500 [02:23<01:10,  2.16it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  70%|██████▉   | 348/500 [02:23<01:10,  2.16it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  70%|██████▉   | 349/500 [02:23<01:08,  2.19it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  70%|██████▉   | 349/500 [02:24<01:08,  2.19it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  70%|███████   | 350/500 [02:24<01:08,  2.20it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  70%|███████   | 350/500 [02:24<01:08,  2.20it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  70%|███████   | 351/500 [02:24<01:07,  2.22it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  70%|███████   | 351/500 [02:25<01:07,  2.22it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  70%|███████   | 352/500 [02:25<01:06,  2.23it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  70%|███████   | 352/500 [02:25<01:06,  2.23it/s, loss=0.0986]\u001b[A\n",
            "Training Batches:  71%|███████   | 353/500 [02:25<01:05,  2.23it/s, loss=0.0986]\u001b[A\n",
            "Training Batches:  71%|███████   | 353/500 [02:25<01:05,  2.23it/s, loss=0.101] \u001b[A\n",
            "Training Batches:  71%|███████   | 354/500 [02:25<01:05,  2.24it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  71%|███████   | 354/500 [02:26<01:05,  2.24it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  71%|███████   | 355/500 [02:26<01:04,  2.24it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  71%|███████   | 355/500 [02:26<01:04,  2.24it/s, loss=0.0998]\u001b[A\n",
            "Training Batches:  71%|███████   | 356/500 [02:26<01:04,  2.24it/s, loss=0.0998]\u001b[A\n",
            "Training Batches:  71%|███████   | 356/500 [02:27<01:04,  2.24it/s, loss=0.101] \u001b[A\n",
            "Training Batches:  71%|███████▏  | 357/500 [02:27<01:03,  2.25it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  71%|███████▏  | 357/500 [02:27<01:03,  2.25it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  72%|███████▏  | 358/500 [02:27<01:03,  2.24it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  72%|███████▏  | 358/500 [02:28<01:03,  2.24it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  72%|███████▏  | 359/500 [02:28<01:02,  2.25it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  72%|███████▏  | 359/500 [02:28<01:02,  2.25it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  72%|███████▏  | 360/500 [02:28<01:02,  2.25it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  72%|███████▏  | 360/500 [02:29<01:02,  2.25it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  72%|███████▏  | 361/500 [02:29<01:01,  2.25it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  72%|███████▏  | 361/500 [02:29<01:01,  2.25it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  72%|███████▏  | 362/500 [02:29<01:01,  2.25it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  72%|███████▏  | 362/500 [02:29<01:01,  2.25it/s, loss=0.0982]\u001b[A\n",
            "Training Batches:  73%|███████▎  | 363/500 [02:29<01:00,  2.25it/s, loss=0.0982]\u001b[A\n",
            "Training Batches:  73%|███████▎  | 363/500 [02:30<01:00,  2.25it/s, loss=0.1]   \u001b[A\n",
            "Training Batches:  73%|███████▎  | 364/500 [02:30<01:00,  2.25it/s, loss=0.1]\u001b[A\n",
            "Training Batches:  73%|███████▎  | 364/500 [02:30<01:00,  2.25it/s, loss=0.0973]\u001b[A\n",
            "Training Batches:  73%|███████▎  | 365/500 [02:30<01:00,  2.25it/s, loss=0.0973]\u001b[A\n",
            "Training Batches:  73%|███████▎  | 365/500 [02:31<01:00,  2.25it/s, loss=0.102] \u001b[A\n",
            "Training Batches:  73%|███████▎  | 366/500 [02:31<00:59,  2.25it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  73%|███████▎  | 366/500 [02:31<00:59,  2.25it/s, loss=0.0994]\u001b[A\n",
            "Training Batches:  73%|███████▎  | 367/500 [02:31<00:59,  2.22it/s, loss=0.0994]\u001b[A\n",
            "Training Batches:  73%|███████▎  | 367/500 [02:32<00:59,  2.22it/s, loss=0.0986]\u001b[A\n",
            "Training Batches:  74%|███████▎  | 368/500 [02:32<00:59,  2.24it/s, loss=0.0986]\u001b[A\n",
            "Training Batches:  74%|███████▎  | 368/500 [02:32<00:59,  2.24it/s, loss=0.1]   \u001b[A\n",
            "Training Batches:  74%|███████▍  | 369/500 [02:32<00:58,  2.23it/s, loss=0.1]\u001b[A\n",
            "Training Batches:  74%|███████▍  | 369/500 [02:33<00:58,  2.23it/s, loss=0.1]\u001b[A\n",
            "Training Batches:  74%|███████▍  | 370/500 [02:33<00:58,  2.23it/s, loss=0.1]\u001b[A\n",
            "Training Batches:  74%|███████▍  | 370/500 [02:33<00:58,  2.23it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  74%|███████▍  | 371/500 [02:33<00:57,  2.24it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  74%|███████▍  | 371/500 [02:33<00:57,  2.24it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  74%|███████▍  | 372/500 [02:33<00:56,  2.25it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  74%|███████▍  | 372/500 [02:34<00:56,  2.25it/s, loss=0.0947]\u001b[A\n",
            "Training Batches:  75%|███████▍  | 373/500 [02:34<00:56,  2.25it/s, loss=0.0947]\u001b[A\n",
            "Training Batches:  75%|███████▍  | 373/500 [02:34<00:56,  2.25it/s, loss=0.0991]\u001b[A\n",
            "Training Batches:  75%|███████▍  | 374/500 [02:34<00:55,  2.27it/s, loss=0.0991]\u001b[A\n",
            "Training Batches:  75%|███████▍  | 374/500 [02:35<00:55,  2.27it/s, loss=0.101] \u001b[A\n",
            "Training Batches:  75%|███████▌  | 375/500 [02:35<00:55,  2.27it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  75%|███████▌  | 375/500 [02:35<00:55,  2.27it/s, loss=0.0969]\u001b[A\n",
            "Training Batches:  75%|███████▌  | 376/500 [02:35<00:54,  2.26it/s, loss=0.0969]\u001b[A\n",
            "Training Batches:  75%|███████▌  | 376/500 [02:36<00:54,  2.26it/s, loss=0.0977]\u001b[A\n",
            "Training Batches:  75%|███████▌  | 377/500 [02:36<00:54,  2.26it/s, loss=0.0977]\u001b[A\n",
            "Training Batches:  75%|███████▌  | 377/500 [02:36<00:54,  2.26it/s, loss=0.103] \u001b[A\n",
            "Training Batches:  76%|███████▌  | 378/500 [02:36<00:53,  2.26it/s, loss=0.103]\u001b[A\n",
            "Training Batches:  76%|███████▌  | 378/500 [02:37<00:53,  2.26it/s, loss=0.099]\u001b[A\n",
            "Training Batches:  76%|███████▌  | 379/500 [02:37<00:53,  2.28it/s, loss=0.099]\u001b[A\n",
            "Training Batches:  76%|███████▌  | 379/500 [02:37<00:53,  2.28it/s, loss=0.0992]\u001b[A\n",
            "Training Batches:  76%|███████▌  | 380/500 [02:37<00:52,  2.27it/s, loss=0.0992]\u001b[A\n",
            "Training Batches:  76%|███████▌  | 380/500 [02:37<00:52,  2.27it/s, loss=0.0977]\u001b[A\n",
            "Training Batches:  76%|███████▌  | 381/500 [02:37<00:52,  2.27it/s, loss=0.0977]\u001b[A\n",
            "Training Batches:  76%|███████▌  | 381/500 [02:38<00:52,  2.27it/s, loss=0.101] \u001b[A\n",
            "Training Batches:  76%|███████▋  | 382/500 [02:38<00:52,  2.27it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  76%|███████▋  | 382/500 [02:38<00:52,  2.27it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  77%|███████▋  | 383/500 [02:38<00:51,  2.26it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  77%|███████▋  | 383/500 [02:39<00:51,  2.26it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  77%|███████▋  | 384/500 [02:39<00:51,  2.26it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  77%|███████▋  | 384/500 [02:39<00:51,  2.26it/s, loss=0.1]  \u001b[A\n",
            "Training Batches:  77%|███████▋  | 385/500 [02:39<00:50,  2.26it/s, loss=0.1]\u001b[A\n",
            "Training Batches:  77%|███████▋  | 385/500 [02:40<00:50,  2.26it/s, loss=0.1]\u001b[A\n",
            "Training Batches:  77%|███████▋  | 386/500 [02:40<00:50,  2.26it/s, loss=0.1]\u001b[A\n",
            "Training Batches:  77%|███████▋  | 386/500 [02:40<00:50,  2.26it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  77%|███████▋  | 387/500 [02:40<00:49,  2.28it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  77%|███████▋  | 387/500 [02:41<00:49,  2.28it/s, loss=0.0974]\u001b[A\n",
            "Training Batches:  78%|███████▊  | 388/500 [02:41<00:49,  2.27it/s, loss=0.0974]\u001b[A\n",
            "Training Batches:  78%|███████▊  | 388/500 [02:41<00:49,  2.27it/s, loss=0.104] \u001b[A\n",
            "Training Batches:  78%|███████▊  | 389/500 [02:41<00:48,  2.29it/s, loss=0.104]\u001b[A\n",
            "Training Batches:  78%|███████▊  | 389/500 [02:41<00:48,  2.29it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  78%|███████▊  | 390/500 [02:41<00:48,  2.28it/s, loss=0.102]\u001b[A\n",
            "Training Batches:  78%|███████▊  | 390/500 [02:42<00:48,  2.28it/s, loss=0.0963]\u001b[A\n",
            "Training Batches:  78%|███████▊  | 391/500 [02:42<00:47,  2.28it/s, loss=0.0963]\u001b[A\n",
            "Training Batches:  78%|███████▊  | 391/500 [02:42<00:47,  2.28it/s, loss=0.101] \u001b[A\n",
            "Training Batches:  78%|███████▊  | 392/500 [02:42<00:47,  2.29it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  78%|███████▊  | 392/500 [02:43<00:47,  2.29it/s, loss=0.098]\u001b[A\n",
            "Training Batches:  79%|███████▊  | 393/500 [02:43<00:46,  2.28it/s, loss=0.098]\u001b[A\n",
            "Training Batches:  79%|███████▊  | 393/500 [02:43<00:46,  2.28it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  79%|███████▉  | 394/500 [02:43<00:46,  2.30it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  79%|███████▉  | 394/500 [02:44<00:46,  2.30it/s, loss=0.0957]\u001b[A\n",
            "Training Batches:  79%|███████▉  | 395/500 [02:44<00:45,  2.29it/s, loss=0.0957]\u001b[A\n",
            "Training Batches:  79%|███████▉  | 395/500 [02:44<00:45,  2.29it/s, loss=0.0937]\u001b[A\n",
            "Training Batches:  79%|███████▉  | 396/500 [02:44<00:45,  2.27it/s, loss=0.0937]\u001b[A\n",
            "Training Batches:  79%|███████▉  | 396/500 [02:44<00:45,  2.27it/s, loss=0.0946]\u001b[A\n",
            "Training Batches:  79%|███████▉  | 397/500 [02:44<00:45,  2.27it/s, loss=0.0946]\u001b[A\n",
            "Training Batches:  79%|███████▉  | 397/500 [02:45<00:45,  2.27it/s, loss=0.0976]\u001b[A\n",
            "Training Batches:  80%|███████▉  | 398/500 [02:45<00:45,  2.24it/s, loss=0.0976]\u001b[A\n",
            "Training Batches:  80%|███████▉  | 398/500 [02:45<00:45,  2.24it/s, loss=0.101] \u001b[A\n",
            "Training Batches:  80%|███████▉  | 399/500 [02:45<00:45,  2.23it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  80%|███████▉  | 399/500 [02:46<00:45,  2.23it/s, loss=0.0989]\u001b[A\n",
            "Training Batches:  80%|████████  | 400/500 [02:46<00:44,  2.27it/s, loss=0.0989]\u001b[A\n",
            "Training Batches:  80%|████████  | 400/500 [02:46<00:44,  2.27it/s, loss=0.0966]\u001b[A\n",
            "Training Batches:  80%|████████  | 401/500 [02:46<00:43,  2.27it/s, loss=0.0966]\u001b[A\n",
            "Training Batches:  80%|████████  | 401/500 [02:47<00:43,  2.27it/s, loss=0.1]   \u001b[A\n",
            "Training Batches:  80%|████████  | 402/500 [02:47<00:42,  2.28it/s, loss=0.1]\u001b[A\n",
            "Training Batches:  80%|████████  | 402/500 [02:47<00:42,  2.28it/s, loss=0.1]\u001b[A\n",
            "Training Batches:  81%|████████  | 403/500 [02:47<00:42,  2.28it/s, loss=0.1]\u001b[A\n",
            "Training Batches:  81%|████████  | 403/500 [02:48<00:42,  2.28it/s, loss=0.0958]\u001b[A\n",
            "Training Batches:  81%|████████  | 404/500 [02:48<00:41,  2.30it/s, loss=0.0958]\u001b[A\n",
            "Training Batches:  81%|████████  | 404/500 [02:48<00:41,  2.30it/s, loss=0.0969]\u001b[A\n",
            "Training Batches:  81%|████████  | 405/500 [02:48<00:41,  2.31it/s, loss=0.0969]\u001b[A\n",
            "Training Batches:  81%|████████  | 405/500 [02:48<00:41,  2.31it/s, loss=0.0992]\u001b[A\n",
            "Training Batches:  81%|████████  | 406/500 [02:48<00:40,  2.30it/s, loss=0.0992]\u001b[A\n",
            "Training Batches:  81%|████████  | 406/500 [02:49<00:40,  2.30it/s, loss=0.0993]\u001b[A\n",
            "Training Batches:  81%|████████▏ | 407/500 [02:49<00:40,  2.29it/s, loss=0.0993]\u001b[A\n",
            "Training Batches:  81%|████████▏ | 407/500 [02:49<00:40,  2.29it/s, loss=0.101] \u001b[A\n",
            "Training Batches:  82%|████████▏ | 408/500 [02:49<00:40,  2.28it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  82%|████████▏ | 408/500 [02:50<00:40,  2.28it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  82%|████████▏ | 409/500 [02:50<00:39,  2.29it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  82%|████████▏ | 409/500 [02:50<00:39,  2.29it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  82%|████████▏ | 410/500 [02:50<00:39,  2.28it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  82%|████████▏ | 410/500 [02:51<00:39,  2.28it/s, loss=0.0964]\u001b[A\n",
            "Training Batches:  82%|████████▏ | 411/500 [02:51<00:38,  2.30it/s, loss=0.0964]\u001b[A\n",
            "Training Batches:  82%|████████▏ | 411/500 [02:51<00:38,  2.30it/s, loss=0.0996]\u001b[A\n",
            "Training Batches:  82%|████████▏ | 412/500 [02:51<00:38,  2.30it/s, loss=0.0996]\u001b[A\n",
            "Training Batches:  82%|████████▏ | 412/500 [02:51<00:38,  2.30it/s, loss=0.0999]\u001b[A\n",
            "Training Batches:  83%|████████▎ | 413/500 [02:51<00:37,  2.30it/s, loss=0.0999]\u001b[A\n",
            "Training Batches:  83%|████████▎ | 413/500 [02:52<00:37,  2.30it/s, loss=0.0999]\u001b[A\n",
            "Training Batches:  83%|████████▎ | 414/500 [02:52<00:37,  2.29it/s, loss=0.0999]\u001b[A\n",
            "Training Batches:  83%|████████▎ | 414/500 [02:52<00:37,  2.29it/s, loss=0.0958]\u001b[A\n",
            "Training Batches:  83%|████████▎ | 415/500 [02:52<00:36,  2.30it/s, loss=0.0958]\u001b[A\n",
            "Training Batches:  83%|████████▎ | 415/500 [02:53<00:36,  2.30it/s, loss=0.101] \u001b[A\n",
            "Training Batches:  83%|████████▎ | 416/500 [02:53<00:36,  2.32it/s, loss=0.101]\u001b[A\n",
            "Training Batches:  83%|████████▎ | 416/500 [02:53<00:36,  2.32it/s, loss=0.0907]\u001b[A\n",
            "Training Batches:  83%|████████▎ | 417/500 [02:53<00:35,  2.33it/s, loss=0.0907]\u001b[A\n",
            "Training Batches:  83%|████████▎ | 417/500 [02:54<00:35,  2.33it/s, loss=0.0971]\u001b[A\n",
            "Training Batches:  84%|████████▎ | 418/500 [02:54<00:35,  2.33it/s, loss=0.0971]\u001b[A\n",
            "Training Batches:  84%|████████▎ | 418/500 [02:54<00:35,  2.33it/s, loss=0.0976]\u001b[A\n",
            "Training Batches:  84%|████████▍ | 419/500 [02:54<00:34,  2.32it/s, loss=0.0976]\u001b[A\n",
            "Training Batches:  84%|████████▍ | 419/500 [02:54<00:34,  2.32it/s, loss=0.097] \u001b[A\n",
            "Training Batches:  84%|████████▍ | 420/500 [02:54<00:34,  2.32it/s, loss=0.097]\u001b[A\n",
            "Training Batches:  84%|████████▍ | 420/500 [02:55<00:34,  2.32it/s, loss=0.0921]\u001b[A\n",
            "Training Batches:  84%|████████▍ | 421/500 [02:55<00:33,  2.33it/s, loss=0.0921]\u001b[A\n",
            "Training Batches:  84%|████████▍ | 421/500 [02:55<00:33,  2.33it/s, loss=0.0972]\u001b[A\n",
            "Training Batches:  84%|████████▍ | 422/500 [02:55<00:33,  2.31it/s, loss=0.0972]\u001b[A\n",
            "Training Batches:  84%|████████▍ | 422/500 [02:56<00:33,  2.31it/s, loss=0.0965]\u001b[A\n",
            "Training Batches:  85%|████████▍ | 423/500 [02:56<00:33,  2.28it/s, loss=0.0965]\u001b[A\n",
            "Training Batches:  85%|████████▍ | 423/500 [02:56<00:33,  2.28it/s, loss=0.0998]\u001b[A\n",
            "Training Batches:  85%|████████▍ | 424/500 [02:56<00:33,  2.28it/s, loss=0.0998]\u001b[A\n",
            "Training Batches:  85%|████████▍ | 424/500 [02:57<00:33,  2.28it/s, loss=0.0973]\u001b[A\n",
            "Training Batches:  85%|████████▌ | 425/500 [02:57<00:32,  2.30it/s, loss=0.0973]\u001b[A\n",
            "Training Batches:  85%|████████▌ | 425/500 [02:57<00:32,  2.30it/s, loss=0.0943]\u001b[A\n",
            "Training Batches:  85%|████████▌ | 426/500 [02:57<00:32,  2.31it/s, loss=0.0943]\u001b[A\n",
            "Training Batches:  85%|████████▌ | 426/500 [02:58<00:32,  2.31it/s, loss=0.0987]\u001b[A\n",
            "Training Batches:  85%|████████▌ | 427/500 [02:58<00:31,  2.30it/s, loss=0.0987]\u001b[A\n",
            "Training Batches:  85%|████████▌ | 427/500 [02:58<00:31,  2.30it/s, loss=0.0959]\u001b[A\n",
            "Training Batches:  86%|████████▌ | 428/500 [02:58<00:31,  2.31it/s, loss=0.0959]\u001b[A\n",
            "Training Batches:  86%|████████▌ | 428/500 [02:58<00:31,  2.31it/s, loss=0.0939]\u001b[A\n",
            "Training Batches:  86%|████████▌ | 429/500 [02:58<00:30,  2.31it/s, loss=0.0939]\u001b[A\n",
            "Training Batches:  86%|████████▌ | 429/500 [02:59<00:30,  2.31it/s, loss=0.0954]\u001b[A\n",
            "Training Batches:  86%|████████▌ | 430/500 [02:59<00:30,  2.31it/s, loss=0.0954]\u001b[A\n",
            "Training Batches:  86%|████████▌ | 430/500 [02:59<00:30,  2.31it/s, loss=0.0984]\u001b[A\n",
            "Training Batches:  86%|████████▌ | 431/500 [02:59<00:29,  2.32it/s, loss=0.0984]\u001b[A\n",
            "Training Batches:  86%|████████▌ | 431/500 [03:00<00:29,  2.32it/s, loss=0.0983]\u001b[A\n",
            "Training Batches:  86%|████████▋ | 432/500 [03:00<00:29,  2.33it/s, loss=0.0983]\u001b[A\n",
            "Training Batches:  86%|████████▋ | 432/500 [03:00<00:29,  2.33it/s, loss=0.0999]\u001b[A\n",
            "Training Batches:  87%|████████▋ | 433/500 [03:00<00:28,  2.32it/s, loss=0.0999]\u001b[A\n",
            "Training Batches:  87%|████████▋ | 433/500 [03:01<00:28,  2.32it/s, loss=0.099] \u001b[A\n",
            "Training Batches:  87%|████████▋ | 434/500 [03:01<00:28,  2.32it/s, loss=0.099]\u001b[A\n",
            "Training Batches:  87%|████████▋ | 434/500 [03:01<00:28,  2.32it/s, loss=0.0934]\u001b[A\n",
            "Training Batches:  87%|████████▋ | 435/500 [03:01<00:28,  2.30it/s, loss=0.0934]\u001b[A\n",
            "Training Batches:  87%|████████▋ | 435/500 [03:02<00:28,  2.30it/s, loss=0.0971]\u001b[A\n",
            "Training Batches:  87%|████████▋ | 436/500 [03:02<00:29,  2.15it/s, loss=0.0971]\u001b[A\n",
            "Training Batches:  87%|████████▋ | 436/500 [03:02<00:29,  2.15it/s, loss=0.0938]\u001b[A\n",
            "Training Batches:  87%|████████▋ | 437/500 [03:02<00:30,  2.10it/s, loss=0.0938]\u001b[A\n",
            "Training Batches:  87%|████████▋ | 437/500 [03:03<00:30,  2.10it/s, loss=0.098] \u001b[A\n",
            "Training Batches:  88%|████████▊ | 438/500 [03:03<00:30,  2.05it/s, loss=0.098]\u001b[A\n",
            "Training Batches:  88%|████████▊ | 438/500 [03:03<00:30,  2.05it/s, loss=0.0946]\u001b[A\n",
            "Training Batches:  88%|████████▊ | 439/500 [03:03<00:30,  1.99it/s, loss=0.0946]\u001b[A\n",
            "Training Batches:  88%|████████▊ | 439/500 [03:04<00:30,  1.99it/s, loss=0.0955]\u001b[A\n",
            "Training Batches:  88%|████████▊ | 440/500 [03:04<00:30,  1.96it/s, loss=0.0955]\u001b[A\n",
            "Training Batches:  88%|████████▊ | 440/500 [03:04<00:30,  1.96it/s, loss=0.0989]\u001b[A\n",
            "Training Batches:  88%|████████▊ | 441/500 [03:04<00:30,  1.91it/s, loss=0.0989]\u001b[A\n",
            "Training Batches:  88%|████████▊ | 441/500 [03:05<00:30,  1.91it/s, loss=0.0925]\u001b[A\n",
            "Training Batches:  88%|████████▊ | 442/500 [03:05<00:30,  1.91it/s, loss=0.0925]\u001b[A\n",
            "Training Batches:  88%|████████▊ | 442/500 [03:05<00:30,  1.91it/s, loss=0.0913]\u001b[A\n",
            "Training Batches:  89%|████████▊ | 443/500 [03:05<00:28,  1.97it/s, loss=0.0913]\u001b[A\n",
            "Training Batches:  89%|████████▊ | 443/500 [03:06<00:28,  1.97it/s, loss=0.0947]\u001b[A\n",
            "Training Batches:  89%|████████▉ | 444/500 [03:06<00:28,  1.94it/s, loss=0.0947]\u001b[A\n",
            "Training Batches:  89%|████████▉ | 444/500 [03:06<00:28,  1.94it/s, loss=0.0978]\u001b[A\n",
            "Training Batches:  89%|████████▉ | 445/500 [03:06<00:26,  2.04it/s, loss=0.0978]\u001b[A\n",
            "Training Batches:  89%|████████▉ | 445/500 [03:07<00:26,  2.04it/s, loss=0.0917]\u001b[A\n",
            "Training Batches:  89%|████████▉ | 446/500 [03:07<00:27,  1.99it/s, loss=0.0917]\u001b[A\n",
            "Training Batches:  89%|████████▉ | 446/500 [03:07<00:27,  1.99it/s, loss=0.0994]\u001b[A\n",
            "Training Batches:  89%|████████▉ | 447/500 [03:07<00:25,  2.08it/s, loss=0.0994]\u001b[A\n",
            "Training Batches:  89%|████████▉ | 447/500 [03:08<00:25,  2.08it/s, loss=0.0941]\u001b[A\n",
            "Training Batches:  90%|████████▉ | 448/500 [03:08<00:24,  2.15it/s, loss=0.0941]\u001b[A\n",
            "Training Batches:  90%|████████▉ | 448/500 [03:08<00:24,  2.15it/s, loss=0.0966]\u001b[A\n",
            "Training Batches:  90%|████████▉ | 449/500 [03:08<00:23,  2.19it/s, loss=0.0966]\u001b[A\n",
            "Training Batches:  90%|████████▉ | 449/500 [03:08<00:23,  2.19it/s, loss=0.0946]\u001b[A\n",
            "Training Batches:  90%|█████████ | 450/500 [03:08<00:22,  2.23it/s, loss=0.0946]\u001b[A\n",
            "Training Batches:  90%|█████████ | 450/500 [03:09<00:22,  2.23it/s, loss=0.0934]\u001b[A\n",
            "Training Batches:  90%|█████████ | 451/500 [03:09<00:21,  2.27it/s, loss=0.0934]\u001b[A\n",
            "Training Batches:  90%|█████████ | 451/500 [03:09<00:21,  2.27it/s, loss=0.0933]\u001b[A\n",
            "Training Batches:  90%|█████████ | 452/500 [03:09<00:21,  2.28it/s, loss=0.0933]\u001b[A\n",
            "Training Batches:  90%|█████████ | 452/500 [03:10<00:21,  2.28it/s, loss=0.095] \u001b[A\n",
            "Training Batches:  91%|█████████ | 453/500 [03:10<00:20,  2.27it/s, loss=0.095]\u001b[A\n",
            "Training Batches:  91%|█████████ | 453/500 [03:10<00:20,  2.27it/s, loss=0.0937]\u001b[A\n",
            "Training Batches:  91%|█████████ | 454/500 [03:10<00:20,  2.27it/s, loss=0.0937]\u001b[A\n",
            "Training Batches:  91%|█████████ | 454/500 [03:11<00:20,  2.27it/s, loss=0.0957]\u001b[A\n",
            "Training Batches:  91%|█████████ | 455/500 [03:11<00:19,  2.29it/s, loss=0.0957]\u001b[A\n",
            "Training Batches:  91%|█████████ | 455/500 [03:11<00:19,  2.29it/s, loss=0.0971]\u001b[A\n",
            "Training Batches:  91%|█████████ | 456/500 [03:11<00:19,  2.31it/s, loss=0.0971]\u001b[A\n",
            "Training Batches:  91%|█████████ | 456/500 [03:11<00:19,  2.31it/s, loss=0.0965]\u001b[A\n",
            "Training Batches:  91%|█████████▏| 457/500 [03:11<00:18,  2.32it/s, loss=0.0965]\u001b[A\n",
            "Training Batches:  91%|█████████▏| 457/500 [03:12<00:18,  2.32it/s, loss=0.0941]\u001b[A\n",
            "Training Batches:  92%|█████████▏| 458/500 [03:12<00:18,  2.33it/s, loss=0.0941]\u001b[A\n",
            "Training Batches:  92%|█████████▏| 458/500 [03:12<00:18,  2.33it/s, loss=0.094] \u001b[A\n",
            "Training Batches:  92%|█████████▏| 459/500 [03:12<00:17,  2.34it/s, loss=0.094]\u001b[A\n",
            "Training Batches:  92%|█████████▏| 459/500 [03:13<00:17,  2.34it/s, loss=0.0925]\u001b[A\n",
            "Training Batches:  92%|█████████▏| 460/500 [03:13<00:17,  2.34it/s, loss=0.0925]\u001b[A\n",
            "Training Batches:  92%|█████████▏| 460/500 [03:13<00:17,  2.34it/s, loss=0.0878]\u001b[A\n",
            "Training Batches:  92%|█████████▏| 461/500 [03:13<00:16,  2.34it/s, loss=0.0878]\u001b[A\n",
            "Training Batches:  92%|█████████▏| 461/500 [03:14<00:16,  2.34it/s, loss=0.0942]\u001b[A\n",
            "Training Batches:  92%|█████████▏| 462/500 [03:14<00:16,  2.35it/s, loss=0.0942]\u001b[A\n",
            "Training Batches:  92%|█████████▏| 462/500 [03:14<00:16,  2.35it/s, loss=0.0949]\u001b[A\n",
            "Training Batches:  93%|█████████▎| 463/500 [03:14<00:15,  2.35it/s, loss=0.0949]\u001b[A\n",
            "Training Batches:  93%|█████████▎| 463/500 [03:14<00:15,  2.35it/s, loss=0.098] \u001b[A\n",
            "Training Batches:  93%|█████████▎| 464/500 [03:14<00:15,  2.35it/s, loss=0.098]\u001b[A\n",
            "Training Batches:  93%|█████████▎| 464/500 [03:15<00:15,  2.35it/s, loss=0.0987]\u001b[A\n",
            "Training Batches:  93%|█████████▎| 465/500 [03:15<00:14,  2.36it/s, loss=0.0987]\u001b[A\n",
            "Training Batches:  93%|█████████▎| 465/500 [03:15<00:14,  2.36it/s, loss=0.0948]\u001b[A\n",
            "Training Batches:  93%|█████████▎| 466/500 [03:15<00:14,  2.35it/s, loss=0.0948]\u001b[A\n",
            "Training Batches:  93%|█████████▎| 466/500 [03:16<00:14,  2.35it/s, loss=0.097] \u001b[A\n",
            "Training Batches:  93%|█████████▎| 467/500 [03:16<00:14,  2.35it/s, loss=0.097]\u001b[A\n",
            "Training Batches:  93%|█████████▎| 467/500 [03:16<00:14,  2.35it/s, loss=0.0908]\u001b[A\n",
            "Training Batches:  94%|█████████▎| 468/500 [03:16<00:13,  2.33it/s, loss=0.0908]\u001b[A\n",
            "Training Batches:  94%|█████████▎| 468/500 [03:17<00:13,  2.33it/s, loss=0.092] \u001b[A\n",
            "Training Batches:  94%|█████████▍| 469/500 [03:17<00:13,  2.32it/s, loss=0.092]\u001b[A\n",
            "Training Batches:  94%|█████████▍| 469/500 [03:17<00:13,  2.32it/s, loss=0.0927]\u001b[A\n",
            "Training Batches:  94%|█████████▍| 470/500 [03:17<00:12,  2.32it/s, loss=0.0927]\u001b[A\n",
            "Training Batches:  94%|█████████▍| 470/500 [03:17<00:12,  2.32it/s, loss=0.0965]\u001b[A\n",
            "Training Batches:  94%|█████████▍| 471/500 [03:17<00:12,  2.32it/s, loss=0.0965]\u001b[A\n",
            "Training Batches:  94%|█████████▍| 471/500 [03:18<00:12,  2.32it/s, loss=0.0957]\u001b[A\n",
            "Training Batches:  94%|█████████▍| 472/500 [03:18<00:12,  2.32it/s, loss=0.0957]\u001b[A\n",
            "Training Batches:  94%|█████████▍| 472/500 [03:18<00:12,  2.32it/s, loss=0.0957]\u001b[A\n",
            "Training Batches:  95%|█████████▍| 473/500 [03:18<00:11,  2.33it/s, loss=0.0957]\u001b[A\n",
            "Training Batches:  95%|█████████▍| 473/500 [03:19<00:11,  2.33it/s, loss=0.0952]\u001b[A\n",
            "Training Batches:  95%|█████████▍| 474/500 [03:19<00:11,  2.32it/s, loss=0.0952]\u001b[A\n",
            "Training Batches:  95%|█████████▍| 474/500 [03:19<00:11,  2.32it/s, loss=0.0911]\u001b[A\n",
            "Training Batches:  95%|█████████▌| 475/500 [03:19<00:10,  2.32it/s, loss=0.0911]\u001b[A\n",
            "Training Batches:  95%|█████████▌| 475/500 [03:20<00:10,  2.32it/s, loss=0.0965]\u001b[A\n",
            "Training Batches:  95%|█████████▌| 476/500 [03:20<00:10,  2.32it/s, loss=0.0965]\u001b[A\n",
            "Training Batches:  95%|█████████▌| 476/500 [03:20<00:10,  2.32it/s, loss=0.0934]\u001b[A\n",
            "Training Batches:  95%|█████████▌| 477/500 [03:20<00:09,  2.31it/s, loss=0.0934]\u001b[A\n",
            "Training Batches:  95%|█████████▌| 477/500 [03:20<00:09,  2.31it/s, loss=0.0978]\u001b[A\n",
            "Training Batches:  96%|█████████▌| 478/500 [03:20<00:09,  2.29it/s, loss=0.0978]\u001b[A\n",
            "Training Batches:  96%|█████████▌| 478/500 [03:21<00:09,  2.29it/s, loss=0.0934]\u001b[A\n",
            "Training Batches:  96%|█████████▌| 479/500 [03:21<00:09,  2.28it/s, loss=0.0934]\u001b[A\n",
            "Training Batches:  96%|█████████▌| 479/500 [03:21<00:09,  2.28it/s, loss=0.0903]\u001b[A\n",
            "Training Batches:  96%|█████████▌| 480/500 [03:21<00:08,  2.28it/s, loss=0.0903]\u001b[A\n",
            "Training Batches:  96%|█████████▌| 480/500 [03:22<00:08,  2.28it/s, loss=0.0959]\u001b[A\n",
            "Training Batches:  96%|█████████▌| 481/500 [03:22<00:08,  2.27it/s, loss=0.0959]\u001b[A\n",
            "Training Batches:  96%|█████████▌| 481/500 [03:22<00:08,  2.27it/s, loss=0.0959]\u001b[A\n",
            "Training Batches:  96%|█████████▋| 482/500 [03:22<00:07,  2.27it/s, loss=0.0959]\u001b[A\n",
            "Training Batches:  96%|█████████▋| 482/500 [03:23<00:07,  2.27it/s, loss=0.0874]\u001b[A\n",
            "Training Batches:  97%|█████████▋| 483/500 [03:23<00:07,  2.29it/s, loss=0.0874]\u001b[A\n",
            "Training Batches:  97%|█████████▋| 483/500 [03:23<00:07,  2.29it/s, loss=0.0933]\u001b[A\n",
            "Training Batches:  97%|█████████▋| 484/500 [03:23<00:06,  2.31it/s, loss=0.0933]\u001b[A\n",
            "Training Batches:  97%|█████████▋| 484/500 [03:23<00:06,  2.31it/s, loss=0.0899]\u001b[A\n",
            "Training Batches:  97%|█████████▋| 485/500 [03:23<00:06,  2.30it/s, loss=0.0899]\u001b[A\n",
            "Training Batches:  97%|█████████▋| 485/500 [03:24<00:06,  2.30it/s, loss=0.0917]\u001b[A\n",
            "Training Batches:  97%|█████████▋| 486/500 [03:24<00:06,  2.30it/s, loss=0.0917]\u001b[A\n",
            "Training Batches:  97%|█████████▋| 486/500 [03:24<00:06,  2.30it/s, loss=0.0971]\u001b[A\n",
            "Training Batches:  97%|█████████▋| 487/500 [03:24<00:05,  2.32it/s, loss=0.0971]\u001b[A\n",
            "Training Batches:  97%|█████████▋| 487/500 [03:25<00:05,  2.32it/s, loss=0.092] \u001b[A\n",
            "Training Batches:  98%|█████████▊| 488/500 [03:25<00:05,  2.33it/s, loss=0.092]\u001b[A\n",
            "Training Batches:  98%|█████████▊| 488/500 [03:25<00:05,  2.33it/s, loss=0.0943]\u001b[A\n",
            "Training Batches:  98%|█████████▊| 489/500 [03:25<00:04,  2.33it/s, loss=0.0943]\u001b[A\n",
            "Training Batches:  98%|█████████▊| 489/500 [03:26<00:04,  2.33it/s, loss=0.096] \u001b[A\n",
            "Training Batches:  98%|█████████▊| 490/500 [03:26<00:04,  2.31it/s, loss=0.096]\u001b[A\n",
            "Training Batches:  98%|█████████▊| 490/500 [03:26<00:04,  2.31it/s, loss=0.0932]\u001b[A\n",
            "Training Batches:  98%|█████████▊| 491/500 [03:26<00:03,  2.32it/s, loss=0.0932]\u001b[A\n",
            "Training Batches:  98%|█████████▊| 491/500 [03:27<00:03,  2.32it/s, loss=0.0936]\u001b[A\n",
            "Training Batches:  98%|█████████▊| 492/500 [03:27<00:03,  2.30it/s, loss=0.0936]\u001b[A\n",
            "Training Batches:  98%|█████████▊| 492/500 [03:27<00:03,  2.30it/s, loss=0.0902]\u001b[A\n",
            "Training Batches:  99%|█████████▊| 493/500 [03:27<00:03,  2.31it/s, loss=0.0902]\u001b[A\n",
            "Training Batches:  99%|█████████▊| 493/500 [03:27<00:03,  2.31it/s, loss=0.0903]\u001b[A\n",
            "Training Batches:  99%|█████████▉| 494/500 [03:27<00:02,  2.32it/s, loss=0.0903]\u001b[A\n",
            "Training Batches:  99%|█████████▉| 494/500 [03:28<00:02,  2.32it/s, loss=0.0992]\u001b[A\n",
            "Training Batches:  99%|█████████▉| 495/500 [03:28<00:02,  2.31it/s, loss=0.0992]\u001b[A\n",
            "Training Batches:  99%|█████████▉| 495/500 [03:28<00:02,  2.31it/s, loss=0.0915]\u001b[A\n",
            "Training Batches:  99%|█████████▉| 496/500 [03:28<00:01,  2.31it/s, loss=0.0915]\u001b[A\n",
            "Training Batches:  99%|█████████▉| 496/500 [03:29<00:01,  2.31it/s, loss=0.0872]\u001b[A\n",
            "Training Batches:  99%|█████████▉| 497/500 [03:29<00:01,  2.33it/s, loss=0.0872]\u001b[A\n",
            "Training Batches:  99%|█████████▉| 497/500 [03:29<00:01,  2.33it/s, loss=0.0945]\u001b[A\n",
            "Training Batches: 100%|█████████▉| 498/500 [03:29<00:00,  2.34it/s, loss=0.0945]\u001b[A\n",
            "Training Batches: 100%|█████████▉| 498/500 [03:30<00:00,  2.34it/s, loss=0.0898]\u001b[A\n",
            "Training Batches: 100%|█████████▉| 499/500 [03:30<00:00,  2.32it/s, loss=0.0898]\u001b[A\n",
            "Training Batches: 100%|█████████▉| 499/500 [03:30<00:00,  2.32it/s, loss=0.0949]\u001b[A\n",
            "Training Batches: 100%|██████████| 500/500 [03:30<00:00,  2.38it/s, loss=0.0949]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Average Training Loss: 0.1606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Batches: 100%|██████████| 125/125 [00:17<00:00,  7.11it/s, loss=0.0919]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Average Validation Loss: 0.0907\n",
            "\n",
            "======== Epoch 2 / 2 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Batches: 100%|██████████| 500/500 [03:31<00:00,  2.36it/s, loss=0.0472]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Average Training Loss: 0.0723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation Batches: 100%|██████████| 125/125 [00:17<00:00,  7.17it/s, loss=0.0532]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Average Validation Loss: 0.0510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # Ignores warnings if some rare diseases weren't predicted\n",
        "\n",
        "# 1. Put model in Evaluation Mode\n",
        "model.eval()\n",
        "\n",
        "# 2. Lists to store all predictions and actual answers\n",
        "all_predictions = []\n",
        "all_actuals = []\n",
        "\n",
        "print(\"Running final evaluation on the Validation Set...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        # Move to GPU\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        targets = batch['targets'].to(device)\n",
        "\n",
        "        # Get raw logits\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Step 1: Apply Sigmoid to get percentages\n",
        "        probabilities = torch.sigmoid(logits)\n",
        "\n",
        "        # Step 2: Apply the 0.5 Threshold\n",
        "        # This creates an array of 0s and 1s just like our MultiLabelBinarizer targets!\n",
        "        binary_predictions = (probabilities > 0.5).int()\n",
        "\n",
        "        # Move back to CPU and store in our lists\n",
        "        all_predictions.extend(binary_predictions.cpu().numpy())\n",
        "        all_actuals.extend(targets.cpu().numpy())\n",
        "\n",
        "# Convert lists to NumPy arrays for scikit-learn\n",
        "all_predictions = np.array(all_predictions)\n",
        "all_actuals = np.array(all_actuals)\n",
        "\n",
        "# Step 3: Generate the Report Card\n",
        "print(\"\\n================= FINAL CLASSIFICATION REPORT =================\")\n",
        "print(classification_report(\n",
        "    all_actuals,\n",
        "    all_predictions,\n",
        "    target_names=mlb.classes_,\n",
        "    digits=3 # Show 3 decimal places\n",
        "))"
      ],
      "metadata": {
        "id": "xwSLBNBb4kSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cef9059-b415-4062-e9d1-00ec771db2c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running final evaluation on the Validation Set...\n",
            "\n",
            "================= FINAL CLASSIFICATION REPORT =================\n",
            "                                          precision    recall  f1-score   support\n",
            "\n",
            "     Acute COPD exacerbation / infection      0.000     0.000     0.000        34\n",
            "                Acute dystonic reactions      1.000     0.745     0.854        51\n",
            "                        Acute laryngitis      0.000     0.000     0.000        47\n",
            "                      Acute otitis media      0.000     0.000     0.000        51\n",
            "                   Acute pulmonary edema      0.000     0.000     0.000        37\n",
            "                    Acute rhinosinusitis      0.000     0.000     0.000        26\n",
            "                      Allergic sinusitis      1.000     0.980     0.990        51\n",
            "                             Anaphylaxis      0.000     0.000     0.000        54\n",
            "                                  Anemia      0.980     0.980     0.980        99\n",
            "                     Atrial fibrillation      0.000     0.000     0.000        41\n",
            "                               Boerhaave      0.000     0.000     0.000        29\n",
            "                          Bronchiectasis      0.000     0.000     0.000        37\n",
            "                           Bronchiolitis      0.000     0.000     0.000         1\n",
            "                              Bronchitis      0.000     0.000     0.000        51\n",
            "Bronchospasm / acute asthma exacerbation      0.000     0.000     0.000        39\n",
            "                                  Chagas      0.000     0.000     0.000        18\n",
            "                  Chronic rhinosinusitis      0.000     0.000     0.000        40\n",
            "                        Cluster headache      0.000     0.000     0.000        41\n",
            "                                   Croup      0.000     0.000     0.000         6\n",
            "                                   Ebola      0.000     0.000     0.000         1\n",
            "                            Epiglottitis      0.000     0.000     0.000        34\n",
            "                                    GERD      1.000     0.039     0.075        51\n",
            "                 Guillain-Barré syndrome      0.000     0.000     0.000        45\n",
            "                 HIV (initial infection)      0.000     0.000     0.000        57\n",
            "                               Influenza      0.000     0.000     0.000        52\n",
            "                         Inguinal hernia      0.000     0.000     0.000        39\n",
            "                             Larygospasm      0.000     0.000     0.000        21\n",
            "                         Localized edema      1.000     0.500     0.667        54\n",
            "                       Myasthenia gravis      0.000     0.000     0.000        36\n",
            "                             Myocarditis      0.000     0.000     0.000        22\n",
            "                                    PSVT      0.000     0.000     0.000        37\n",
            "                     Pancreatic neoplasm      0.000     0.000     0.000        37\n",
            "                            Panic attack      0.000     0.000     0.000        49\n",
            "                            Pericarditis      0.000     0.000     0.000        44\n",
            "                               Pneumonia      0.000     0.000     0.000        50\n",
            "                 Possible NSTEMI / STEMI      0.000     0.000     0.000        41\n",
            "                      Pulmonary embolism      1.000     0.056     0.105        54\n",
            "                      Pulmonary neoplasm      0.000     0.000     0.000        28\n",
            "                                     SLE      0.000     0.000     0.000        23\n",
            "                             Sarcoidosis      0.000     0.000     0.000        42\n",
            "                Scombroid food poisoning      0.000     0.000     0.000        36\n",
            "                Spontaneous pneumothorax      0.000     0.000     0.000        20\n",
            "                Spontaneous rib fracture      0.000     0.000     0.000        11\n",
            "                           Stable angina      0.000     0.000     0.000        33\n",
            "                            Tuberculosis      0.000     0.000     0.000        31\n",
            "                                    URTI      1.000     0.992     0.996       126\n",
            "                         Unstable angina      0.000     0.000     0.000        41\n",
            "                       Viral pharyngitis      0.859     0.967     0.910       120\n",
            "                          Whooping cough      0.000     0.000     0.000        12\n",
            "\n",
            "                               micro avg      0.956     0.229     0.370      2000\n",
            "                               macro avg      0.160     0.107     0.114      2000\n",
            "                            weighted avg      0.294     0.229     0.236      2000\n",
            "                             samples avg      0.229     0.229     0.229      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def diagnose_patient(model, tokenizer, mlb, text, threshold=0.5):\n",
        "    # 1. Put model in Evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # 2. Tokenize the input text\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    # Move to GPU\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    # 3. Make Prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probabilities = torch.sigmoid(logits)[0] # Grab the first (and only) patient's probabilities\n",
        "\n",
        "    # 4. Filter the results based on our threshold\n",
        "    predictions = []\n",
        "    for i, prob in enumerate(probabilities):\n",
        "        if prob > threshold:\n",
        "            disease_name = mlb.classes_[i]\n",
        "            confidence = prob.item() * 100\n",
        "            predictions.append((disease_name, confidence))\n",
        "\n",
        "    # Sort by highest confidence\n",
        "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "    return predictions\n",
        "\n",
        "# --- TEST IT OUT LIVE ---\n",
        "# Let's give it the classic symptoms of URTI / Pharyngitis since we know it learned those well!\n",
        "custom_patient_story = \"I am a 22-year-old male. I have a really bad sore throat, a runny nose, and I have been coughing all day. I feel a bit feverish too.\"\n",
        "\n",
        "results = diagnose_patient(model, tokenizer, mlb, custom_patient_story, threshold=0.5)\n",
        "\n",
        "print(f\"PATIENT STORY: '{custom_patient_story}'\\n\")\n",
        "print(\"=== HEAL BRIDGE AI DIAGNOSIS ===\")\n",
        "if not results:\n",
        "    print(\"No diseases detected above the confidence threshold.\")\n",
        "else:\n",
        "    for disease, confidence in results:\n",
        "        print(f\"-> {disease}: {confidence:.2f}% confidence\")"
      ],
      "metadata": {
        "id": "JAFD6upO4kP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "214daf1a-ae15-4cbd-ee28-ee1f0f4c2a8c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PATIENT STORY: 'I am a 22-year-old male. I have a really bad sore throat, a runny nose, and I have been coughing all day. I feel a bit feverish too.'\n",
            "\n",
            "=== HEAL BRIDGE AI DIAGNOSIS ===\n",
            "No diseases detected above the confidence threshold.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- THE DUAL INFERENCE TEST ---\n",
        "\n",
        "# Story 1: Using the exact vocabulary the model learned in Phase 1\n",
        "exact_story = \"I am a 22-year-old male. I came into the clinic today because I have a fever (either felt or measured with a thermometer). I have a sore throat. I have a cough.\"\n",
        "\n",
        "# Story 2: Your conversational version\n",
        "conversational_story = \"I am a 22-year-old male. I have a really bad sore throat, a runny nose, and I have been coughing all day. I feel a bit feverish too.\"\n",
        "\n",
        "print(\"=== TEST 1: EXACT VOCABULARY ===\")\n",
        "results_exact = diagnose_patient(model, tokenizer, mlb, exact_story, threshold=0.05)\n",
        "for disease, confidence in results_exact:\n",
        "    print(f\"-> {disease}: {confidence:.2f}% confidence\")\n",
        "\n",
        "print(\"\\n=== TEST 2: CONVERSATIONAL VOCABULARY ===\")\n",
        "results_conv = diagnose_patient(model, tokenizer, mlb, conversational_story, threshold=0.05)\n",
        "for disease, confidence in results_conv:\n",
        "    print(f\"-> {disease}: {confidence:.2f}% confidence\")"
      ],
      "metadata": {
        "id": "heEglbAU4kNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b6426d-a7ed-44aa-9517-72525b3fc6de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TEST 1: EXACT VOCABULARY ===\n",
            "-> Allergic sinusitis: 7.49% confidence\n",
            "-> Tuberculosis: 5.58% confidence\n",
            "\n",
            "=== TEST 2: CONVERSATIONAL VOCABULARY ===\n",
            "-> Allergic sinusitis: 18.01% confidence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def diagnose_patient_top_k(model, tokenizer, mlb, text, top_k=3):\n",
        "    model.eval()\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # Get raw probabilities\n",
        "        probabilities = torch.sigmoid(outputs.logits)[0]\n",
        "\n",
        "    # FORCE the model to give us the indices of its top 3 highest probabilities\n",
        "    top_indices = torch.topk(probabilities, top_k).indices.tolist()\n",
        "\n",
        "    predictions = []\n",
        "    for idx in top_indices:\n",
        "        disease_name = mlb.classes_[idx]\n",
        "        confidence = probabilities[idx].item() * 100\n",
        "        predictions.append((disease_name, confidence))\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# --- THE TOP-3 FORCED INFERENCE TEST ---\n",
        "\n",
        "print(\"=== TEST 1: EXACT VOCABULARY ===\")\n",
        "results_exact = diagnose_patient_top_k(model, tokenizer, mlb, exact_story, top_k=3)\n",
        "for disease, confidence in results_exact:\n",
        "    print(f\"-> {disease}: {confidence:.4f}% confidence\")\n",
        "\n",
        "print(\"\\n=== TEST 2: CONVERSATIONAL VOCABULARY ===\")\n",
        "results_conv = diagnose_patient_top_k(model, tokenizer, mlb, conversational_story, top_k=3)\n",
        "for disease, confidence in results_conv:\n",
        "    print(f\"-> {disease}: {confidence:.4f}% confidence\")"
      ],
      "metadata": {
        "id": "iJ2GsH5Y4kKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b2bb9e-67fe-4c04-e351-f98e350b81d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TEST 1: EXACT VOCABULARY ===\n",
            "-> Allergic sinusitis: 7.4905% confidence\n",
            "-> Tuberculosis: 5.5840% confidence\n",
            "-> Bronchiectasis: 3.9299% confidence\n",
            "\n",
            "=== TEST 2: CONVERSATIONAL VOCABULARY ===\n",
            "-> Allergic sinusitis: 18.0101% confidence\n",
            "-> Tuberculosis: 3.9962% confidence\n",
            "-> Bronchospasm / acute asthma exacerbation: 3.5851% confidence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Mount Google Drive (It will ask for permission again if you restarted)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Unzipping the 1-Million row dataset into Colab's fast local storage...\")\n",
        "# 2. Extract the file directly to /content/\n",
        "# (-q means quiet so it doesn't print 1 million lines to your screen, -o means overwrite)\n",
        "!unzip -q -o /content/drive/MyDrive/healbridge/translated_train_data.zip -d /content/\n",
        "\n",
        "# 3. Load the unzipped CSV into Pandas\n",
        "print(\"Loading the dataset into memory...\")\n",
        "df_full = pd.read_csv('/content/translated_train_data.csv')\n",
        "\n",
        "# 4. The Final Verification\n",
        "print(\"\\n--- DATASET STATUS ---\")\n",
        "print(f\"Total Rows: {df_full.shape[0]}\")\n",
        "print(f\"Total Columns: {df_full.shape[1]}\")\n",
        "print(\"First 3 rows:\")\n",
        "print(df_full.head(3))"
      ],
      "metadata": {
        "id": "pwKTSTP64kH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bcee5c-a48b-41e0-cbb6-d5c1d7fee293"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Unzipping the 1-Million row dataset into Colab's fast local storage...\n",
            "Loading the dataset into memory...\n",
            "\n",
            "--- DATASET STATUS ---\n",
            "Total Rows: 1025602\n",
            "Total Columns: 2\n",
            "First 3 rows:\n",
            "                 PATHOLOGY                                          NARRATIVE\n",
            "0                     URTI  I am an 18-year-old male. I came into the clin...\n",
            "1  HIV (initial infection)  I am an 21-year-old male. I came into the clin...\n",
            "2                Pneumonia  I am an 19-year-old female. I came into the cl...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "print(\"1. Re-fitting the MultiLabelBinarizer on the FULL dataset...\")\n",
        "# Make sure TARGET_LIST exists\n",
        "df_full['TARGET_LIST'] = df_full['PATHOLOGY'].apply(lambda x: [x])\n",
        "\n",
        "# We use the full dataset so the Binarizer sees every single disease perfectly\n",
        "mlb.fit(df_full['TARGET_LIST'])\n",
        "\n",
        "print(\"2. Splitting 1 Million Rows into Train and Validation (80/20)...\")\n",
        "df_full_train, df_full_val = train_test_split(\n",
        "    df_full,\n",
        "    test_size=0.2,\n",
        "    stratify=df_full['PATHOLOGY'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"3. Initializing the massive Datasets (this takes a moment)...\")\n",
        "# We reuse the exact same DDXPlusDataset class we built earlier!\n",
        "train_dataset_full = DDXPlusDataset(df_full_train, tokenizer, mlb, max_len=128)\n",
        "val_dataset_full = DDXPlusDataset(df_full_val, tokenizer, mlb, max_len=128)\n",
        "\n",
        "print(\"4. Creating the Production DataLoaders...\")\n",
        "BATCH_SIZE = 16 # Safe memory limit for the free Colab T4 GPU\n",
        "train_loader_full = DataLoader(train_dataset_full, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader_full = DataLoader(val_dataset_full, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(\"\\n--- PRODUCTION DATA PIPELINE READY ---\")\n",
        "print(f\"Total Training Patients: {len(train_dataset_full)}\")\n",
        "print(f\"Total Validation Patients: {len(val_dataset_full)}\")\n",
        "print(f\"Total Training Batches per Epoch: {len(train_loader_full)}\")"
      ],
      "metadata": {
        "id": "fIkqgxJ04kBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "209eded7-b72f-4a05-952e-9c1ad046ccb2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Re-fitting the MultiLabelBinarizer on the FULL dataset...\n",
            "2. Splitting 1 Million Rows into Train and Validation (80/20)...\n",
            "3. Initializing the massive Datasets (this takes a moment)...\n",
            "4. Creating the Production DataLoaders...\n",
            "\n",
            "--- PRODUCTION DATA PIPELINE READY ---\n",
            "Total Training Patients: 820481\n",
            "Total Validation Patients: 205121\n",
            "Total Training Batches per Epoch: 51281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Setup the Engine\n",
        "checkpoint_path = '/content/drive/MyDrive/healbridge/checkpoints/heal_bridge_best_model.pt'\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "scaler = torch.cuda.amp.GradScaler() # Fresh scaler for the resumed AMP loop\n",
        "\n",
        "# 2. Load the Checkpoint\n",
        "print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
        "checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "# 3. Restore the Brain and Memory\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "start_epoch = checkpoint['epoch']\n",
        "best_val_loss = checkpoint['loss']\n",
        "EPOCHS = 3\n",
        "\n",
        "print(\"-\" * 40)\n",
        "print(f\"✅ Successfully restored!\")\n",
        "print(f\"Resuming from Epoch: {start_epoch + 1}\")\n",
        "print(f\"Previous Best Validation Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "# 4. The Resumed High-Speed AMP Loop\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    print(f\"\\n======== Epoch {epoch+1} / {EPOCHS} ========\")\n",
        "\n",
        "    # --- TRAINING ---\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    train_loop = tqdm(train_loader_full, leave=True, desc=\"Training\")\n",
        "\n",
        "    for batch in train_loop:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
        "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
        "        targets = batch['targets'].to(device, non_blocking=True)\n",
        "\n",
        "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, targets)\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader_full)\n",
        "    print(f\"\\n>>> Avg Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # --- VALIDATION ---\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    val_loop = tqdm(val_loader_full, leave=True, desc=\"Validation\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loop:\n",
        "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
        "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
        "            targets = batch['targets'].to(device, non_blocking=True)\n",
        "\n",
        "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                loss = criterion(outputs.logits, targets)\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "            val_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader_full)\n",
        "    print(f\"\\n>>> Avg Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # --- CHECKPOINTING ---\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        print(f\"🌟 Validation loss improved from {best_val_loss:.4f} to {avg_val_loss:.4f}!\")\n",
        "        print(\"💾 Saving the brain to Google Drive...\")\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': avg_val_loss\n",
        "        }\n",
        "        torch.save(checkpoint, checkpoint_path)\n",
        "        best_val_loss = avg_val_loss\n",
        "        print(\"✅ Save complete.\\n\")\n",
        "    else:\n",
        "        print(\"No improvement this epoch. Skipping save.\\n\")"
      ],
      "metadata": {
        "id": "ES5JiRVn4j6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e902a12c-2e32-41e0-8c18-a98242935cbf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint from: /content/drive/MyDrive/healbridge/checkpoints/heal_bridge_best_model.pt\n",
            "----------------------------------------\n",
            "✅ Successfully restored!\n",
            "Resuming from Epoch: 2\n",
            "Previous Best Validation Loss: 0.0021\n",
            "\n",
            "======== Epoch 2 / 3 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 51281/51281 [2:08:14<00:00,  6.66it/s, loss=2.28e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Avg Training Loss: 0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 12821/12821 [09:52<00:00, 21.62it/s, loss=8.92e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Avg Validation Loss: 0.0020\n",
            "🌟 Validation loss improved from 0.0021 to 0.0020!\n",
            "💾 Saving the brain to Google Drive...\n",
            "✅ Save complete.\n",
            "\n",
            "\n",
            "======== Epoch 3 / 3 ========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 51281/51281 [2:07:41<00:00,  6.69it/s, loss=0.0169]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Avg Training Loss: 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 12821/12821 [10:00<00:00, 21.35it/s, loss=4.72e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Avg Validation Loss: 0.0019\n",
            "🌟 Validation loss improved from 0.0020 to 0.0019!\n",
            "💾 Saving the brain to Google Drive...\n",
            "✅ Save complete.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "729tdtK24j34"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0hLAjhjK4j1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3efG_zHRFJg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "704Gf1qMFJdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mYWpL-d4FJal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hEIn_jvWFJX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1jNwaeI4FJVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UwHLTEwNFJSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "biADru2iFJPz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}