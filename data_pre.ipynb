{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a22182dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Evidences (Symptoms/Antecedents) loaded: 223\n",
      "Total Conditions (Pathologies) loaded: 49\n",
      "----------------------------------------\n",
      "--- Structure of Evidence: E_53 ---\n",
      "{\n",
      "    \"name\": \"E_53\",\n",
      "    \"code_question\": \"E_53\",\n",
      "    \"question_fr\": \"Avez-vous de la douleur \\u00e0 quelque part en lien avec votre raison de consultation?\",\n",
      "    \"question_en\": \"Do you have pain somewhere, related to your reason for consulting?\",\n",
      "    \"is_antecedent\": false,\n",
      "    \"default_value\": 0,\n",
      "    \"value_meaning\": {},\n",
      "    \"possible-values\": [],\n",
      "    \"data_type\": \"B\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 1. Load the JSON files\n",
    "with open('release_evidences.json', 'r', encoding='utf-8') as f:\n",
    "    evidences = json.load(f)\n",
    "\n",
    "with open('release_conditions.json', 'r', encoding='utf-8') as f:\n",
    "    conditions = json.load(f)\n",
    "\n",
    "# 2. Print basic stats to ensure they loaded correctly\n",
    "print(f\"Total Evidences (Symptoms/Antecedents) loaded: {len(evidences)}\")\n",
    "print(f\"Total Conditions (Pathologies) loaded: {len(conditions)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 3. Inspect a specific Binary Evidence (e.g., a cough)\n",
    "sample_evidence_code = 'E_53' # E_53 is usually a common symptom\n",
    "if sample_evidence_code in evidences:\n",
    "    print(f\"--- Structure of Evidence: {sample_evidence_code} ---\")\n",
    "    print(json.dumps(evidences[sample_evidence_code], indent=4))\n",
    "else:\n",
    "    print(f\"Could not find {sample_evidence_code}. Let's try the first item in the dictionary.\")\n",
    "    first_key = list(evidences.keys())[0]\n",
    "    print(json.dumps(evidences[first_key], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944dd010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Structure of Complex Evidence: E_55 ---\n",
      "{\n",
      "    \"name\": \"E_55\",\n",
      "    \"code_question\": \"E_53\",\n",
      "    \"question_fr\": \"Avez-vous de la douleur quelque part?\",\n",
      "    \"question_en\": \"Do you feel pain somewhere?\",\n",
      "    \"is_antecedent\": false,\n",
      "    \"default_value\": \"V_123\",\n",
      "    \"value_meaning\": {\n",
      "        \"V_123\": {\n",
      "            \"fr\": \"nulle part\",\n",
      "            \"en\": \"nowhere\"\n",
      "        },\n",
      "        \"V_14\": {\n",
      "            \"fr\": \"aile iliaque(D)\",\n",
      "            \"en\": \"iliac wing(R)\"\n",
      "        },\n",
      "        \"V_15\": {\n",
      "            \"fr\": \"aile iliaque(G)\",\n",
      "            \"en\": \"iliac wing(L)\"\n",
      "        },\n",
      "        \"V_16\": {\n",
      "            \"fr\": \"aine(D)\",\n",
      "            \"en\": \"groin(R)\"\n",
      "        },\n",
      "        \"V_17\": {\n",
      "            \"fr\": \"aine(G)\",\n",
      "            \"en\": \"groin(L)\"\n",
      "        },\n",
      "        \"V_19\": {\n",
      "            \"fr\": \"aisselle(G)\",\n",
      "            \"en\": \"axilla(L)\"\n",
      "        },\n",
      "        \"V_18\": {\n",
      "            \"fr\": \"aisselle(D)\",\n",
      "            \"en\": \"axilla(R)\"\n",
      "        },\n",
      "        \"V_20\": {\n",
      "            \"fr\": \"amygdale(D)\",\n",
      "            \"en\": \"tonsil(R)\"\n",
      "        },\n",
      "        \"V_21\": {\n",
      "            \"fr\": \"amygdale(G)\",\n",
      "            \"en\": \"tonsil(L)\"\n",
      "        },\n",
      "        \"V_22\": {\n",
      "            \"fr\": \"anus\",\n",
      "            \"en\": \"anus\"\n",
      "        },\n",
      "        \"V_26\": {\n",
      "            \"fr\": \"arri\\u00e8re du cou\",\n",
      "            \"en\": \"back of the neck\"\n",
      "        },\n",
      "        \"V_25\": {\n",
      "            \"fr\": \"arri\\u00e8re de t\\u00eate\",\n",
      "            \"en\": \"back of head\"\n",
      "        },\n",
      "        \"V_30\": {\n",
      "            \"fr\": \"biceps(D)\",\n",
      "            \"en\": \"biceps(R)\"\n",
      "        },\n",
      "        \"V_31\": {\n",
      "            \"fr\": \"biceps(G)\",\n",
      "            \"en\": \"biceps(L)\"\n",
      "        },\n",
      "        \"V_32\": {\n",
      "            \"fr\": \"bouche\",\n",
      "            \"en\": \"mouth\"\n",
      "        },\n",
      "        \"V_33\": {\n",
      "            \"fr\": \"cartilage thyroidien\",\n",
      "            \"en\": \"thyroid cartilage\"\n",
      "        },\n",
      "        \"V_34\": {\n",
      "            \"fr\": \"cheville(D)\",\n",
      "            \"en\": \"ankle(R)\"\n",
      "        },\n",
      "        \"V_35\": {\n",
      "            \"fr\": \"cheville(G)\",\n",
      "            \"en\": \"ankle(L)\"\n",
      "        },\n",
      "        \"V_36\": {\n",
      "            \"fr\": \"clitoris\",\n",
      "            \"en\": \"clitoris\"\n",
      "        },\n",
      "        \"V_37\": {\n",
      "            \"fr\": \"coccyx\",\n",
      "            \"en\": \"coccyx\"\n",
      "        },\n",
      "        \"V_38\": {\n",
      "            \"fr\": \"colonne cervicale\",\n",
      "            \"en\": \"cervical spine\"\n",
      "        },\n",
      "        \"V_39\": {\n",
      "            \"fr\": \"colonne dorsale\",\n",
      "            \"en\": \"thoracic spine\"\n",
      "        },\n",
      "        \"V_40\": {\n",
      "            \"fr\": \"colonne lombaire\",\n",
      "            \"en\": \"lumbar spine\"\n",
      "        },\n",
      "        \"V_41\": {\n",
      "            \"fr\": \"commissure(D)\",\n",
      "            \"en\": \"commissure(R)\"\n",
      "        },\n",
      "        \"V_42\": {\n",
      "            \"fr\": \"commissure(G)\",\n",
      "            \"en\": \"commissure(L)\"\n",
      "        },\n",
      "        \"V_49\": {\n",
      "            \"fr\": \"cr\\u00eate iliaque(D)\",\n",
      "            \"en\": \"iliac crest(R)\"\n",
      "        },\n",
      "        \"V_50\": {\n",
      "            \"fr\": \"cr\\u00eate iliaque(G)\",\n",
      "            \"en\": \"iliac crest(L)\"\n",
      "        },\n",
      "        \"V_51\": {\n",
      "            \"fr\": \"cuisse(D)\",\n",
      "            \"en\": \"thigh(R)\"\n",
      "        },\n",
      "        \"V_52\": {\n",
      "            \"fr\": \"cuisse(G)\",\n",
      "            \"en\": \"thigh(L)\"\n",
      "        },\n",
      "        \"V_57\": {\n",
      "            \"fr\": \"dents inf\\u00e9rieures(D)\",\n",
      "            \"en\": \"lower teeth(R)\"\n",
      "        },\n",
      "        \"V_58\": {\n",
      "            \"fr\": \"dents inf\\u00e9rieures(G)\",\n",
      "            \"en\": \"lower teeth(L)\"\n",
      "        },\n",
      "        \"V_59\": {\n",
      "            \"fr\": \"dents sup\\u00e9rieures(D)\",\n",
      "            \"en\": \"upper teeth(R)\"\n",
      "        },\n",
      "        \"V_60\": {\n",
      "            \"fr\": \"dents sup\\u00e9rieures(G)\",\n",
      "            \"en\": \"upper teeth(L)\"\n",
      "        },\n",
      "        \"V_67\": {\n",
      "            \"fr\": \"doigt(index)(D)\",\n",
      "            \"en\": \"finger (index)(R)\"\n",
      "        },\n",
      "        \"V_68\": {\n",
      "            \"fr\": \"doigt(index)(G)\",\n",
      "            \"en\": \"finger (index)(L)\"\n",
      "        },\n",
      "        \"V_69\": {\n",
      "            \"fr\": \"doigt(majeur)(D)\",\n",
      "            \"en\": \"finger (middle)(R)\"\n",
      "        },\n",
      "        \"V_70\": {\n",
      "            \"fr\": \"doigt(majeur)(G)\",\n",
      "            \"en\": \"finger (middle)(L)\"\n",
      "        },\n",
      "        \"V_63\": {\n",
      "            \"fr\": \"doigt(annulaire)(D)\",\n",
      "            \"en\": \"finger (ring finger)(R)\"\n",
      "        },\n",
      "        \"V_64\": {\n",
      "            \"fr\": \"doigt(annulaire)(G)\",\n",
      "            \"en\": \"finger (ring finger)(L)\"\n",
      "        },\n",
      "        \"V_65\": {\n",
      "            \"fr\": \"doigt(auriculaire)(D)\",\n",
      "            \"en\": \"finger (little finger)(R)\"\n",
      "        },\n",
      "        \"V_66\": {\n",
      "            \"fr\": \"doigt(auriculaire)(G)\",\n",
      "            \"en\": \"finger (little finger)(L)\"\n",
      "        },\n",
      "        \"V_62\": {\n",
      "            \"fr\": \"dessus de t\\u00eate\",\n",
      "            \"en\": \"top of the head\"\n",
      "        },\n",
      "        \"V_194\": {\n",
      "            \"fr\": \"\\u00e9paule(D)\",\n",
      "            \"en\": \"shoulder(R)\"\n",
      "        },\n",
      "        \"V_195\": {\n",
      "            \"fr\": \"\\u00e9paule(G)\",\n",
      "            \"en\": \"shoulder(L)\"\n",
      "        },\n",
      "        \"V_197\": {\n",
      "            \"fr\": \"\\u00e9pigastre\",\n",
      "            \"en\": \"epigastric\"\n",
      "        },\n",
      "        \"V_27\": {\n",
      "            \"fr\": \"avant-bras(D)\",\n",
      "            \"en\": \"forearm(R)\"\n",
      "        },\n",
      "        \"V_28\": {\n",
      "            \"fr\": \"avant-bras(G)\",\n",
      "            \"en\": \"forearm(L)\"\n",
      "        },\n",
      "        \"V_76\": {\n",
      "            \"fr\": \"face dorsale main(D)\",\n",
      "            \"en\": \"dorsal aspect of the hand(R)\"\n",
      "        },\n",
      "        \"V_77\": {\n",
      "            \"fr\": \"face dorsale main(G)\",\n",
      "            \"en\": \"dorsal aspect of the hand(L)\"\n",
      "        },\n",
      "        \"V_72\": {\n",
      "            \"fr\": \"face dorsale du pied(D)\",\n",
      "            \"en\": \"dorsal aspect of the foot(R)\"\n",
      "        },\n",
      "        \"V_73\": {\n",
      "            \"fr\": \"face dorsale du pied(G)\",\n",
      "            \"en\": \"dorsal aspect of the foot(L)\"\n",
      "        },\n",
      "        \"V_74\": {\n",
      "            \"fr\": \"face dorsale du poignet(D)\",\n",
      "            \"en\": \"dorsal aspect of the wrist(R)\"\n",
      "        },\n",
      "        \"V_75\": {\n",
      "            \"fr\": \"face dorsale du poignet(G)\",\n",
      "            \"en\": \"dorsal aspect of the wrist(L)\"\n",
      "        },\n",
      "        \"V_149\": {\n",
      "            \"fr\": \"plante du pied(D)\",\n",
      "            \"en\": \"sole(R)\"\n",
      "        },\n",
      "        \"V_150\": {\n",
      "            \"fr\": \"plante du pied(G)\",\n",
      "            \"en\": \"sole(L)\"\n",
      "        },\n",
      "        \"V_80\": {\n",
      "            \"fr\": \"face palmaire du poignet(D)\",\n",
      "            \"en\": \"palmar face of the wrist(R)\"\n",
      "        },\n",
      "        \"V_81\": {\n",
      "            \"fr\": \"face palmaire du poignet(G)\",\n",
      "            \"en\": \"palmar face of the wrist(L)\"\n",
      "        },\n",
      "        \"V_43\": {\n",
      "            \"fr\": \"cot\\u00e9 lateral du pied(D)\",\n",
      "            \"en\": \"lateral side of the foot(R)\"\n",
      "        },\n",
      "        \"V_44\": {\n",
      "            \"fr\": \"cot\\u00e9 lateral du pied(G)\",\n",
      "            \"en\": \"lateral side of the foot(L)\"\n",
      "        },\n",
      "        \"V_82\": {\n",
      "            \"fr\": \"fesse(D)\",\n",
      "            \"en\": \"buttock(R)\"\n",
      "        },\n",
      "        \"V_83\": {\n",
      "            \"fr\": \"fesse(G)\",\n",
      "            \"en\": \"buttock(L)\"\n",
      "        },\n",
      "        \"V_84\": {\n",
      "            \"fr\": \"flanc(D)\",\n",
      "            \"en\": \"flank(R)\"\n",
      "        },\n",
      "        \"V_85\": {\n",
      "            \"fr\": \"flanc(G)\",\n",
      "            \"en\": \"flank(L)\"\n",
      "        },\n",
      "        \"V_78\": {\n",
      "            \"fr\": \"face palmaire de l'avant-bras(D)\",\n",
      "            \"en\": \"palmar side of the forearm(R)\"\n",
      "        },\n",
      "        \"V_79\": {\n",
      "            \"fr\": \"face palmaire de l'avant-bras(G)\",\n",
      "            \"en\": \"palmar side of the forearm(L)\"\n",
      "        },\n",
      "        \"V_87\": {\n",
      "            \"fr\": \"fosse iliaque(D)\",\n",
      "            \"en\": \"iliac fossa(R)\"\n",
      "        },\n",
      "        \"V_88\": {\n",
      "            \"fr\": \"fosse iliaque(G)\",\n",
      "            \"en\": \"iliac fossa(L)\"\n",
      "        },\n",
      "        \"V_89\": {\n",
      "            \"fr\": \"front\",\n",
      "            \"en\": \"forehead\"\n",
      "        },\n",
      "        \"V_92\": {\n",
      "            \"fr\": \"genou(D)\",\n",
      "            \"en\": \"knee(R)\"\n",
      "        },\n",
      "        \"V_93\": {\n",
      "            \"fr\": \"genou(G)\",\n",
      "            \"en\": \"knee(L)\"\n",
      "        },\n",
      "        \"V_90\": {\n",
      "            \"fr\": \"gencive inf\\u00e9rieure\",\n",
      "            \"en\": \"lower gum\"\n",
      "        },\n",
      "        \"V_47\": {\n",
      "            \"fr\": \"creux poplit\\u00e9(D)\",\n",
      "            \"en\": \"popliteal fossa(R)\"\n",
      "        },\n",
      "        \"V_48\": {\n",
      "            \"fr\": \"creux poplit\\u00e9(G)\",\n",
      "            \"en\": \"popliteal fossa(L)\"\n",
      "        },\n",
      "        \"V_91\": {\n",
      "            \"fr\": \"gencive sup\\u00e9rieure\",\n",
      "            \"en\": \"upper gum\"\n",
      "        },\n",
      "        \"V_94\": {\n",
      "            \"fr\": \"gland\",\n",
      "            \"en\": \"glans\"\n",
      "        },\n",
      "        \"V_95\": {\n",
      "            \"fr\": \"grande l\\u00e8vre(D)\",\n",
      "            \"en\": \"labia majora(R)\"\n",
      "        },\n",
      "        \"V_96\": {\n",
      "            \"fr\": \"grande l\\u00e8vre(G)\",\n",
      "            \"en\": \"labia majora(L)\"\n",
      "        },\n",
      "        \"V_97\": {\n",
      "            \"fr\": \"gros orteil(D)\",\n",
      "            \"en\": \"big toe(R)\"\n",
      "        },\n",
      "        \"V_98\": {\n",
      "            \"fr\": \"gros orteil(G)\",\n",
      "            \"en\": \"big toe(L)\"\n",
      "        },\n",
      "        \"V_99\": {\n",
      "            \"fr\": \"hanche(D)\",\n",
      "            \"en\": \"hip(R)\"\n",
      "        },\n",
      "        \"V_100\": {\n",
      "            \"fr\": \"hanche(G)\",\n",
      "            \"en\": \"hip(L)\"\n",
      "        },\n",
      "        \"V_102\": {\n",
      "            \"fr\": \"hymen\",\n",
      "            \"en\": \"hymen\"\n",
      "        },\n",
      "        \"V_103\": {\n",
      "            \"fr\": \"hypochondre(D)\",\n",
      "            \"en\": \"hypochondrium(R)\"\n",
      "        },\n",
      "        \"V_104\": {\n",
      "            \"fr\": \"hypochondre(G)\",\n",
      "            \"en\": \"hypochondrium(L)\"\n",
      "        },\n",
      "        \"V_105\": {\n",
      "            \"fr\": \"ischio(D)\",\n",
      "            \"en\": \"ischio jambier(R)\"\n",
      "        },\n",
      "        \"V_106\": {\n",
      "            \"fr\": \"ischio(G)\",\n",
      "            \"en\": \"ischio jambier(L)\"\n",
      "        },\n",
      "        \"V_108\": {\n",
      "            \"fr\": \"joue(D)\",\n",
      "            \"en\": \"cheek(R)\"\n",
      "        },\n",
      "        \"V_109\": {\n",
      "            \"fr\": \"joue(G)\",\n",
      "            \"en\": \"cheek(L)\"\n",
      "        },\n",
      "        \"V_110\": {\n",
      "            \"fr\": \"joue interne(D)\",\n",
      "            \"en\": \"internal cheek(R)\"\n",
      "        },\n",
      "        \"V_111\": {\n",
      "            \"fr\": \"joue interne(G)\",\n",
      "            \"en\": \"internal cheek(L)\"\n",
      "        },\n",
      "        \"V_53\": {\n",
      "            \"fr\": \"c\\u00f4t\\u00e9 du cou(D)\",\n",
      "            \"en\": \"side of the neck(R)\"\n",
      "        },\n",
      "        \"V_54\": {\n",
      "            \"fr\": \"c\\u00f4t\\u00e9 du cou(G)\",\n",
      "            \"en\": \"side of the neck(L)\"\n",
      "        },\n",
      "        \"V_55\": {\n",
      "            \"fr\": \"c\\u00f4t\\u00e9 du thorax(D)\",\n",
      "            \"en\": \"side of the chest(R)\"\n",
      "        },\n",
      "        \"V_56\": {\n",
      "            \"fr\": \"c\\u00f4t\\u00e9 du thorax(G)\",\n",
      "            \"en\": \"side of the chest(L)\"\n",
      "        },\n",
      "        \"V_116\": {\n",
      "            \"fr\": \"l\\u00e8vre inferieure(D)\",\n",
      "            \"en\": \"bottom lip(R)\"\n",
      "        },\n",
      "        \"V_117\": {\n",
      "            \"fr\": \"l\\u00e8vre sup\\u00e9rieure(D)\",\n",
      "            \"en\": \"upper lip(R)\"\n",
      "        },\n",
      "        \"V_113\": {\n",
      "            \"fr\": \"loge renale(D)\",\n",
      "            \"en\": \"renal fossa(R)\"\n",
      "        },\n",
      "        \"V_114\": {\n",
      "            \"fr\": \"loge renale(G)\",\n",
      "            \"en\": \"renal fossa(L)\"\n",
      "        },\n",
      "        \"V_115\": {\n",
      "            \"fr\": \"luette\",\n",
      "            \"en\": \"uvula\"\n",
      "        },\n",
      "        \"V_121\": {\n",
      "            \"fr\": \"m\\u00e2choire\",\n",
      "            \"en\": \"jaw\"\n",
      "        },\n",
      "        \"V_118\": {\n",
      "            \"fr\": \"menton\",\n",
      "            \"en\": \"chin\"\n",
      "        },\n",
      "        \"V_29\": {\n",
      "            \"fr\": \"bas du thorax\",\n",
      "            \"en\": \"lower chest\"\n",
      "        },\n",
      "        \"V_119\": {\n",
      "            \"fr\": \"mollet(D)\",\n",
      "            \"en\": \"calf(R)\"\n",
      "        },\n",
      "        \"V_120\": {\n",
      "            \"fr\": \"mollet(G)\",\n",
      "            \"en\": \"calf(L)\"\n",
      "        },\n",
      "        \"V_122\": {\n",
      "            \"fr\": \"nez\",\n",
      "            \"en\": \"nose\"\n",
      "        },\n",
      "        \"V_124\": {\n",
      "            \"fr\": \"occiput\",\n",
      "            \"en\": \"occiput\"\n",
      "        },\n",
      "        \"V_125\": {\n",
      "            \"fr\": \"oeil(D)\",\n",
      "            \"en\": \"eye(R)\"\n",
      "        },\n",
      "        \"V_126\": {\n",
      "            \"fr\": \"oeil(G)\",\n",
      "            \"en\": \"eye(L)\"\n",
      "        },\n",
      "        \"V_127\": {\n",
      "            \"fr\": \"omoplate(D)\",\n",
      "            \"en\": \"scapula(R)\"\n",
      "        },\n",
      "        \"V_128\": {\n",
      "            \"fr\": \"omoplate(G)\",\n",
      "            \"en\": \"scapula(L)\"\n",
      "        },\n",
      "        \"V_129\": {\n",
      "            \"fr\": \"oreille(D)\",\n",
      "            \"en\": \"ear(R)\"\n",
      "        },\n",
      "        \"V_130\": {\n",
      "            \"fr\": \"oreille(G)\",\n",
      "            \"en\": \"ear(L)\"\n",
      "        },\n",
      "        \"V_131\": {\n",
      "            \"fr\": \"orteil (1)(D)\",\n",
      "            \"en\": \"toe (1)(R)\"\n",
      "        },\n",
      "        \"V_132\": {\n",
      "            \"fr\": \"orteil (1)(G)\",\n",
      "            \"en\": \"toe (1)(L)\"\n",
      "        },\n",
      "        \"V_133\": {\n",
      "            \"fr\": \"orteil (2)(D)\",\n",
      "            \"en\": \"toe (2)(R)\"\n",
      "        },\n",
      "        \"V_134\": {\n",
      "            \"fr\": \"orteil (2)(G)\",\n",
      "            \"en\": \"toe (2)(L)\"\n",
      "        },\n",
      "        \"V_135\": {\n",
      "            \"fr\": \"orteil (3)(D)\",\n",
      "            \"en\": \"toe (3)(R)\"\n",
      "        },\n",
      "        \"V_136\": {\n",
      "            \"fr\": \"orteil (3)(G)\",\n",
      "            \"en\": \"toe (3)(L)\"\n",
      "        },\n",
      "        \"V_144\": {\n",
      "            \"fr\": \"petit orteil (4)(D)\",\n",
      "            \"en\": \"little toe (4)(R)\"\n",
      "        },\n",
      "        \"V_145\": {\n",
      "            \"fr\": \"petit orteil (4)(G)\",\n",
      "            \"en\": \"little toe (4)(L)\"\n",
      "        },\n",
      "        \"V_45\": {\n",
      "            \"fr\": \"coude(D)\",\n",
      "            \"en\": \"elbow(R)\"\n",
      "        },\n",
      "        \"V_46\": {\n",
      "            \"fr\": \"coude(G)\",\n",
      "            \"en\": \"elbow(L)\"\n",
      "        },\n",
      "        \"V_137\": {\n",
      "            \"fr\": \"palais\",\n",
      "            \"en\": \"palace\"\n",
      "        },\n",
      "        \"V_170\": {\n",
      "            \"fr\": \"thorax post\\u00e9rieur(D)\",\n",
      "            \"en\": \"posterior chest wall(R)\"\n",
      "        },\n",
      "        \"V_171\": {\n",
      "            \"fr\": \"thorax post\\u00e9rieur(G)\",\n",
      "            \"en\": \"posterior chest wall(L)\"\n",
      "        },\n",
      "        \"V_139\": {\n",
      "            \"fr\": \"paroi vaginale\",\n",
      "            \"en\": \"vaginal wall\"\n",
      "        },\n",
      "        \"V_140\": {\n",
      "            \"fr\": \"paroi vaginale(D)\",\n",
      "            \"en\": \"vaginal wall(R)\"\n",
      "        },\n",
      "        \"V_141\": {\n",
      "            \"fr\": \"paroi vaginale(G)\",\n",
      "            \"en\": \"vaginal wall(L)\"\n",
      "        },\n",
      "        \"V_142\": {\n",
      "            \"fr\": \"paume(D)\",\n",
      "            \"en\": \"palm(R)\"\n",
      "        },\n",
      "        \"V_143\": {\n",
      "            \"fr\": \"paume(G)\",\n",
      "            \"en\": \"palm(L)\"\n",
      "        },\n",
      "        \"V_155\": {\n",
      "            \"fr\": \"p\\u00e9nis\",\n",
      "            \"en\": \"penis\"\n",
      "        },\n",
      "        \"V_187\": {\n",
      "            \"fr\": \"ventre\",\n",
      "            \"en\": \"belly\"\n",
      "        },\n",
      "        \"V_146\": {\n",
      "            \"fr\": \"petite l\\u00e8vre(D)\",\n",
      "            \"en\": \"labia minora(R)\"\n",
      "        },\n",
      "        \"V_147\": {\n",
      "            \"fr\": \"petite l\\u00e8vre(G)\",\n",
      "            \"en\": \"labia minora(L)\"\n",
      "        },\n",
      "        \"V_148\": {\n",
      "            \"fr\": \"pharynx\",\n",
      "            \"en\": \"pharynx\"\n",
      "        },\n",
      "        \"V_23\": {\n",
      "            \"fr\": \"arri\\u00e8re de la cheville(D)\",\n",
      "            \"en\": \"posterior aspect of the ankle(R)\"\n",
      "        },\n",
      "        \"V_24\": {\n",
      "            \"fr\": \"arri\\u00e8re de la cheville(G)\",\n",
      "            \"en\": \"posterior aspect of the ankle(L)\"\n",
      "        },\n",
      "        \"V_151\": {\n",
      "            \"fr\": \"pouce(D)\",\n",
      "            \"en\": \"thumb(R)\"\n",
      "        },\n",
      "        \"V_152\": {\n",
      "            \"fr\": \"pouce(G)\",\n",
      "            \"en\": \"thumb(L)\"\n",
      "        },\n",
      "        \"V_158\": {\n",
      "            \"fr\": \"scrotum\",\n",
      "            \"en\": \"scrotum\"\n",
      "        },\n",
      "        \"V_159\": {\n",
      "            \"fr\": \"sein(D)\",\n",
      "            \"en\": \"breast(R)\"\n",
      "        },\n",
      "        \"V_160\": {\n",
      "            \"fr\": \"sein(G)\",\n",
      "            \"en\": \"breast(L)\"\n",
      "        },\n",
      "        \"V_162\": {\n",
      "            \"fr\": \"sous la langue\",\n",
      "            \"en\": \"under the tongue\"\n",
      "        },\n",
      "        \"V_163\": {\n",
      "            \"fr\": \"sous la machoire\",\n",
      "            \"en\": \"under the jaw\"\n",
      "        },\n",
      "        \"V_101\": {\n",
      "            \"fr\": \"haut du thorax\",\n",
      "            \"en\": \"upper chest\"\n",
      "        },\n",
      "        \"V_61\": {\n",
      "            \"fr\": \"dessus de la langue\",\n",
      "            \"en\": \"above the tongue\"\n",
      "        },\n",
      "        \"V_153\": {\n",
      "            \"fr\": \"pubis\",\n",
      "            \"en\": \"pubis\"\n",
      "        },\n",
      "        \"V_164\": {\n",
      "            \"fr\": \"talon(D)\",\n",
      "            \"en\": \"heel(R)\"\n",
      "        },\n",
      "        \"V_165\": {\n",
      "            \"fr\": \"talon(G)\",\n",
      "            \"en\": \"heel(L)\"\n",
      "        },\n",
      "        \"V_166\": {\n",
      "            \"fr\": \"tempe(D)\",\n",
      "            \"en\": \"temple(R)\"\n",
      "        },\n",
      "        \"V_167\": {\n",
      "            \"fr\": \"tempe(G)\",\n",
      "            \"en\": \"temple(L)\"\n",
      "        },\n",
      "        \"V_168\": {\n",
      "            \"fr\": \"testicule(D)\",\n",
      "            \"en\": \"testicle(R)\"\n",
      "        },\n",
      "        \"V_169\": {\n",
      "            \"fr\": \"testicule(G)\",\n",
      "            \"en\": \"testicle(L)\"\n",
      "        },\n",
      "        \"V_172\": {\n",
      "            \"fr\": \"tibia(D)\",\n",
      "            \"en\": \"tibia(R)\"\n",
      "        },\n",
      "        \"V_173\": {\n",
      "            \"fr\": \"tibia(G)\",\n",
      "            \"en\": \"tibia(L)\"\n",
      "        },\n",
      "        \"V_175\": {\n",
      "            \"fr\": \"trap\\u00e8ze(D)\",\n",
      "            \"en\": \"trapezius(R)\"\n",
      "        },\n",
      "        \"V_176\": {\n",
      "            \"fr\": \"trap\\u00e8ze(G)\",\n",
      "            \"en\": \"trapezius(L)\"\n",
      "        },\n",
      "        \"V_174\": {\n",
      "            \"fr\": \"trach\\u00e9e\",\n",
      "            \"en\": \"trachea\"\n",
      "        },\n",
      "        \"V_177\": {\n",
      "            \"fr\": \"triceps(D)\",\n",
      "            \"en\": \"triceps(R)\"\n",
      "        },\n",
      "        \"V_178\": {\n",
      "            \"fr\": \"triceps(G)\",\n",
      "            \"en\": \"triceps(L)\"\n",
      "        },\n",
      "        \"V_185\": {\n",
      "            \"fr\": \"ur\\u00e8tre\",\n",
      "            \"en\": \"urethra\"\n",
      "        },\n",
      "        \"V_186\": {\n",
      "            \"fr\": \"vagin\",\n",
      "            \"en\": \"vagina\"\n",
      "        },\n",
      "        \"V_188\": {\n",
      "            \"fr\": \"vermillon(D)\",\n",
      "            \"en\": \"vermilion(R)\"\n",
      "        },\n",
      "        \"V_189\": {\n",
      "            \"fr\": \"vermillon(G)\",\n",
      "            \"en\": \"vermilion(L)\"\n",
      "        },\n",
      "        \"V_190\": {\n",
      "            \"fr\": \"vestibule\",\n",
      "            \"en\": \"vulval vestibule\"\n",
      "        }\n",
      "    },\n",
      "    \"possible-values\": [\n",
      "        \"V_123\",\n",
      "        \"V_14\",\n",
      "        \"V_15\",\n",
      "        \"V_16\",\n",
      "        \"V_17\",\n",
      "        \"V_18\",\n",
      "        \"V_19\",\n",
      "        \"V_20\",\n",
      "        \"V_21\",\n",
      "        \"V_22\",\n",
      "        \"V_23\",\n",
      "        \"V_24\",\n",
      "        \"V_25\",\n",
      "        \"V_26\",\n",
      "        \"V_27\",\n",
      "        \"V_28\",\n",
      "        \"V_29\",\n",
      "        \"V_30\",\n",
      "        \"V_31\",\n",
      "        \"V_32\",\n",
      "        \"V_33\",\n",
      "        \"V_34\",\n",
      "        \"V_35\",\n",
      "        \"V_36\",\n",
      "        \"V_37\",\n",
      "        \"V_38\",\n",
      "        \"V_39\",\n",
      "        \"V_40\",\n",
      "        \"V_41\",\n",
      "        \"V_42\",\n",
      "        \"V_43\",\n",
      "        \"V_44\",\n",
      "        \"V_45\",\n",
      "        \"V_46\",\n",
      "        \"V_47\",\n",
      "        \"V_48\",\n",
      "        \"V_49\",\n",
      "        \"V_50\",\n",
      "        \"V_51\",\n",
      "        \"V_52\",\n",
      "        \"V_53\",\n",
      "        \"V_54\",\n",
      "        \"V_55\",\n",
      "        \"V_56\",\n",
      "        \"V_57\",\n",
      "        \"V_58\",\n",
      "        \"V_59\",\n",
      "        \"V_60\",\n",
      "        \"V_61\",\n",
      "        \"V_62\",\n",
      "        \"V_63\",\n",
      "        \"V_64\",\n",
      "        \"V_65\",\n",
      "        \"V_66\",\n",
      "        \"V_67\",\n",
      "        \"V_68\",\n",
      "        \"V_69\",\n",
      "        \"V_70\",\n",
      "        \"V_72\",\n",
      "        \"V_73\",\n",
      "        \"V_74\",\n",
      "        \"V_75\",\n",
      "        \"V_76\",\n",
      "        \"V_77\",\n",
      "        \"V_78\",\n",
      "        \"V_79\",\n",
      "        \"V_80\",\n",
      "        \"V_81\",\n",
      "        \"V_82\",\n",
      "        \"V_83\",\n",
      "        \"V_84\",\n",
      "        \"V_85\",\n",
      "        \"V_87\",\n",
      "        \"V_88\",\n",
      "        \"V_89\",\n",
      "        \"V_90\",\n",
      "        \"V_91\",\n",
      "        \"V_92\",\n",
      "        \"V_93\",\n",
      "        \"V_94\",\n",
      "        \"V_95\",\n",
      "        \"V_96\",\n",
      "        \"V_97\",\n",
      "        \"V_98\",\n",
      "        \"V_99\",\n",
      "        \"V_100\",\n",
      "        \"V_101\",\n",
      "        \"V_102\",\n",
      "        \"V_103\",\n",
      "        \"V_104\",\n",
      "        \"V_105\",\n",
      "        \"V_106\",\n",
      "        \"V_108\",\n",
      "        \"V_109\",\n",
      "        \"V_110\",\n",
      "        \"V_111\",\n",
      "        \"V_113\",\n",
      "        \"V_114\",\n",
      "        \"V_115\",\n",
      "        \"V_116\",\n",
      "        \"V_117\",\n",
      "        \"V_118\",\n",
      "        \"V_119\",\n",
      "        \"V_120\",\n",
      "        \"V_121\",\n",
      "        \"V_122\",\n",
      "        \"V_124\",\n",
      "        \"V_125\",\n",
      "        \"V_126\",\n",
      "        \"V_127\",\n",
      "        \"V_128\",\n",
      "        \"V_129\",\n",
      "        \"V_130\",\n",
      "        \"V_131\",\n",
      "        \"V_132\",\n",
      "        \"V_133\",\n",
      "        \"V_134\",\n",
      "        \"V_135\",\n",
      "        \"V_136\",\n",
      "        \"V_137\",\n",
      "        \"V_139\",\n",
      "        \"V_140\",\n",
      "        \"V_141\",\n",
      "        \"V_142\",\n",
      "        \"V_143\",\n",
      "        \"V_144\",\n",
      "        \"V_145\",\n",
      "        \"V_146\",\n",
      "        \"V_147\",\n",
      "        \"V_148\",\n",
      "        \"V_149\",\n",
      "        \"V_150\",\n",
      "        \"V_151\",\n",
      "        \"V_152\",\n",
      "        \"V_153\",\n",
      "        \"V_155\",\n",
      "        \"V_158\",\n",
      "        \"V_159\",\n",
      "        \"V_160\",\n",
      "        \"V_162\",\n",
      "        \"V_163\",\n",
      "        \"V_164\",\n",
      "        \"V_165\",\n",
      "        \"V_166\",\n",
      "        \"V_167\",\n",
      "        \"V_168\",\n",
      "        \"V_169\",\n",
      "        \"V_170\",\n",
      "        \"V_171\",\n",
      "        \"V_172\",\n",
      "        \"V_173\",\n",
      "        \"V_174\",\n",
      "        \"V_175\",\n",
      "        \"V_176\",\n",
      "        \"V_177\",\n",
      "        \"V_178\",\n",
      "        \"V_185\",\n",
      "        \"V_186\",\n",
      "        \"V_187\",\n",
      "        \"V_188\",\n",
      "        \"V_189\",\n",
      "        \"V_190\",\n",
      "        \"V_194\",\n",
      "        \"V_195\",\n",
      "        \"V_197\"\n",
      "    ],\n",
      "    \"data_type\": \"M\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Search for a Categorical (C) or Multi-choice (M) evidence\n",
    "complex_evidence = None\n",
    "for code, details in evidences.items():\n",
    "    if details.get('data_type') in ['C', 'M']:\n",
    "        complex_evidence = details\n",
    "        break\n",
    "\n",
    "if complex_evidence:\n",
    "    print(f\"--- Structure of Complex Evidence: {complex_evidence['name']} ---\")\n",
    "    print(json.dumps(complex_evidence, indent=4))\n",
    "else:\n",
    "    print(\"No complex data types found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d63ff0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patient Records: 1025602\n",
      "--------------------------------------------------\n",
      "--- RAW PATIENT DATA (ROW 0) ---\n",
      "AGE: 18\n",
      "SEX: M\n",
      "PATHOLOGY (The Ground Truth Label): URTI\n",
      "INITIAL_EVIDENCE (The primary complaint): E_91\n",
      "\n",
      "FULL EVIDENCES LIST (19 items):\n",
      " - E_48\n",
      " - E_50\n",
      " - E_53\n",
      " - E_54_@_V_161\n",
      " - E_54_@_V_183\n",
      " - E_55_@_V_89\n",
      " - E_55_@_V_108\n",
      " - E_55_@_V_167\n",
      " - E_56_@_4\n",
      " - E_57_@_V_123\n",
      " - E_58_@_3\n",
      " - E_59_@_3\n",
      " - E_77\n",
      " - E_79\n",
      " - E_91\n",
      " - E_97\n",
      " - E_201\n",
      " - E_204_@_V_10\n",
      " - E_222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# 1. Load the training patients dataset\n",
    "# We use pd.read_csv even if the file doesn't have a .csv extension\n",
    "df_train = pd.read_csv('release_train_patients')\n",
    "\n",
    "# 2. Print the shape to see how many patients we have\n",
    "print(f\"Total Patient Records: {df_train.shape[0]}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 3. Extract and print the very first patient row\n",
    "first_patient = df_train.iloc[0]\n",
    "print(\"--- RAW PATIENT DATA (ROW 0) ---\")\n",
    "print(f\"AGE: {first_patient['AGE']}\")\n",
    "print(f\"SEX: {first_patient['SEX']}\")\n",
    "print(f\"PATHOLOGY (The Ground Truth Label): {first_patient['PATHOLOGY']}\")\n",
    "print(f\"INITIAL_EVIDENCE (The primary complaint): {first_patient['INITIAL_EVIDENCE']}\")\n",
    "\n",
    "# 4. Extract the full list of evidence for this patient\n",
    "# DDXPlus stores this column as a string that looks like a list, so we safely evaluate it\n",
    "evidence_list = ast.literal_eval(first_patient['EVIDENCES'])\n",
    "print(f\"\\nFULL EVIDENCES LIST ({len(evidence_list)} items):\")\n",
    "for item in evidence_list:\n",
    "    print(f\" - {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baea8a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GENERATED PATIENT NARRATIVE ---\n",
      "I am an 18-year-old male. I came in today because: Do you have a fever (either felt or measured with a thermometer)? Regarding 'Characterize your pain:', my answer is: sensitive, heavy. Regarding 'Do you feel pain somewhere?', my answer is: forehead, cheek(R), temple(L). Regarding 'How intense is the pain?', my answer is: 4. Regarding 'How precisely is the pain located?', my answer is: 3. Regarding 'How fast did the pain appear?', my answer is: 3. Regarding 'Have you traveled out of the country in the last 4 weeks?', my answer is: N. Additionally, I am experiencing the following: - Do you live with 4 or more people? - Have you had significantly increased sweating? - Do you have pain somewhere, related to your reason for consulting? - Do you have a cough that produces colored or more abundant sputum than usual? - Do you smoke cigarettes? - Do you have a sore throat? - Do you have a cough? - Are you exposed to secondhand cigarette smoke on a daily basis?\n",
      "-----------------------------------\n",
      "Target Pathology to Predict: URTI\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def translate_row_to_narrative(row_data, evidences_dict):\n",
    "    \"\"\"\n",
    "    Translates a single DDXPlus tabular row into a first-person narrative.\n",
    "    \"\"\"\n",
    "    # 1. Demographics Hook\n",
    "    age = row_data['AGE']\n",
    "    sex_str = \"male\" if row_data['SEX'] == 'M' else \"female\"\n",
    "    narrative = [f\"I am an {age}-year-old {sex_str}.\"]\n",
    "    \n",
    "    # 2. Extract Data\n",
    "    initial_ev = row_data['INITIAL_EVIDENCE']\n",
    "    # Safely evaluate the string representation of the list\n",
    "    all_evidences = ast.literal_eval(row_data['EVIDENCES']) \n",
    "    \n",
    "    # Remove the initial evidence from the general list to avoid repetition\n",
    "    if initial_ev in all_evidences:\n",
    "        all_evidences.remove(initial_ev)\n",
    "    \n",
    "    # 3. Setup temporary storage for grouping\n",
    "    binary_complaints = []\n",
    "    complex_complaints = {} # Format: {'E_55': ['forehead', 'cheek', 'temple']}\n",
    "\n",
    "    # 4. Process the Initial Evidence first (The main reason for visit)\n",
    "    # Note: In a full pipeline, we map this to a custom string. For now, we fetch the English question.\n",
    "    initial_question = evidences_dict.get(initial_ev, {}).get('question_en', 'I have a specific complaint.')\n",
    "    narrative.append(f\"I came in today because: {initial_question}\")\n",
    "\n",
    "    # 5. Process the remaining evidence list\n",
    "    for ev_string in all_evidences:\n",
    "        \n",
    "        # Handle Complex/Multi-choice types (e.g., E_55_@_V_89)\n",
    "        if '_@_' in ev_string:\n",
    "            code, value = ev_string.split('_@_')\n",
    "            \n",
    "            # TRAP AVOIDANCE: Skip 'nowhere' or baseline values\n",
    "            if value == 'V_123' or value == '0':\n",
    "                continue\n",
    "                \n",
    "            # Fetch the human-readable meaning from the dictionary\n",
    "            evidence_details = evidences_dict.get(code, {})\n",
    "            value_dict = evidence_details.get('value_meaning', {})\n",
    "            \n",
    "            # Extract the English translation of the specific value (e.g., 'forehead')\n",
    "            meaning_en = value_dict.get(value, {}).get('en', value)\n",
    "            \n",
    "            # Group it by the base code\n",
    "            if code not in complex_complaints:\n",
    "                complex_complaints[code] = []\n",
    "            complex_complaints[code].append(meaning_en)\n",
    "            \n",
    "        # Handle Simple Binary types (e.g., E_53)\n",
    "        else:\n",
    "            question_en = evidences_dict.get(ev_string, {}).get('question_en', ev_string)\n",
    "            binary_complaints.append(question_en)\n",
    "\n",
    "    # 6. Assemble the Complex Symptoms (The Grouping Logic)\n",
    "    for code, values in complex_complaints.items():\n",
    "        # Example: E_55 usually means \"pain location\"\n",
    "        base_question = evidences_dict.get(code, {}).get('question_en', 'I have this related to')\n",
    "        joined_values = \", \".join(values)\n",
    "        narrative.append(f\"Regarding '{base_question}', my answer is: {joined_values}.\")\n",
    "\n",
    "    # 7. Assemble the Binary Symptoms\n",
    "    if binary_complaints:\n",
    "        narrative.append(\"Additionally, I am experiencing the following:\")\n",
    "        for complaint in binary_complaints:\n",
    "            narrative.append(f\"- {complaint}\")\n",
    "\n",
    "    # Join the final paragraph\n",
    "    return \" \".join(narrative)\n",
    "\n",
    "# --- EXECUTE ON ROW 0 ---\n",
    "first_row = df_train.iloc[0]\n",
    "patient_story = translate_row_to_narrative(first_row, evidences)\n",
    "\n",
    "print(\"--- GENERATED PATIENT NARRATIVE ---\")\n",
    "print(patient_story)\n",
    "print(\"-\" * 35)\n",
    "print(f\"Target Pathology to Predict: {first_row['PATHOLOGY']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de48eff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- POLISHED PATIENT NARRATIVE ---\n",
      "I am an 18-year-old male. I came into the clinic today because I have been running a fever. I would describe the pain as sensitive and heavy. The pain is specifically located in my forehead, cheek(R), and temple(L). On a scale of 1 to 10, the pain intensity is a 4. On a scale of 1 to 10, the precision of the pain location is a 3. Regarding how fast the pain appeared, on a scale of 1 to 10, it was a 3. No, I am not exposed to secondhand smoke on a daily basis.. To give you more context: I live in a household with 4 or more people. I've noticed I am sweating significantly more than usual. I am definitely experiencing pain related to this. I am coughing up sputum that is colored or more abundant than normal. I am a cigarette smoker. My throat is really sore. I have a cough. I have not traveled out of the country recently.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# --- THE NARRATIVE DICTIONARY ---\n",
    "# We map the E_codes to conversational first-person stems.\n",
    "NARRATIVE_STEMS = {\n",
    "    # The Main Complaints\n",
    "    'E_91': \"I have been running a fever.\",\n",
    "    \n",
    "    # Complex Groupings (Pain characteristics)\n",
    "    'E_55': \"The pain is specifically located in my\",\n",
    "    'E_54': \"I would describe the pain as\",\n",
    "    'E_56': \"On a scale of 1 to 10, the pain intensity is a\",\n",
    "    'E_57': \"The pain radiates to my\",\n",
    "    'E_58': \"On a scale of 1 to 10, the precision of the pain location is a\",\n",
    "    'E_59': \"Regarding how fast the pain appeared, on a scale of 1 to 10, it was a\",\n",
    "    \n",
    "    # Binary Symptoms & Antecedents (Background)\n",
    "    'E_53': \"I am definitely experiencing pain related to this.\",\n",
    "    'E_48': \"I live in a household with 4 or more people.\",\n",
    "    'E_50': \"I've noticed I am sweating significantly more than usual.\",\n",
    "    'E_77': \"I am coughing up sputum that is colored or more abundant than normal.\",\n",
    "    'E_79': \"I am a cigarette smoker.\",\n",
    "    'E_97': \"My throat is really sore.\",\n",
    "    'E_201': \"I have a cough.\",\n",
    "    'E_204': \"I am exposed to secondhand smoke on a daily basis.\",\n",
    "    'E_222': \"I have not traveled out of the country recently.\"\n",
    "}\n",
    "\n",
    "def generate_human_narrative(row_data, evidences_dict, stems_dict):\n",
    "    age = row_data['AGE']\n",
    "    sex_str = \"male\" if row_data['SEX'] == 'M' else \"female\"\n",
    "    narrative = [f\"I am an {age}-year-old {sex_str}.\"]\n",
    "    \n",
    "    initial_ev = row_data['INITIAL_EVIDENCE']\n",
    "    all_evidences = ast.literal_eval(row_data['EVIDENCES']) \n",
    "    \n",
    "    if initial_ev in all_evidences:\n",
    "        all_evidences.remove(initial_ev)\n",
    "    \n",
    "    binary_complaints = []\n",
    "    complex_complaints = {} \n",
    "\n",
    "    # 1. Process Initial Evidence smoothly\n",
    "    stem = stems_dict.get(initial_ev, f\"I have an issue regarding {initial_ev}.\")\n",
    "    narrative.append(f\"I came into the clinic today because {stem}\")\n",
    "\n",
    "    for ev_string in all_evidences:\n",
    "        if '_@_' in ev_string:\n",
    "            code, value = ev_string.split('_@_')\n",
    "            if value == 'V_123' or value == '0':\n",
    "                continue\n",
    "                \n",
    "            meaning_en = evidences_dict.get(code, {}).get('value_meaning', {}).get(value, {}).get('en', value)\n",
    "            \n",
    "            # Handle N/Y travel edge cases cleanly\n",
    "            if meaning_en == 'N': meaning_en = 'no'\n",
    "            if meaning_en == 'Y': meaning_en = 'yes'\n",
    "            \n",
    "            if code not in complex_complaints:\n",
    "                complex_complaints[code] = []\n",
    "            complex_complaints[code].append(meaning_en)\n",
    "            \n",
    "        else:\n",
    "            # Look up the smooth string, fallback to the raw question if not found\n",
    "            fallback_question = evidences_dict.get(ev_string, {}).get('question_en', ev_string)\n",
    "            binary_str = stems_dict.get(ev_string, f\"I also noticed: {fallback_question}\")\n",
    "            binary_complaints.append(binary_str)\n",
    "\n",
    "    # 2. Assemble Complex Symptoms smoothly\n",
    "    # 2. Assemble Complex Symptoms smoothly (WITH FIXES)\n",
    "    for code, values in complex_complaints.items():\n",
    "        base_stem = stems_dict.get(code, f\"Regarding {code}, it is\")\n",
    "        \n",
    "        # FIX 1: The \"Stray No\" / \"Yes\" Handler\n",
    "        # If the value is literally just 'yes' or 'no' (e.g., travel history)\n",
    "        if len(values) == 1 and values[0].lower() in ['yes', 'y']:\n",
    "            narrative.append(f\"Yes, {base_stem.lower()}.\")\n",
    "            continue\n",
    "        elif len(values) == 1 and values[0].lower() in ['no', 'n']:\n",
    "            # We add 'not' to make it negative (e.g., \"I am not exposed to...\")\n",
    "            narrative.append(f\"No, I am not {base_stem.lower().replace('i am ', '')}.\")\n",
    "            continue\n",
    "\n",
    "        # FIX 2: The \"Double And\" Grammatical List Handler\n",
    "        if len(values) == 1:\n",
    "            joined_values = values[0]\n",
    "        elif len(values) == 2:\n",
    "            joined_values = f\"{values[0]} and {values[1]}\"\n",
    "        else:\n",
    "            # Joins all but the last with commas, then adds \", and [last]\"\n",
    "            joined_values = \", \".join(values[:-1]) + f\", and {values[-1]}\"\n",
    "            \n",
    "        narrative.append(f\"{base_stem} {joined_values}.\")\n",
    "\n",
    "    # 3. Assemble Binary Symptoms naturally\n",
    "    if binary_complaints:\n",
    "        narrative.append(\"To give you more context:\")\n",
    "        for complaint in binary_complaints:\n",
    "            narrative.append(complaint)\n",
    "\n",
    "    return \" \".join(narrative)\n",
    "\n",
    "# --- EXECUTE AND COMPARE ---\n",
    "first_row = df_train.iloc[0] # Your 18-year-old URTI patient\n",
    "polished_story = generate_human_narrative(first_row, evidences, NARRATIVE_STEMS)\n",
    "\n",
    "print(\"--- POLISHED PATIENT NARRATIVE ---\")\n",
    "print(polished_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42804bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TOP 20 CODES TO ADD TO NARRATIVE_STEMS ---\n",
      "'E_55': # Appears 3203271 times -> Question: Do you feel pain somewhere?\n",
      "'E_54': # Appears 1647421 times -> Question: Characterize your pain:\n",
      "'E_57': # Appears 1355490 times -> Question: Does the pain radiate to another location?\n",
      "'E_204': # Appears 1025602 times -> Question: Have you traveled out of the country in the last 4 weeks?\n",
      "'E_56': # Appears 798938 times -> Question: How intense is the pain?\n",
      "'E_58': # Appears 798938 times -> Question: How precisely is the pain located?\n",
      "'E_59': # Appears 798938 times -> Question: How fast did the pain appear?\n",
      "'E_53': # Appears 788079 times -> Question: Do you have pain somewhere, related to your reason for consulting?\n",
      "'E_133': # Appears 618662 times -> Question: Where is the affected region located?\n",
      "'E_66': # Appears 399695 times -> Question: Are you experiencing shortness of breath or difficulty breathing in a significant way?\n",
      "'E_152': # Appears 352462 times -> Question: Where is the swelling located?\n",
      "'E_201': # Appears 319418 times -> Question: Do you have a cough?\n",
      "'E_79': # Appears 287363 times -> Question: Do you smoke cigarettes?\n",
      "'E_91': # Appears 216215 times -> Question: Do you have a fever (either felt or measured with a thermometer)?\n",
      "'E_181': # Appears 202756 times -> Question: Do you have nasal congestion or a clear runny nose?\n",
      "'E_130': # Appears 200072 times -> Question: What color is the rash?\n",
      "'E_131': # Appears 200072 times -> Question: Do your lesions peel off?\n",
      "'E_132': # Appears 200072 times -> Question: Is the rash swollen?\n",
      "'E_135': # Appears 200072 times -> Question: Is the lesion (or are the lesions) larger than 1cm?\n",
      "'E_136': # Appears 200072 times -> Question: How severe is the itching?\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "# Count all evidences across the entire dataset\n",
    "all_codes = []\n",
    "for index, row in df_train.iterrows():\n",
    "    ev_list = ast.literal_eval(row['EVIDENCES'])\n",
    "    for ev in ev_list:\n",
    "        # We only care about the base code, not the complex values\n",
    "        base_code = ev.split('_@_')[0] if '_@_' in ev else ev\n",
    "        all_codes.append(base_code)\n",
    "\n",
    "# Get the top 20 most common codes\n",
    "top_codes = Counter(all_codes).most_common(20)\n",
    "\n",
    "print(\"--- TOP 20 CODES TO ADD TO NARRATIVE_STEMS ---\")\n",
    "for code, count in top_codes:\n",
    "    question = evidences.get(code, {}).get('question_en', 'Unknown')\n",
    "    print(f\"'{code}': # Appears {count} times -> Question: {question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431c1d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! 223 codes exported to stem_mapping_template.csv.\n",
      "You can now open this file in VS Code or Excel to review the stems.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Create a list to hold our template rows\n",
    "mapping_data = []\n",
    "\n",
    "for code, details in evidences.items():\n",
    "    raw_question = details.get('question_en', '')\n",
    "    \n",
    "    # 2. Smart Auto-Drafting Logic (to save you typing time)\n",
    "    draft_stem = raw_question\n",
    "    q_lower = raw_question.lower()\n",
    "    \n",
    "    if q_lower.startswith(\"do you have a\"):\n",
    "        draft_stem = \"I have a\" + raw_question[13:].replace(\"?\", \".\")\n",
    "    elif q_lower.startswith(\"do you have\"):\n",
    "        draft_stem = \"I have\" + raw_question[11:].replace(\"?\", \".\")\n",
    "    elif q_lower.startswith(\"are you\"):\n",
    "        draft_stem = \"I am\" + raw_question[7:].replace(\"?\", \".\")\n",
    "    elif q_lower.startswith(\"do you\"):\n",
    "        draft_stem = \"I\" + raw_question[6:].replace(\"?\", \".\")\n",
    "    elif q_lower.startswith(\"how intense\"):\n",
    "        draft_stem = \"On a scale of 1 to 10, the intensity is\"\n",
    "    else:\n",
    "        # Fallback for complex questions\n",
    "        draft_stem = \"Regarding the question '\" + raw_question.replace(\"?\", \"\") + \"', my answer is\"\n",
    "\n",
    "    # 3. Append to our data list\n",
    "    mapping_data.append({\n",
    "        'E_Code': code,\n",
    "        'Raw_Question': raw_question,\n",
    "        'Narrative_Stem': draft_stem\n",
    "    })\n",
    "\n",
    "# 4. Export to a CSV file\n",
    "template_df = pd.DataFrame(mapping_data)\n",
    "template_file = 'stem_mapping_template.csv'\n",
    "template_df.to_csv(template_file, index=False)\n",
    "\n",
    "print(f\"Success! {len(template_df)} codes exported to {template_file}.\")\n",
    "print(\"You can now open this file in VS Code or Excel to review the stems.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e3cdb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 223 narrative stems into memory!\n",
      "----------------------------------------\n",
      "--- TEST WITH FULL 223 DICTIONARY ---\n",
      "I am an 18-year-old male. I came into the clinic today because I have a fever (either felt or measured with a thermometer). Regarding the question 'Characterize your pain:', my answer is sensitive and heavy. I feel pain somewhere. forehead, cheek(R), and temple(L). On a scale of 1 to 10, the intensity is 4. Regarding the question 'How precisely is the pain located', my answer is 3. Regarding the question 'How fast did the pain appear', my answer is 3. No, I am not regarding the question 'have you traveled out of the country in the last 4 weeks', my answer is. To give you more context: I live with 4 or more people. Regarding the question 'Have you had significantly increased sweating', my answer is I have pain somewhere, related to your reason for consulting. I have a cough that produces colored or more abundant sputum than usual. I smoke cigarettes. I have a sore throat. I have a cough. I am exposed to secondhand cigarette smoke on a daily basis.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the CSV you just finalized\n",
    "mapping_df = pd.read_csv('stem_mapping_template.csv')\n",
    "\n",
    "# 2. Convert it into a Python dictionary for instant lookup\n",
    "# This completely replaces the manual NARRATIVE_STEMS we wrote earlier\n",
    "NARRATIVE_STEMS = dict(zip(mapping_df['E_Code'], mapping_df['Narrative_Stem']))\n",
    "\n",
    "print(f\"Successfully loaded {len(NARRATIVE_STEMS)} narrative stems into memory!\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 3. Let's do a quick sanity check on Row 0 using the full dictionary\n",
    "first_row = df_train.iloc[0] # Your 18-year-old male\n",
    "test_story = generate_human_narrative(first_row, evidences, NARRATIVE_STEMS)\n",
    "\n",
    "print(\"--- TEST WITH FULL 223 DICTIONARY ---\")\n",
    "print(test_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "616b4d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 223 narrative stems into memory!\n",
      "----------------------------------------\n",
      "--- FINAL POLISHED NARRATIVE (ROW 0) ---\n",
      "I am an 18-year-old male. I came into the clinic today because I have a fever (either felt or measured with a thermometer). I would describe the pain as sensitive and heavy. The pain is specifically located in my. forehead, cheek(R), and temple(L). On a scale of 1 to 10, the intensity is 4. On a scale of 1 to 10, the precision of the pain location is a 3. Regarding how fast the pain appeared, on a scale of 1 to 10, it was a 3. No, I am not traveling out of the country recently. To give you more context: I live with 4 or more people. Regarding the question 'Have you had significantly increased sweating', my answer is I have pain somewhere, related to your reason for consulting. I have a cough that produces colored or more abundant sputum than usual. I smoke cigarettes. I have a sore throat. I have a cough. I am exposed to secondhand cigarette smoke on a daily basis.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Reload your polished CSV\n",
    "mapping_df = pd.read_csv('stem_mapping_template.csv')\n",
    "NARRATIVE_STEMS = dict(zip(mapping_df['E_Code'], mapping_df['Narrative_Stem']))\n",
    "\n",
    "print(f\"Loaded {len(NARRATIVE_STEMS)} narrative stems into memory!\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 2. Test Row 0 again\n",
    "first_row = df_train.iloc[0] # Your 18-year-old male\n",
    "final_story = generate_human_narrative(first_row, evidences, NARRATIVE_STEMS)\n",
    "\n",
    "print(\"--- FINAL POLISHED NARRATIVE (ROW 0) ---\")\n",
    "print(final_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26454ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting translation pipeline for release_train_patients...\n",
      "Processing chunk 1 (Rows 0 to 50000)...\n",
      "Processing chunk 2 (Rows 50000 to 100000)...\n",
      "Processing chunk 3 (Rows 100000 to 150000)...\n",
      "Processing chunk 4 (Rows 150000 to 200000)...\n",
      "Processing chunk 5 (Rows 200000 to 250000)...\n",
      "Processing chunk 6 (Rows 250000 to 300000)...\n",
      "Processing chunk 7 (Rows 300000 to 350000)...\n",
      "Processing chunk 8 (Rows 350000 to 400000)...\n",
      "Processing chunk 9 (Rows 400000 to 450000)...\n",
      "Processing chunk 10 (Rows 450000 to 500000)...\n",
      "Processing chunk 11 (Rows 500000 to 550000)...\n",
      "Processing chunk 12 (Rows 550000 to 600000)...\n",
      "Processing chunk 13 (Rows 600000 to 650000)...\n",
      "Processing chunk 14 (Rows 650000 to 700000)...\n",
      "Processing chunk 15 (Rows 700000 to 750000)...\n",
      "Processing chunk 16 (Rows 750000 to 800000)...\n",
      "Processing chunk 17 (Rows 800000 to 850000)...\n",
      "Processing chunk 18 (Rows 850000 to 900000)...\n",
      "Processing chunk 19 (Rows 900000 to 950000)...\n",
      "Processing chunk 20 (Rows 950000 to 1000000)...\n",
      "Processing chunk 21 (Rows 1000000 to 1050000)...\n",
      "Pipeline completed successfully! Phase 1 is officially done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Pipeline Configuration\n",
    "input_file = 'release_train_patients'\n",
    "output_file = 'translated_train_data.csv'\n",
    "chunk_size = 50000\n",
    "\n",
    "# 2. Initialize the Output File (Only saving Target and Text)\n",
    "pd.DataFrame(columns=['PATHOLOGY', 'NARRATIVE']).to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Starting translation pipeline for {input_file}...\")\n",
    "\n",
    "# 3. Process in Chunks\n",
    "for i, chunk in enumerate(pd.read_csv(input_file, chunksize=chunk_size)):\n",
    "    print(f\"Processing chunk {i+1} (Rows {i*chunk_size} to {(i+1)*chunk_size})...\")\n",
    "    \n",
    "    # Apply the translation function\n",
    "    chunk['NARRATIVE'] = chunk.apply(\n",
    "        lambda row: generate_human_narrative(row, evidences, NARRATIVE_STEMS), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Keep only what Phase 2 needs: The target label and the narrative text\n",
    "    processed_chunk = chunk[['PATHOLOGY', 'NARRATIVE']]\n",
    "    \n",
    "    # Append to the CSV on your hard drive\n",
    "    processed_chunk.to_csv(output_file, mode='a', header=False, index=False)\n",
    "\n",
    "print(\"Pipeline completed successfully! Phase 1 is officially done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf23cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99e65255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the 1-Million row dataset...\n",
      "Stratifying and sampling 10,000 rows...\n",
      "----------------------------------------\n",
      "Success! Tiny sample saved as tiny_train_sample.csv\n",
      "Total rows: 10000\n",
      "Total unique pathologies represented: 49 (Should be 49)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load the massive dataset we just built\n",
    "print(\"Loading the 1-Million row dataset...\")\n",
    "df_full = pd.read_csv('translated_train_data.csv')\n",
    "\n",
    "# 2. Create a 10,000 row stratified sample\n",
    "# We use train_test_split purely to mathematically sample the data while maintaining the disease ratios\n",
    "print(\"Stratifying and sampling 10,000 rows...\")\n",
    "_, df_sample = train_test_split(\n",
    "    df_full, \n",
    "    test_size=10000, \n",
    "    stratify=df_full['PATHOLOGY'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. Save the tiny sample to your hard drive\n",
    "sample_filename = 'tiny_train_sample.csv'\n",
    "df_sample.to_csv(sample_filename, index=False)\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Success! Tiny sample saved as {sample_filename}\")\n",
    "print(f\"Total rows: {df_sample.shape[0]}\")\n",
    "print(f\"Total unique pathologies represented: {df_sample['PATHOLOGY'].nunique()} (Should be 49)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299315f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652b10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755e4031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff7cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f88b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c39f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a9a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9053c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35dc30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4b2395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565fbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1afec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a244d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb9f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b446f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cc049f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755bd79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d3a5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e41db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59619a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3fff04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e6f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
